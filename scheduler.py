#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‹›è˜å²—ä½å®šæ—¶æŠ“å–ä¸é’‰é’‰æ¨é€è„šæœ¬
åŠŸèƒ½ï¼šæ¯3å°æ—¶è‡ªåŠ¨æŠ“å–æœ€æ–°å²—ä½ï¼Œå»é‡åæ¨é€åˆ°é’‰é’‰ç¾¤

âš ï¸ é‡è¦æç¤ºï¼šè¯·åŠ¡å¿…ä¿ç®¡å¥½ä½ çš„ DingTalk Tokenï¼Œä¸è¦æ³„éœ²ç»™ä»–äººï¼

å®‰è£…ä¾èµ–ï¼š
    pip install playwright schedule requests

å®‰è£…Playwrightæµè§ˆå™¨ï¼š
    playwright install chromium

ä½¿ç”¨æ–¹æ³•ï¼š
    python job_scraper_scheduler.py
"""

import time
import random
import sqlite3
import requests
import urllib.parse
import pandas as pd
from datetime import datetime
from typing import List, Dict, Optional
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError

# ==================== é…ç½®åŒºåŸŸ ====================

# é’‰é’‰Webhookåœ°å€ï¼ˆè¯·æ›¿æ¢ä¸ºä½ çš„å®é™…Tokenï¼‰
DINGTALK_WEBHOOK = "https://oapi.dingtalk.com/robot/send?access_token=c5b4858e08eb2b4cbf4e1678368b3ed64d82eb0b3083dd8c77964126f4ac7994"

# æ•°æ®åº“æ–‡ä»¶è·¯å¾„
DB_FILE = "jobs.db"

# æŠ“å–é—´éš”ï¼ˆç§’ï¼‰- 3å°æ—¶ = 10800ç§’
SCRAPE_INTERVAL = 10800  # 3å°æ—¶

# éšæœºç­‰å¾…æ—¶é—´èŒƒå›´ï¼ˆç§’ï¼‰- æ¨¡æ‹Ÿäººç±»æ“ä½œï¼ˆå·²ä¼˜åŒ–ä¸ºæ›´å¿«é€Ÿåº¦ï¼‰
# å¿«é€Ÿæ¨¡å¼ï¼š1-3ç§’ï¼Œå¹³è¡¡æ¨¡å¼ï¼š2-5ç§’ï¼Œå®‰å…¨æ¨¡å¼ï¼š5-15ç§’
RANDOM_WAIT_MIN = 1
RANDOM_WAIT_MAX = 3

# åŸå¸‚æ˜ å°„é…ç½®ï¼ˆç”¨äºå°†æ¨¡ç³Šåœ°åŒºè½¬æ¢ä¸ºå…·ä½“åŸå¸‚ï¼‰
CITY_MAPPING = {
    'éåè¿œåœ°åŒº': [
        'åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'å—äº¬', 'è‹å·', 'æˆéƒ½', 'é‡åº†', 
        'æ­¦æ±‰', 'è¥¿å®‰', 'å¤©æ´¥', 'é’å²›', 'å¤§è¿', 'å®æ³¢', 'æ— é”¡', 'é•¿æ²™', 'éƒ‘å·',
        'æµå—', 'åˆè‚¥', 'ç¦å·', 'å¦é—¨', 'æ˜†æ˜', 'å—å®', 'çŸ³å®¶åº„', 'å“ˆå°”æ»¨', 'é•¿æ˜¥', 'æ²ˆé˜³'
    ],
    'å—æ–¹åŸå¸‚': [
        'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'å—äº¬', 'è‹å·', 'æˆéƒ½', 'é‡åº†', 'æ­¦æ±‰',
        'é•¿æ²™', 'ç¦å·', 'å¦é—¨', 'æ˜†æ˜', 'å—å®', 'æµ·å£', 'ä¸‰äºš', 'ç æµ·', 'ä¸œè',
        'ä½›å±±', 'ä¸­å±±', 'æƒ å·', 'å®æ³¢', 'æ— é”¡', 'åˆè‚¥', 'å—æ˜Œ', 'è´µé˜³'
    ],
    'ç ä¸‰è§’': [
        'å¹¿å·', 'æ·±åœ³', 'ç æµ·', 'ä¸œè', 'ä½›å±±', 'ä¸­å±±', 'æƒ å·', 'æ±Ÿé—¨', 'è‚‡åº†'
    ],
    'ä¸€çº¿åŸå¸‚': [
        'åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³'
    ],
    'åŒ—ä¸Šå¹¿æ·±': [
        'åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³'
    ],
    'åŒ—ä¸Šå¹¿æ·±æ­': [
        'åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·'
    ],
    'æ±Ÿæµ™æ²ª': [
        'æ±Ÿè‹', 'æµ™æ±Ÿ', 'ä¸Šæµ·'
    ],
    'ä¸œä¸‰çœ': [
        'å“ˆå°”æ»¨', 'é•¿æ˜¥', 'æ²ˆé˜³', 'å¤§è¿'
    ],
    'åŒ—æ–¹äºŒçº¿åŸå¸‚': [
        'å¤©æ´¥', 'é’å²›', 'å¤§è¿', 'æµå—', 'çŸ³å®¶åº„', 'å¤ªåŸ', 'éƒ‘å·', 'è¥¿å®‰', 'å“ˆå°”æ»¨', 'é•¿æ˜¥', 'æ²ˆé˜³'
    ],
    'å¹¿ä¸œ': [
        'å¹¿å·', 'æ·±åœ³', 'ç æµ·', 'ä¸œè', 'ä½›å±±', 'ä¸­å±±', 'æƒ å·', 'æ±Ÿé—¨', 'è‚‡åº†', 'æ±•å¤´', 'æ¹›æ±Ÿ'
    ],
}

# æœç´¢é…ç½®åˆ—è¡¨ï¼ˆå®Œæ•´ç‰ˆï¼ŒåŒ…å«æ‰€æœ‰43ä¸ªé…ç½®ï¼‰
SEARCH_CONFIGS = [
    {
        'keywords': ['åŒ–å­¦è¯ç‰©ç ”å‘'],
        'locations': ['æ±Ÿè‹', 'æµ™æ±Ÿ', 'ä¸Šæµ·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['ç­–å±•åŠ©ç†', 'ç§‘æ™®å±•è§ˆ', 'æ–‡æ¡ˆç¼–è¾‘', 'ç¯ä¿å…¬ç›Š', 'è‡ªç„¶ä¿æŠ¤', 'CRO', 'CDMO', 'åŒ»ç–—å™¨æ¢°', 'IVD'],
        'locations': ['éåè¿œåœ°åŒº'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['å¤–è´¸ä¸šåŠ¡', 'æµ·å¤–å®¢æˆ·', 'å’¨è¯¢', 'å›½é™…åŒ–'],
        'locations': ['ä¸Šæµ·'],
        'grad_year': 2025,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': 'å¤§å…¬å¸ä¼˜å…ˆ',
        'education': 'æœ¬ç§‘',
        'company_type': None,
    },
    {
        'keywords': ['æ³•åŠ¡', 'æ³•å¾‹'],
        'locations': ['å±±è¥¿', 'é™•è¥¿', 'æˆéƒ½', 'æ­å·', 'æ·±åœ³', 'é’å²›', 'ä¸Šæµ·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': 'å¤®å›½ä¼',
    },
    {
        'keywords': ['ç”Ÿç‰©åŒ»ç–—æŠ€æœ¯', 'ä¸´åºŠåº”ç”¨', 'äº§å“æ¨å¹¿'],
        'locations': ['æ±Ÿè‹', 'æµ™æ±Ÿ', 'ä¸Šæµ·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': 'ä¼ä¸š/ç§‘ç ”/å«ç”Ÿç³»ç»Ÿ',
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['ç¯å¢ƒ', 'ESG', 'ç¨€åœŸ'],
        'locations': ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'è´µå·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['Tesol', 'å›½é™…å­¦æ ¡è€å¸ˆ', 'å¿ƒç†è¾…å¯¼', 'è¾…å¯¼å‘˜', 'å­¦æ ¡è¡Œæ”¿', 'å‡å­¦æŒ‡å¯¼'],
        'locations': ['å—æ–¹åŸå¸‚'],
        'grad_year': [2025, 2026],
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['CSR', 'ESG', 'å’¨è¯¢', 'è¡Œç ”', 'æ”¿ç­–ç ”ç©¶', 'å¸‚åœºè°ƒç ”'],
        'locations': ['å¹¿å·', 'ç ä¸‰è§’'],
        'grad_year': 2025,
        'recruit_type': 'ç¤¾æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['ç²¾ç®—å¸ˆ'],
        'locations': ['ä¸€çº¿åŸå¸‚'],
        'grad_year': 2023,
        'recruit_type': 'æ ¡æ‹›',
        'industry': ['ä¿é™©', 'é‡‘è'],
        'notes': 'æ— ç»éªŒ',
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['ä½“è‚²è€å¸ˆ'],
        'locations': ['åŒ—äº¬'],
        'grad_year': None,
        'recruit_type': 'ç¤¾æ‹›/æ ¡æ‹›',
        'industry': None,
        'notes': 'ä¸­å­¦/å¤§å­¦',
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['æ”¿åºœäº‹åŠ¡', 'å›½é™…ç»„ç»‡'],
        'locations': ['å…¨å›½'],
        'grad_year': None,
        'recruit_type': 'ç¤¾æ‹›/æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['å›½é™…å­¦æ ¡éæ•™èŒ', 'è¾…å¯¼å‘˜', 'æ•™åŠ¡'],
        'locations': ['æ­å·'],
        'grad_year': None,
        'recruit_type': 'ç¤¾æ‹›/æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['æ’ç”»', 'å¹³é¢è®¾è®¡'],
        'locations': ['æ±Ÿè‹', 'æµ™æ±Ÿ', 'ä¸Šæµ·'],
        'grad_year': 2025,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': 'ææ–™ä¸“ä¸šèƒŒæ™¯ä¼˜å…ˆ(éš¾ä»¥ç­›é€‰ï¼Œå…ˆæŠ“å…³é”®è¯)',
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['é‡‘è'],
        'locations': ['æ·±åœ³'],
        'grad_year': 2025,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['äººåŠ›èµ„æº'],
        'locations': ['åŒ—äº¬'],
        'grad_year': 2024,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': 'å¤§å‚, å…«å¤§',
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['å¿«æ¶ˆå¸‚åœº', 'äº’è”ç½‘è¿è¥', 'ç®¡åŸ¹ç”Ÿ'],
        'locations': ['ä¸Šæµ·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['æ•°æ®ç›¸å…³'],
        'locations': ['å…¨å›½'],
        'grad_year': 2024,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['æ•°æ®åˆ†æ', 'å•†ä¸šåˆ†æ'],
        'locations': ['ä¸Šæµ·'],
        'grad_year': 2024,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['å†…å®¹è¿è¥', 'å¸‚åœºå“ç‰Œ'],
        'locations': ['æ­å·'],
        'grad_year': 2025,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['æ§åˆ¶ç®—æ³•'],
        'locations': ['è‹å·', 'ä¸Šæµ·', 'æ­å·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['æœºæ¢°'],
        'locations': ['æ¹–å—'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': 'å¤§ä¸“',
        'company_type': None,
    },
    {
        'keywords': ['åº”å±Šç”Ÿ'],
        'locations': ['ä¸Šæµ·'],
        'grad_year': 2024,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': 'æ¯•ä¸šæ—¶é—´ï¼š24å¹´8æœˆ',
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['å½±è§†æ€»è£ç‰¹åŠ©', 'æ¼”å‡ºç®¡ç†', 'æ¼”å”±ä¼šç­–åˆ’', 'ç­–å±•'],
        'locations': ['åŒ—äº¬', 'æ­å·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['å†…å®¹è¿è¥'],
        'locations': ['å¹¿å·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['é‡åŒ–'],
        'locations': ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['ä¾›åº”é“¾ç®¡ç†', 'é¡¹ç›®ç®¡ç†'],
        'locations': ['ä¸Šæµ·', 'æ­å·', 'æ·±åœ³', 'å¹¿å·'],
        'grad_year': None,
        'recruit_type': 'ç¤¾æ‹›',
        'industry': None,
        'notes': '2å¹´ç»éªŒ',
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['å®¡è®¡', 'è´¢åŠ¡', 'æŠ•èµ„'],
        'locations': ['ä¸Šæµ·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['å¸‚åœº', 'å“ç‰Œ', 'è¿è¥', 'åˆ›æ„ç­–åˆ’'],
        'locations': ['æ±Ÿè‹', 'æµ™æ±Ÿ', 'ä¸Šæµ·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['ç­–åˆ’'],
        'locations': ['åŒ—äº¬'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': 'å›½å¤®ä¼',
    },
    {
        'keywords': ['è‹±è¯­æ•™å¸ˆ'],
        'locations': ['æ­å·', 'å—äº¬', 'è‹å·', 'æ·±åœ³', 'å¹¿å·', 'å—å®', 'æˆéƒ½', 'é‡åº†', 'æ­¦æ±‰', 'å®æ³¢', 'æ— é”¡', 'ä¸Šæµ·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': 'é«˜æ ¡/å›½é™…å­¦æ ¡',
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['ä½“è‚²è€å¸ˆ'],
        'locations': ['ä¸œä¸‰çœ', 'åŒ—äº¬'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': 'å…¬åŠé™¢æ ¡',
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['ä¸»æŒ', 'æ’­éŸ³', 'å®£ä¼ å²—', 'ä¼ä¸šæ–‡åŒ–', 'å…šç¾¤å·¥ä½œ'],
        'locations': ['åŒ—äº¬'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': 'å¹¿ç”µå¤®ä¼',
    },
    {
        'keywords': ['åŸä¹¡è§„åˆ’', 'å‡ºè¡Œ', 'è¿è¥'],
        'locations': ['å—äº¬', 'æ±Ÿè‹', 'é•¿æ²™', 'æˆéƒ½', 'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'ä¸Šæµ·', 'åŒ—äº¬'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['æ³•å¾‹', 'èˆªè¿é™©èµ„æ³•å¾‹', 'æ³•åŠ¡', 'å¾‹å¸ˆ'],
        'locations': ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['è‡ªåŠ¨åŒ–'],
        'locations': ['åŒ—æ–¹äºŒçº¿åŸå¸‚'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': 'å›½å¤®ä¼',
    },
    {
        'keywords': ['æ¸¸æˆç­–åˆ’', 'æ¸¸æˆè¿è¥'],
        'locations': ['å…¨å›½'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['é¡¹ç›®ç®¡ç†'],
        'locations': ['æ±Ÿè‹', 'æµ™æ±Ÿ', 'ä¸Šæµ·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['å®¡è®¡'],
        'locations': ['æ·±åœ³', 'å¹¿å·'],
        'grad_year': 2026,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': 'å››å¤§',
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['ç½‘ç»œå®‰å…¨'],
        'locations': ['å¹¿ä¸œ'],
        'grad_year': 2025,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['æœºæ¢°é”€å”®'],
        'locations': ['æ·±åœ³', 'å¹¿å·'],
        'grad_year': 2025,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['ç”Ÿç‰©åŒ»è¯', 'å†œä¸šç§‘æŠ€'],
        'locations': ['å¹¿ä¸œ'],
        'grad_year': 2025,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['äº§å“ç ”ç©¶å‘˜', 'æŠ•èµ„åˆ†æå¸ˆ', 'è¡Œç ”', 'æ•°æ®åˆ†æ'],
        'locations': ['åŒ—äº¬'],
        'grad_year': 2025,
        'recruit_type': 'æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
    {
        'keywords': ['å›½é™…å­¦æ ¡è‹±è¯­æ•™å¸ˆ', 'åŒè¯­è€å¸ˆ', 'æ•™åŸ¹è‹±è¯­'],
        'locations': ['å…¨å›½'],
        'grad_year': None,
        'recruit_type': 'ç¤¾æ‹›/æ ¡æ‹›',
        'industry': None,
        'notes': None,
        'education': None,
        'company_type': None,
    },
]


# ==================== æ•°æ®åº“æ¨¡å— ====================

class DBManager:
    """æ•°æ®åº“ç®¡ç†å™¨ - ç”¨äºè®°å½•å·²æ¨é€çš„å²—ä½"""
    
    def __init__(self, db_file: str = DB_FILE):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        self.db_file = db_file
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„ï¼ˆåŒ…å«æ‰€æœ‰9ä¸ªå­—æ®µï¼‰"""
        conn = sqlite3.connect(self.db_file)
        cursor = conn.cursor()
        
        # åˆ›å»ºè¡¨ï¼šposted_jobsï¼ˆåŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µï¼‰
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS posted_jobs (
                url TEXT PRIMARY KEY,
                company_name TEXT,
                company_type TEXT,
                work_location TEXT,
                recruit_type TEXT,
                recruit_target TEXT,
                job_title TEXT NOT NULL,
                update_time TEXT,
                deadline TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # å¦‚æœè¡¨å·²å­˜åœ¨ä½†å­—æ®µä¸å®Œæ•´ï¼Œå°è¯•æ·»åŠ æ–°å­—æ®µ
        try:
            cursor.execute('ALTER TABLE posted_jobs ADD COLUMN company_type TEXT')
        except:
            pass
        try:
            cursor.execute('ALTER TABLE posted_jobs ADD COLUMN work_location TEXT')
        except:
            pass
        try:
            cursor.execute('ALTER TABLE posted_jobs ADD COLUMN recruit_type TEXT')
        except:
            pass
        try:
            cursor.execute('ALTER TABLE posted_jobs ADD COLUMN recruit_target TEXT')
        except:
            pass
        try:
            cursor.execute('ALTER TABLE posted_jobs ADD COLUMN update_time TEXT')
        except:
            pass
        try:
            cursor.execute('ALTER TABLE posted_jobs ADD COLUMN deadline TEXT')
        except:
            pass
        
        conn.commit()
        conn.close()
        print(f"âœ“ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.db_file}")
    
    def is_job_exists(self, url: str) -> bool:
        """åˆ¤æ–­å²—ä½æ˜¯å¦å·²å­˜åœ¨"""
        conn = sqlite3.connect(self.db_file)
        cursor = conn.cursor()
        
        cursor.execute('SELECT 1 FROM posted_jobs WHERE url = ?', (url,))
        exists = cursor.fetchone() is not None
        
        conn.close()
        return exists
    
    def save_job(self, data: Dict):
        """ä¿å­˜æ–°å²—ä½åˆ°æ•°æ®åº“ï¼ˆåŒ…å«æ‰€æœ‰9ä¸ªå­—æ®µï¼‰"""
        conn = sqlite3.connect(self.db_file)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                INSERT OR IGNORE INTO posted_jobs (
                    url, company_name, company_type, work_location,
                    recruit_type, recruit_target, job_title,
                    update_time, deadline, created_at
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                data.get('url', ''),
                data.get('company_name', 'æœªçŸ¥'),
                data.get('company_type', 'æœªçŸ¥'),
                data.get('work_location', ''),
                data.get('recruit_type', ''),
                data.get('recruit_target', ''),
                data.get('job_title', ''),
                data.get('update_time', 'æœªçŸ¥'),
                data.get('deadline', 'è¯¦è§é“¾æ¥'),
                datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            ))
            conn.commit()
            return True
        except Exception as e:
            print(f"âš  ä¿å­˜å²—ä½åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {str(e)}")
            return False
        finally:
            conn.close()
    
    def get_total_count(self) -> int:
        """è·å–æ•°æ®åº“ä¸­æ€»å²—ä½æ•°"""
        conn = sqlite3.connect(self.db_file)
        cursor = conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM posted_jobs')
        count = cursor.fetchone()[0]
        
        conn.close()
        return count


# ==================== é’‰é’‰é€šçŸ¥æ¨¡å— ====================

class DingTalkSender:
    """é’‰é’‰æ¶ˆæ¯å‘é€å™¨"""
    
    def __init__(self, webhook: str = DINGTALK_WEBHOOK):
        """åˆå§‹åŒ–é’‰é’‰å‘é€å™¨"""
        self.webhook = webhook
        if "YOUR_TOKEN" in webhook:
            print("âš  è­¦å‘Š: è¯·å…ˆé…ç½®é’‰é’‰Webhookåœ°å€ï¼")
    
    def send_file(self, file_path: str, file_name: str = None) -> bool:
        """å‘é€æ–‡ä»¶åˆ°é’‰é’‰ç¾¤ï¼ˆé€šè¿‡æ–‡ä»¶ä¸Šä¼ APIï¼‰"""
        if "YOUR_TOKEN" in self.webhook:
            print("âš  é’‰é’‰Webhookæœªé…ç½®ï¼Œè·³è¿‡æ–‡ä»¶å‘é€")
            return False
        
        if not file_name:
            file_name = file_path.split('/')[-1]
        
        try:
            # è¯»å–æ–‡ä»¶
            with open(file_path, 'rb') as f:
                file_content = f.read()
            
            # é’‰é’‰æœºå™¨äººå‘é€æ–‡ä»¶éœ€è¦å…ˆä¸Šä¼ åˆ°é’‰é’‰æœåŠ¡å™¨
            # æ–¹æ³•1: ä½¿ç”¨é’‰é’‰çš„æ–‡ä»¶ä¸Šä¼ æ¥å£ï¼ˆéœ€è¦access_tokenï¼‰
            # æ–¹æ³•2: ä½¿ç”¨é’‰é’‰çš„"æ–‡ä»¶"æ¶ˆæ¯ç±»å‹ï¼ˆéœ€è¦media_idï¼‰
            # 
            # ç”±äºé’‰é’‰æœºå™¨äººWebhookä¸æ”¯æŒç›´æ¥å‘é€æ–‡ä»¶ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹æ–¹æ¡ˆï¼š
            # 1. å°†æ–‡ä»¶è½¬æ¢ä¸ºbase64ï¼ˆä½†é’‰é’‰ä¸æ”¯æŒï¼‰
            # 2. ä¸Šä¼ åˆ°äº‘å­˜å‚¨åå‘é€é“¾æ¥ï¼ˆéœ€è¦äº‘å­˜å‚¨æœåŠ¡ï¼‰
            # 3. ä½¿ç”¨é’‰é’‰ä¼ä¸šåº”ç”¨APIä¸Šä¼ æ–‡ä»¶ï¼ˆéœ€è¦é¢å¤–æƒé™ï¼‰
            #
            # æœ€å®ç”¨çš„æ–¹æ¡ˆï¼šåœ¨æ¶ˆæ¯ä¸­æ·»åŠ æ–‡ä»¶ä¸‹è½½è¯´æ˜ï¼Œå¹¶æä¾›æœ¬åœ°æ–‡ä»¶è·¯å¾„
            # æˆ–è€…ï¼šä½¿ç”¨é’‰é’‰çš„æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ï¼ˆéœ€è¦ä»webhookä¸­æå–access_tokenï¼‰
            
            # å°è¯•ä½¿ç”¨é’‰é’‰çš„æ–‡ä»¶ä¸Šä¼ API
            # ä»webhook URLä¸­æå–access_token
            import re
            token_match = re.search(r'access_token=([^&]+)', self.webhook)
            if not token_match:
                print("âš  æ— æ³•ä»Webhookä¸­æå–access_token")
                return False
            
            access_token = token_match.group(1)
            
            # é’‰é’‰æ–‡ä»¶ä¸Šä¼ æ¥å£
            upload_url = "https://oapi.dingtalk.com/media/upload"
            
            # å‡†å¤‡æ–‡ä»¶
            files = {
                'media': (file_name, file_content, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
            }
            data = {
                'type': 'file',
                'access_token': access_token
            }
            
            # ä¸Šä¼ æ–‡ä»¶
            print(f"æ­£åœ¨ä¸Šä¼ æ–‡ä»¶åˆ°é’‰é’‰: {file_name}...")
            response = requests.post(upload_url, files=files, data=data, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if result.get('errcode') == 0:
                    media_id = result.get('media_id')
                    print(f"âœ“ æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œmedia_id: {media_id[:20]}...")
                    
                    # å‘é€æ–‡ä»¶æ¶ˆæ¯
                    return self._send_file_message(media_id, file_name)
                else:
                    print(f"âœ— æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {result.get('errmsg')}")
                    # å¦‚æœä¸Šä¼ å¤±è´¥ï¼Œå°è¯•å‘é€æ–‡ä»¶é“¾æ¥æ¶ˆæ¯
                    return self._send_file_link_message(file_path, file_name)
            else:
                print(f"âœ— æ–‡ä»¶ä¸Šä¼ è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                # å¦‚æœä¸Šä¼ å¤±è´¥ï¼Œå°è¯•å‘é€æ–‡ä»¶é“¾æ¥æ¶ˆæ¯
                return self._send_file_link_message(file_path, file_name)
                
        except Exception as e:
            print(f"âœ— å‘é€æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            # å¦‚æœå‡ºé”™ï¼Œå°è¯•å‘é€æ–‡ä»¶é“¾æ¥æ¶ˆæ¯
            return self._send_file_link_message(file_path, file_name)
    
    def _send_file_message(self, media_id: str, file_name: str) -> bool:
        """å‘é€æ–‡ä»¶æ¶ˆæ¯ï¼ˆä½¿ç”¨media_idï¼‰"""
        payload = {
            "msgtype": "file",
            "file": {
                "media_id": media_id
            }
        }
        
        try:
            response = requests.post(self.webhook, json=payload, timeout=10)
            if response.status_code == 200:
                result = response.json()
                if result.get('errcode') == 0:
                    print(f"âœ“ æ–‡ä»¶æ¶ˆæ¯å‘é€æˆåŠŸ: {file_name}")
                    return True
                else:
                    print(f"âœ— æ–‡ä»¶æ¶ˆæ¯å‘é€å¤±è´¥: {result.get('errmsg')}")
                    return False
            else:
                print(f"âœ— æ–‡ä»¶æ¶ˆæ¯è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                return False
        except Exception as e:
            print(f"âœ— å‘é€æ–‡ä»¶æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
            return False
    
    def _send_file_link_message(self, file_path: str, file_name: str) -> bool:
        """å‘é€æ–‡ä»¶é“¾æ¥æ¶ˆæ¯ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼šé’‰é’‰æœºå™¨äººä¸æ”¯æŒç›´æ¥å‘é€æ–‡ä»¶ï¼‰"""
        import os
        abs_path = os.path.abspath(file_path)
        
        # è·å–æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path)
        file_size_mb = file_size / (1024 * 1024)
        
        # å‘é€åŒ…å«æ–‡ä»¶ä¿¡æ¯çš„æ¶ˆæ¯å¡ç‰‡
        content = f"""## ğŸ“ å²—ä½æ•°æ®Excelæ–‡ä»¶

**æ–‡ä»¶å**: `{file_name}`

**æ–‡ä»¶å¤§å°**: {file_size_mb:.2f} MB

**æ–‡ä»¶ä½ç½®**: 
```
{abs_path}
```

**æŸ¥çœ‹æ–¹å¼**:
1. ğŸ’» åœ¨ç”µè„‘ä¸Šç›´æ¥æ‰“å¼€æ–‡ä»¶
2. ğŸ“± é€šè¿‡æ–‡ä»¶å…±äº«å·¥å…·è®¿é—®
3. â˜ï¸ å¦‚éœ€åœ¨çº¿æŸ¥çœ‹ï¼Œå¯å°†æ–‡ä»¶ä¸Šä¼ åˆ°äº‘ç›˜

**æç¤º**: 
- æ–‡ä»¶å·²è‡ªåŠ¨ç”Ÿæˆå¹¶ä¿å­˜åœ¨è„šæœ¬è¿è¡Œç›®å½•
- æ¯æ¬¡æŠ“å–å®Œæˆåä¼šè‡ªåŠ¨æ›´æ–°æ­¤æ–‡ä»¶
- åŒ…å«æ‰€æœ‰å²—ä½çš„å®Œæ•´æ•°æ®ï¼ˆ{file_size_mb:.1f}MBï¼‰
"""
        
        payload = {
            "msgtype": "markdown",
            "markdown": {
                "title": f"ğŸ“ Excelæ–‡ä»¶: {file_name}",
                "text": content
            }
        }
        
        try:
            response = requests.post(self.webhook, json=payload, timeout=10)
            if response.status_code == 200:
                result = response.json()
                if result.get('errcode') == 0:
                    print(f"âœ“ æ–‡ä»¶ä¿¡æ¯æ¶ˆæ¯å‘é€æˆåŠŸ: {file_name}")
                    return True
                else:
                    print(f"âœ— æ–‡ä»¶ä¿¡æ¯æ¶ˆæ¯å‘é€å¤±è´¥: {result.get('errmsg')}")
                    return False
            else:
                print(f"âœ— æ–‡ä»¶ä¿¡æ¯æ¶ˆæ¯è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                return False
        except Exception as e:
            print(f"âœ— å‘é€æ–‡ä»¶ä¿¡æ¯æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
            return False
    
    def send_markdown(self, title: str, content: str) -> bool:
        """å‘é€Markdownæ ¼å¼æ¶ˆæ¯"""
        if "YOUR_TOKEN" in self.webhook:
            print("âš  é’‰é’‰Webhookæœªé…ç½®ï¼Œè·³è¿‡æ¨é€")
            return False
        
        payload = {
            "msgtype": "markdown",
            "markdown": {
                "title": title,
                "text": content
            }
        }
        
        try:
            response = requests.post(self.webhook, json=payload, timeout=10)
            if response.status_code == 200:
                result = response.json()
                if result.get('errcode') == 0:
                    print("âœ“ é’‰é’‰æ¶ˆæ¯å‘é€æˆåŠŸ")
                    return True
                else:
                    print(f"âœ— é’‰é’‰æ¶ˆæ¯å‘é€å¤±è´¥: {result.get('errmsg')}")
                    return False
            else:
                print(f"âœ— é’‰é’‰è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                return False
        except Exception as e:
            print(f"âœ— å‘é€é’‰é’‰æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
            return False
    
    def format_jobs_message(self, new_jobs: List[Dict], total_count: int, excel_file: Optional[str] = None) -> tuple:
        """æ ¼å¼åŒ–å²—ä½æ¶ˆæ¯ä¸ºMarkdownæ ¼å¼ï¼ˆä¼˜åŒ–ç‰ˆï¼šåªæ˜¾ç¤ºæœ€æ–°50ä¸ªï¼Œé€»è¾‘æ¸…æ™°ï¼‰"""
        if not new_jobs:
            return None, None
        
        # åªå–æœ€æ–°50ä¸ªå²—ä½
        display_jobs = new_jobs[:50] if len(new_jobs) > 50 else new_jobs
        remaining_count = len(new_jobs) - len(display_jobs)
        
        # æ ‡é¢˜
        title = f"ğŸ“¢ æ‹›è˜é›·è¾¾ | æ–°å¢å²—ä½ {len(new_jobs)} ä¸ª"
        
        # æŒ‰éœ€æ±‚åˆ†ç±»åˆ†ç»„ï¼ˆæŒ‰é…ç½®å…³é”®è¯åˆ†ç»„ï¼‰
        grouped_jobs = {}
        for job in display_jobs:
            group_key = job.get('config_keywords', 'å…¶ä»–')
            if group_key not in grouped_jobs:
                grouped_jobs[group_key] = []
            grouped_jobs[group_key].append(job)
        
        # æ„å»ºMarkdownå†…å®¹ï¼ˆé€»è¾‘æ¸…æ™°ï¼Œå±•ç¤ºæ¸…æ™°ï¼‰
        content_parts = []
        
        # å¤´éƒ¨ä¿¡æ¯ï¼ˆæ¸…æ™°å±•ç¤ºï¼‰
        content_parts.append(f"## ğŸ“¢ æ‹›è˜é›·è¾¾\n\n")
        content_parts.append(f"**ğŸ“… æŠ“å–æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        content_parts.append(f"**ğŸ“Š æœ¬æ¬¡æ–°å¢**: {len(new_jobs)} ä¸ªå²—ä½\n")
        content_parts.append(f"**ğŸ’¾ æ•°æ®åº“æ€»è®¡**: {total_count} ä¸ªå²—ä½\n\n")
        
        if excel_file:
            import os
            if os.path.exists(excel_file):
                file_size = os.path.getsize(excel_file) / (1024 * 1024)
                content_parts.append(f"**ğŸ“ Excelæ–‡ä»¶**: `{excel_file}` ({file_size:.1f}MB)\n\n")
        
        content_parts.append("---\n\n")
        
        # å²—ä½åˆ—è¡¨ï¼ˆæŒ‰åˆ†ç±»æ¸…æ™°å±•ç¤ºï¼‰
        if len(display_jobs) > 0:
            content_parts.append(f"### ğŸ“‹ æœ€æ–°å²—ä½åˆ—è¡¨ï¼ˆæ˜¾ç¤ºå‰{len(display_jobs)}ä¸ªï¼‰\n\n")
            
            # æŒ‰åˆ†ç»„æ˜¾ç¤º
            for idx, (group_key, jobs) in enumerate(grouped_jobs.items(), 1):
                if not jobs:
                    continue
                
                # åˆ†ç»„æ ‡é¢˜ï¼ˆæ¸…æ™°æ ‡è¯†ï¼‰
                content_parts.append(f"**{idx}. {group_key}** ({len(jobs)}ä¸ªå²—ä½)\n\n")
                
                # å²—ä½åˆ—è¡¨ï¼ˆæ ¼å¼æ¸…æ™°ï¼‰
                for job_idx, job in enumerate(jobs, 1):
                    title_text = job.get('job_title', job.get('title', 'æœªçŸ¥å²—ä½'))
                    url = job.get('url', '#')
                    company = job.get('company_name', job.get('company', 'æœªçŸ¥å…¬å¸'))
                    location = job.get('work_location', job.get('location', 'æœªçŸ¥åœ°ç‚¹'))
                    recruit_type = job.get('recruit_type', '')
                    recruit_target = job.get('recruit_target', '')
                    
                    # æ¸…æ™°çš„æ ¼å¼ï¼šå²—ä½å | å…¬å¸ | åœ°ç‚¹ | ç±»å‹
                    line_parts = []
                    line_parts.append(f"   {job_idx}. **[{title_text}]({url})**")
                    
                    if company and company != 'æœªçŸ¥':
                        line_parts.append(f" | {company}")
                    
                    if location and location != 'æœªçŸ¥åœ°ç‚¹':
                        line_parts.append(f" | ğŸ“ {location}")
                    
                    if recruit_type:
                        line_parts.append(f" | {recruit_type}")
                    
                    if recruit_target:
                        line_parts.append(f" | {recruit_target}")
                    
                    content_parts.append("".join(line_parts) + "\n")
                
                content_parts.append("\n")
        
        # åº•éƒ¨æç¤ºï¼ˆå¦‚æœæœ‰æ›´å¤šå²—ä½ï¼‰
        if remaining_count > 0:
            content_parts.append("---\n\n")
            content_parts.append(f"**ğŸ’¡ æç¤º**: è¿˜æœ‰ {remaining_count} ä¸ªå²—ä½æœªæ˜¾ç¤ºï¼Œè¯·æŸ¥çœ‹Excelæ–‡ä»¶è·å–å®Œæ•´æ•°æ®\n\n")
        
        content = "".join(content_parts)
        return title, content


# ==================== çˆ¬è™«æ¨¡å— ====================

class JobScraper:
    """å²—ä½æŠ“å–å™¨"""
    
    def __init__(self, db_manager: DBManager):
        """åˆå§‹åŒ–çˆ¬è™«"""
        self.db = db_manager
        self.playwright = None
        self.browser = None
        self.page = None
    
    def start_browser(self, headless: bool = True):
        """å¯åŠ¨æµè§ˆå™¨"""
        print("æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
        self.playwright = sync_playwright().start()
        self.browser = self.playwright.chromium.launch(
            headless=headless,
            args=['--disable-blink-features=AutomationControlled']
        )
        
        context = self.browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            viewport={'width': 1920, 'height': 1080}
        )
        
        self.page = context.new_page()
        print("âœ“ æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
    
    def close_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.browser:
            self.browser.close()
        if self.playwright:
            self.playwright.stop()
        print("âœ“ æµè§ˆå™¨å·²å…³é—­")
    
    def random_sleep(self, min_time: int = RANDOM_WAIT_MIN, max_time: int = RANDOM_WAIT_MAX):
        """éšæœºä¼‘çœ """
        sleep_time = random.uniform(min_time, max_time)
        time.sleep(sleep_time)
    
    def expand_city_list(self, locations: List[str]) -> List[str]:
        """å±•å¼€åŸå¸‚åˆ—è¡¨"""
        expanded = []
        for loc in locations:
            if loc in CITY_MAPPING:
                expanded.extend(CITY_MAPPING[loc])
            else:
                expanded.append(loc)
        # å»é‡
        seen = set()
        result = []
        for city in expanded:
            if city not in seen:
                seen.add(city)
                result.append(city)
        return result
    
    def search_yingjiesheng(self, keyword: str, city: str, grad_year: Optional[int], 
                           recruit_type: str, config_keywords: str) -> List[Dict]:
        """åœ¨åº”å±Šç”Ÿæ±‚èŒç½‘æœç´¢å²—ä½"""
        results = []
        
        try:
            keyword_encoded = urllib.parse.quote(keyword)
            city_encoded = urllib.parse.quote(city)
            
            # åº”å±Šç”Ÿæ±‚èŒç½‘çš„æœç´¢URLæ ¼å¼
            # å®é™…URLæ ¼å¼ï¼šhttps://www.yingjiesheng.com/job/?keyword=å…³é”®è¯&city=åŸå¸‚
            if recruit_type == 'æ ¡æ‹›' or 'æ ¡æ‹›' in recruit_type or recruit_type == 'å®ä¹ ' or grad_year:
                # åº”å±Šç”Ÿæ±‚èŒç½‘ä¸»è¦é’ˆå¯¹æ ¡æ‹›ï¼Œä½¿ç”¨æ ‡å‡†æœç´¢URL
                url = f"https://www.yingjiesheng.com/job/?keyword={keyword_encoded}&city={city_encoded}"
            else:
                return results
            
            print(f"    æœç´¢åº”å±Šç”Ÿæ±‚èŒç½‘: {keyword} | {city}")
            print(f"    URL: {url}")
            try:
                self.page.goto(url, wait_until="networkidle", timeout=20000)
                self.random_sleep(2, 3)  # ç­‰å¾…é¡µé¢åŠ è½½
            except Exception as e:
                print(f"    âš  è®¿é—®é¡µé¢å¤±è´¥: {str(e)[:50]}")
                return results
            self.random_sleep(0.5, 1.5)  # å¿«é€Ÿæ¨¡å¼ï¼šå‡å°‘ç­‰å¾…æ—¶é—´
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            try:
                self.page.wait_for_load_state("domcontentloaded", timeout=5000)
                self.random_sleep(0.5, 1)  # å¿«é€Ÿæ¨¡å¼ï¼šå‡å°‘ç­‰å¾…æ—¶é—´
                
                # å°è¯•å¤šç§é€‰æ‹©å™¨ï¼ˆåº”å±Šç”Ÿæ±‚èŒç½‘çš„å¸¸è§é€‰æ‹©å™¨ï¼‰
                selectors = [
                    '.job-list-item',
                    '.job-item',
                    '.job-info',
                    '[class*="job"]',
                    '.list-item',
                    'tr',  # å¯èƒ½æ˜¯è¡¨æ ¼å½¢å¼
                ]
                
                job_elements = None
                for selector in selectors:
                    try:
                        elements = self.page.query_selector_all(selector)
                        if elements and len(elements) > 1:  # è‡³å°‘2ä¸ªï¼ˆæ’é™¤è¡¨å¤´ï¼‰
                            # è¿‡æ»¤æ‰è¡¨å¤´è¡Œ
                            if selector == 'tr':
                                filtered = [e for e in elements if e.query_selector('a[href*="job"]') or e.query_selector('a[href*="/job-"]')]
                                if filtered:
                                    job_elements = filtered
                                    print(f"    âœ“ æ‰¾åˆ° {len(job_elements)} ä¸ªèŒä½å…ƒç´ ï¼ˆé€‰æ‹©å™¨: {selector}ï¼‰")
                                    break
                            else:
                                job_elements = elements
                                print(f"    âœ“ æ‰¾åˆ° {len(job_elements)} ä¸ªèŒä½å…ƒç´ ï¼ˆé€‰æ‹©å™¨: {selector}ï¼‰")
                                break
                    except:
                        continue
                
                if not job_elements:
                    print(f"    âš  æœªæ‰¾åˆ°èŒä½åˆ—è¡¨ï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")
                    # å°è¯•è·å–é¡µé¢æ ‡é¢˜ç¡®è®¤æ˜¯å¦åŠ è½½æˆåŠŸ
                    try:
                        title = self.page.title()
                        print(f"    é¡µé¢æ ‡é¢˜: {title[:50]}")
                        # å°è¯•è·å–é¡µé¢æ–‡æœ¬ï¼Œçœ‹çœ‹æ˜¯å¦æœ‰"èŒä½"ã€"æ‹›è˜"ç­‰å…³é”®è¯
                        page_text = self.page.inner_text('body')[:200]
                        if 'èŒä½' in page_text or 'æ‹›è˜' in page_text or 'å²—ä½' in page_text:
                            print(f"    â„¹ é¡µé¢ä¼¼ä¹å·²åŠ è½½ï¼Œä½†é€‰æ‹©å™¨ä¸åŒ¹é…")
                            # å°è¯•æ›´é€šç”¨çš„é€‰æ‹©å™¨
                            all_links = self.page.query_selector_all('a[href*="job"], a[href*="/job-"]')
                            if all_links:
                                print(f"    âœ“ æ‰¾åˆ° {len(all_links)} ä¸ªèŒä½é“¾æ¥ï¼Œå°è¯•æå–...")
                                job_elements = all_links[:20]  # é™åˆ¶æ•°é‡
                    except Exception as e:
                        print(f"    âš  æ£€æŸ¥é¡µé¢æ—¶å‡ºé”™: {str(e)[:30]}")
                    
                    if not job_elements:
                        return results
                
                # æå–èŒä½ä¿¡æ¯
                for job_elem in job_elements[:15]:  # é™åˆ¶æ¯é¡µ15ä¸ª
                    try:
                        # æå–èŒä½åç§°å’Œé“¾æ¥ï¼ˆä¼˜åŒ–ï¼šä¼˜å…ˆä½¿ç”¨æœ€å¸¸è§çš„é€‰æ‹©å™¨ï¼‰
                        job_title = None
                        job_link = None
                        
                        # ä¼˜å…ˆå°è¯•é“¾æ¥å…ƒç´ ï¼ˆåº”å±Šç”Ÿæ±‚èŒç½‘çš„é“¾æ¥æ ¼å¼ï¼‰
                        try:
                            # åº”å±Šç”Ÿæ±‚èŒç½‘é€šå¸¸æ˜¯è¡¨æ ¼å½¢å¼ï¼Œé“¾æ¥åœ¨ç¬¬ä¸€åˆ—
                            link_elem = (job_elem.query_selector('td:first-child a') or 
                                        job_elem.query_selector('a[href*="/job-"]') or 
                                        job_elem.query_selector('a[href*="job"]') or 
                                        job_elem.query_selector('a'))
                            if link_elem:
                                job_title = link_elem.inner_text().strip()
                                href = link_elem.get_attribute('href')
                                if href:
                                    if href.startswith('http'):
                                        job_link = href
                                    elif href.startswith('/'):
                                        job_link = f"https://www.yingjiesheng.com{href}"
                                    else:
                                        job_link = f"https://www.yingjiesheng.com/{href}"
                        except:
                            pass
                        
                        # å¦‚æœä¸Šé¢æ²¡æ‰¾åˆ°ï¼Œå†å°è¯•å…¶ä»–é€‰æ‹©å™¨
                        if not job_title:
                            # å°è¯•ä»è¡¨æ ¼å•å…ƒæ ¼è·å–
                            try:
                                first_td = job_elem.query_selector('td:first-child')
                                if first_td:
                                    job_title = first_td.inner_text().strip()
                                    link = first_td.query_selector('a')
                                    if link and not job_link:
                                        href = link.get_attribute('href')
                                        if href:
                                            if href.startswith('http'):
                                                job_link = href
                                            elif href.startswith('/'):
                                                job_link = f"https://www.yingjiesheng.com{href}"
                                            else:
                                                job_link = f"https://www.yingjiesheng.com/{href}"
                            except:
                                pass
                            
                            # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–é€‰æ‹©å™¨
                            if not job_title:
                                title_selectors = ['.job-name', '.job-title', '.title', 'h3', 'h4', '[class*="job-name"]', '[class*="title"]']
                                for sel in title_selectors[:3]:
                                    try:
                                        elem = job_elem.query_selector(sel)
                                        if elem:
                                            job_title = elem.inner_text().strip()
                                            break
                                    except:
                                        continue
                        
                        if not job_title or not job_link:
                            continue
                        
                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                        if self.db.is_job_exists(job_link):
                            continue
                        
                        # æå–å…¬å¸åç§°ï¼ˆåº”å±Šç”Ÿæ±‚èŒç½‘é€šå¸¸æ˜¯è¡¨æ ¼ï¼Œå…¬å¸ååœ¨ç¬¬äºŒåˆ—ï¼‰
                        company_name = 'æœªçŸ¥'
                        try:
                            # ä¼˜å…ˆå°è¯•è¡¨æ ¼ç¬¬äºŒåˆ—
                            company_td = job_elem.query_selector('td:nth-child(2)')
                            if company_td:
                                company_name = company_td.inner_text().strip()
                        except:
                            pass
                        
                        if company_name == 'æœªçŸ¥' or not company_name:
                            company_selectors = ['.company-name', '.company', '[class*="company"]', '.firm-name', '.employer']
                            for sel in company_selectors[:3]:
                                try:
                                    elem = job_elem.query_selector(sel)
                                    if elem:
                                        company_name = elem.inner_text().strip()
                                        if company_name:
                                            break
                                except:
                                    continue
                        
                        # æå–å·¥ä½œåœ°ç‚¹ï¼ˆåº”å±Šç”Ÿæ±‚èŒç½‘é€šå¸¸æ˜¯è¡¨æ ¼ï¼Œåœ°ç‚¹åœ¨ç¬¬ä¸‰åˆ—ï¼‰
                        work_location = city  # é»˜è®¤ä½¿ç”¨æœç´¢çš„åŸå¸‚
                        try:
                            location_td = job_elem.query_selector('td:nth-child(3)')
                            if location_td:
                                work_location = location_td.inner_text().strip()
                        except:
                            pass
                        
                        if not work_location or work_location == city:
                            location_selectors = ['.city', '.location', '[class*="city"]', '[class*="location"]', '.work-place']
                            for sel in location_selectors[:3]:
                                try:
                                    elem = job_elem.query_selector(sel)
                                    if elem:
                                        work_location = elem.inner_text().strip()
                                        if work_location:
                                            break
                                except:
                                    continue
                        
                        # æå–æ›´æ–°æ—¶é—´ï¼ˆåº”å±Šç”Ÿæ±‚èŒç½‘é€šå¸¸æ˜¯è¡¨æ ¼ï¼Œæ—¶é—´åœ¨ç¬¬å››åˆ—ï¼‰
                        update_time = 'æœªçŸ¥'
                        try:
                            time_td = job_elem.query_selector('td:nth-child(4)')
                            if time_td:
                                update_time = time_td.inner_text().strip()
                        except:
                            pass
                        
                        if not update_time or update_time == 'æœªçŸ¥':
                            time_selectors = ['.update-time', '.time', '.publish-time', '[class*="time"]', '[class*="update"]']
                            for sel in time_selectors[:3]:
                                try:
                                    elem = job_elem.query_selector(sel)
                                    if elem:
                                        update_time = elem.inner_text().strip()
                                        if update_time:
                                            break
                                except:
                                    continue
                        
                        # åˆ¤æ–­æ‹›è˜ç±»å‹
                        if 'å®ä¹ ' in job_title or 'å®ä¹ ' in company_name:
                            recruit_type_str = 'å®ä¹ '
                        elif recruit_type == 'ç¤¾æ‹›':
                            recruit_type_str = 'ç¤¾æ‹›'
                        else:
                            recruit_type_str = 'æ ¡æ‹›'
                        
                        # æ‹›è˜å¯¹è±¡
                        if grad_year:
                            if isinstance(grad_year, list):
                                recruit_target = f"{'/'.join(map(str, grad_year))}å±Š"
                            else:
                                recruit_target = f"{grad_year}å±Š"
                        else:
                            recruit_target = 'ä¸é™'
                        
                        # å…¬å¸ç±»å‹ï¼ˆåˆ—è¡¨é¡µé€šå¸¸æ²¡æœ‰ï¼Œè®¾ä¸ºæœªçŸ¥ï¼Œåç»­å¯è¿›å…¥è¯¦æƒ…é¡µè·å–ï¼‰
                        company_type = 'æœªçŸ¥'
                        
                        # æŠ•é€’æˆªæ­¢ï¼ˆåˆ—è¡¨é¡µé€šå¸¸æ²¡æœ‰ï¼Œè®¾ä¸ºé»˜è®¤å€¼ï¼‰
                        deadline = 'è¯¦è§é“¾æ¥'
                        
                        # æ„å»ºå®Œæ•´çš„å²—ä½æ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰9ä¸ªå­—æ®µï¼‰
                        job_data = {
                            'url': job_link,
                            'company_name': company_name,
                            'company_type': company_type,
                            'work_location': work_location,
                            'recruit_type': recruit_type_str,
                            'recruit_target': recruit_target,
                            'job_title': job_title,
                            'update_time': update_time,
                            'deadline': deadline,
                            'config_keywords': config_keywords,  # ç”¨äºæ¶ˆæ¯åˆ†ç»„
                        }
                        
                        # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆåŒ…å«æ‰€æœ‰å­—æ®µï¼‰
                        self.db.save_job({
                            'url': job_link,
                            'company_name': company_name,
                            'company_type': company_type,
                            'work_location': work_location,
                            'recruit_type': recruit_type_str,
                            'recruit_target': recruit_target,
                            'job_title': job_title,
                            'update_time': update_time,
                            'deadline': deadline,
                        })
                        
                        results.append(job_data)
                        
                    except Exception as e:
                        continue
                
            except Exception as e:
                print(f"    âš  è§£æé¡µé¢æ—¶å‡ºé”™: {str(e)[:50]}")
        
        except Exception as e:
            print(f"    âœ— æœç´¢æ—¶å‡ºé”™: {str(e)[:50]}")
        
        return results
    
    def scrape_all_configs(self) -> List[Dict]:
        """æŠ“å–æ‰€æœ‰é…ç½®çš„å²—ä½"""
        all_new_jobs = []
        
        total_configs = len(SEARCH_CONFIGS)
        print(f"\nå¼€å§‹æŠ“å–ï¼Œå…± {total_configs} ä¸ªé…ç½®...")
        
        for idx, config in enumerate(SEARCH_CONFIGS, 1):
            try:
                print(f"\n[{idx}/{total_configs}] å¤„ç†é…ç½®: {', '.join(config['keywords'][:2])}...")
                
                # å±•å¼€åŸå¸‚åˆ—è¡¨
                cities = self.expand_city_list(config['locations'])
                keywords = config['keywords']
                grad_year = config['grad_year']
                recruit_type = config['recruit_type']
                config_keywords = ', '.join(keywords[:3])
                
                # éå†å…³é”®è¯å’ŒåŸå¸‚
                for keyword in keywords:
                    for city in cities:
                        if recruit_type == 'æ ¡æ‹›' or 'æ ¡æ‹›' in recruit_type or grad_year or recruit_type == 'å®ä¹ ':
                            # ä½¿ç”¨åº”å±Šç”Ÿæ±‚èŒç½‘æŠ“å–
                            jobs = self.search_yingjiesheng(keyword, city, grad_year, recruit_type, config_keywords)
                            all_new_jobs.extend(jobs)
                            self.random_sleep(0.5, 1.5)  # å¿«é€Ÿæ¨¡å¼ï¼šå‡å°‘ç­‰å¾…æ—¶é—´
                
                print(f"  âœ“ æœ¬é…ç½®æ–°å¢ {len([j for j in all_new_jobs if j.get('config_keywords') == config_keywords])} ä¸ªå²—ä½")
                
            except Exception as e:
                print(f"  âœ— å¤„ç†é…ç½®æ—¶å‡ºé”™: {str(e)[:100]}")
                continue
        
        return all_new_jobs


# ==================== è°ƒåº¦æ¨¡å— ====================

class Scheduler:
    """å®šæ—¶è°ƒåº¦å™¨"""
    
    def __init__(self, db_manager: DBManager, dingtalk_sender: DingTalkSender):
        """åˆå§‹åŒ–è°ƒåº¦å™¨"""
        self.db = db_manager
        self.dingtalk = dingtalk_sender
        self.scraper = None
    
    def export_to_excel(self) -> Optional[str]:
        """å¯¼å‡ºæ‰€æœ‰å²—ä½åˆ°Excelæ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰9ä¸ªå­—æ®µï¼‰"""
        try:
            conn = sqlite3.connect(DB_FILE)
            df = pd.read_sql_query("""
                SELECT 
                    company_name as 'å…¬å¸åç§°',
                    company_type as 'å…¬å¸ç±»å‹',
                    work_location as 'å·¥ä½œåœ°ç‚¹',
                    recruit_type as 'æ‹›è˜ç±»å‹',
                    recruit_target as 'æ‹›è˜å¯¹è±¡',
                    job_title as 'å²—ä½(å¤§éƒ½ä¸é™ä¸“ä¸š)',
                    update_time as 'æ›´æ–°æ—¶é—´',
                    deadline as 'æŠ•é€’æˆªæ­¢',
                    url as 'ç›¸å…³é“¾æ¥'
                FROM posted_jobs 
                ORDER BY created_at DESC
            """, conn)
            conn.close()
            
            if df.empty:
                return None
            
            # ç”Ÿæˆæ–‡ä»¶å
            excel_file = f"job_hunting_results_{datetime.now().strftime('%Y%m%d')}.xlsx"
            
            # ä¿å­˜åˆ°Excel
            df.to_excel(excel_file, index=False, engine='openpyxl')
            
            return excel_file
        except Exception as e:
            print(f"âš  å¯¼å‡ºExcelæ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def run_once(self):
        """æ‰§è¡Œä¸€æ¬¡æŠ“å–ä»»åŠ¡"""
        print("\n" + "="*60)
        print(f"å¼€å§‹æ‰§è¡ŒæŠ“å–ä»»åŠ¡ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)
        
        try:
            # åˆå§‹åŒ–çˆ¬è™«
            self.scraper = JobScraper(self.db)
            self.scraper.start_browser(headless=True)
            
            # æŠ“å–æ‰€æœ‰é…ç½®
            new_jobs = self.scraper.scrape_all_configs()
            
            # å…³é—­æµè§ˆå™¨
            self.scraper.close_browser()
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_count = self.db.get_total_count()
            
            print(f"\nâœ“ æŠ“å–å®Œæˆ: æ–°å¢ {len(new_jobs)} ä¸ªå²—ä½ï¼Œæ•°æ®åº“æ€»è®¡ {total_count} ä¸ª")
            
            # å¯¼å‡ºExcelæ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰å²—ä½ï¼‰
            excel_file = self.export_to_excel()
            if excel_file:
                print(f"âœ“ Excelæ–‡ä»¶å·²ç”Ÿæˆ: {excel_file}")
            
            # å‘é€é’‰é’‰é€šçŸ¥ï¼ˆåªå‘é€æ¶ˆæ¯å¡ç‰‡ï¼ŒExcelæ–‡ä»¶ä¿¡æ¯ä¸å‘é€ï¼‰
            if new_jobs:
                title, content = self.dingtalk.format_jobs_message(new_jobs, total_count, excel_file)
                if title and content:
                    # åªå‘é€æ¶ˆæ¯å¡ç‰‡
                    self.dingtalk.send_markdown(title, content)
                    if excel_file:
                        print(f"âœ“ Excelæ–‡ä»¶å·²ä¿å­˜åˆ°æœ¬åœ°: {excel_file}")
            else:
                print("â„¹ æœ¬æ¬¡æ— æ–°å¢å²—ä½ï¼Œä¸å‘é€é€šçŸ¥")
            
        except Exception as e:
            print(f"\nâœ— æ‰§è¡Œä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
        finally:
            if self.scraper:
                self.scraper.close_browser()
    
    def run_forever(self):
        """æŒç»­è¿è¡Œè°ƒåº¦å™¨"""
        print("\n" + "="*60)
        print("æ‹›è˜å²—ä½å®šæ—¶æŠ“å–æœåŠ¡å·²å¯åŠ¨")
        print("="*60)
        print(f"æŠ“å–é—´éš”: {SCRAPE_INTERVAL // 3600} å°æ—¶")
        print(f"ä¸‹æ¬¡è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)
        print("\næç¤º: æŒ‰ Ctrl+C å¯åœæ­¢æœåŠ¡\n")
        
        # ç«‹å³æ‰§è¡Œä¸€æ¬¡
        self.run_once()
        
        # å®šæ—¶æ‰§è¡Œ
        while True:
            try:
                # ç­‰å¾…æŒ‡å®šæ—¶é—´
                print(f"\nç­‰å¾… {SCRAPE_INTERVAL // 3600} å°æ—¶åæ‰§è¡Œä¸‹ä¸€æ¬¡æŠ“å–...")
                time.sleep(SCRAPE_INTERVAL)
                
                # æ‰§è¡Œä»»åŠ¡
                self.run_once()
                
            except KeyboardInterrupt:
                print("\n\næ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
                break
            except Exception as e:
                print(f"\nâœ— è°ƒåº¦å™¨å‡ºé”™: {str(e)}")
                import traceback
                traceback.print_exc()
                print(f"\nç­‰å¾… {SCRAPE_INTERVAL // 3600} å°æ—¶åé‡è¯•...")
                time.sleep(SCRAPE_INTERVAL)


# ==================== ä¸»ç¨‹åº ====================

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*60)
    print("æ‹›è˜å²—ä½å®šæ—¶æŠ“å–ä¸é’‰é’‰æ¨é€è„šæœ¬")
    print("="*60)
    print("\nâš ï¸  é‡è¦æç¤º: è¯·åŠ¡å¿…ä¿ç®¡å¥½ä½ çš„ DingTalk Tokenï¼")
    print("\nå®‰è£…ä¾èµ–:")
    print("  pip install playwright schedule requests")
    print("\nå®‰è£…Playwrightæµè§ˆå™¨:")
    print("  playwright install chromium")
    print("="*60)
    
    # åˆå§‹åŒ–ç»„ä»¶
    db_manager = DBManager()
    dingtalk_sender = DingTalkSender()
    scheduler = Scheduler(db_manager, dingtalk_sender)
    
    # å¯åŠ¨è°ƒåº¦å™¨
    try:
        scheduler.run_forever()
    except KeyboardInterrupt:
        print("\n\nç¨‹åºå·²åœæ­¢")
    except Exception as e:
        print(f"\nç¨‹åºå¼‚å¸¸é€€å‡º: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

