#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ·é©¬èŒåŠ Â·å¸‚åœºé›·è¾¾æ—¥æŠ¥
åŸºäº DrissionPage + é˜¿é‡Œé€šä¹‰åƒé—® (Qwen) çš„å¸‚åœºæƒ…æŠ¥è‡ªåŠ¨åŒ–ç³»ç»Ÿ

================================================================================
ã€é‡è¦ã€‘è¿è¡Œå‰å¿…é¡»æ“ä½œï¼šå¯åŠ¨ Chrome è°ƒè¯•æ¨¡å¼
================================================================================

å°çº¢ä¹¦é‡‡é›†éœ€è¦æ¥ç®¡æ‚¨æœ¬åœ°å·²ç™»å½•çš„ Chrome æµè§ˆå™¨ï¼Œè¯·å…ˆæ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

ã€Mac ç³»ç»Ÿã€‘
åœ¨ç»ˆç«¯æ‰§è¡Œï¼š
    open -n /Applications/Google\ Chrome.app --args --remote-debugging-port=9222

ã€Windows ç³»ç»Ÿã€‘
åœ¨å‘½ä»¤æç¤ºç¬¦ï¼ˆCMDï¼‰æˆ– PowerShell æ‰§è¡Œï¼š
    "C:\Program Files\Google\Chrome\Application\chrome.exe" --remote-debugging-port=9222

ã€Linux ç³»ç»Ÿã€‘
åœ¨ç»ˆç«¯æ‰§è¡Œï¼š
    google-chrome --remote-debugging-port=9222

æ‰§è¡Œåï¼ŒChrome ä¼šä»¥è°ƒè¯•æ¨¡å¼å¯åŠ¨ï¼Œç„¶åï¼š
1. æ‰‹åŠ¨ç™»å½•å°çº¢ä¹¦è´¦å·ï¼ˆhttps://www.xiaohongshu.comï¼‰
2. ä¿æŒ Chrome æµè§ˆå™¨æ‰“å¼€çŠ¶æ€
3. å†è¿è¡Œæœ¬è„šæœ¬

å¦‚æœå¿˜è®°å¯åŠ¨è°ƒè¯•æ¨¡å¼ï¼Œè„šæœ¬ä¼šæç¤ºé”™è¯¯å¹¶é€€å‡ºã€‚
================================================================================
"""

import json
import time
import random
import re
import os
import platform
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from DrissionPage import ChromiumPage, ChromiumOptions
import dashscope
from dashscope import Generation
import logging

# å¯¼å…¥å¤‡ç”¨æ–¹æ¡ˆæ‰€éœ€çš„åº“
try:
    import requests
    from bs4 import BeautifulSoup
    BING_BACKUP_AVAILABLE = True
except ImportError:
    BING_BACKUP_AVAILABLE = False
    logger.warning("requests æˆ– BeautifulSoup æœªå®‰è£…ï¼ŒBing å¤‡ç”¨æ–¹æ¡ˆä¸å¯ç”¨")

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('market_radar_qwen.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==================== ç¡¬ç¼–ç é…ç½® ====================
# é˜¿é‡Œé€šä¹‰åƒé—® API Key
DASHSCOPE_API_KEY = "sk-668c28bae516493d9ea8a3662118ec98"

# ==================== ä¼˜åŒ–åçš„å…³é”®è¯é…ç½® ====================
# ä½¿ç”¨ç»„åˆå…³é”®è¯æœç´¢ï¼Œé¿å…åŒ¹é…åˆ°æ— å…³å†…å®¹ï¼ˆå’–å•¡ã€é‹å­ç­‰ï¼‰

# ç«å“å“ç‰Œç»„åˆæœç´¢å…³é”®è¯
SEARCH_QUERIES = {
    'è·¯è§…': [
        'è·¯è§…ç•™å­¦',
        'è·¯è§…è¾…å¯¼',
        'è·¯è§…ç½‘è¯¾',
        'è·¯è§…ä½œä¸šè¾…å¯¼',
        'è·¯è§…è®ºæ–‡',
        'è·¯è§…è¯¾ç¨‹',
        'è·¯è§… æŒ‚ç§‘',
        'è·¯è§… GPA'
    ],
    'è€ƒè€Œæ€': [
        'è€ƒè€Œæ€ç•™å­¦',
        'è€ƒè€Œæ€è¾…å¯¼',
        'è€ƒè€Œæ€ç½‘è¯¾',
        'è€ƒè€Œæ€æ€ä¹ˆæ ·',
        'è€ƒè€Œæ€è¯¾ç¨‹',
        'è€ƒè€Œæ€ é€€è´¹'
    ],
    'è¾…æ— å¿§': [
        'è¾…æ— å¿§ç•™å­¦',
        'è¾…æ— å¿§è¾…å¯¼',
        'è¾…æ— å¿§ç½‘è¯¾',
        'è¾…æ— å¿§æ€ä¹ˆæ ·',
        'è¾…æ— å¿§è®ºæ–‡'
    ],
    'ä¸‡èƒ½ç­é•¿': [
        'ä¸‡èƒ½ç­é•¿ç•™å­¦',
        'ä¸‡èƒ½ç­é•¿è¾…å¯¼',
        'ä¸‡èƒ½ç­é•¿ç½‘è¯¾',
        'ä¸‡èƒ½ç­é•¿æ€ä¹ˆæ ·'
    ],
    'æµ·é©¬è¯¾å ‚': [
        'æµ·é©¬è¯¾å ‚',
        'æµ·é©¬è¯¾å ‚æ€ä¹ˆæ ·',
        'æµ·é©¬è¯¾å ‚è¾…å¯¼',
        'æµ·é©¬è¯¾å ‚è®ºæ–‡',
        'æµ·é©¬è¯¾å ‚ é€€è´¹',
        'æµ·é©¬è¯¾å ‚ é¿é›·'
    ]
}

# ç«å“å“ç‰Œåˆ—è¡¨ï¼ˆç”¨äºéå†ï¼‰
KEYWORDS = list(SEARCH_QUERIES.keys())

# ==================== Chromeç”¨æˆ·æ•°æ®ç›®å½•é…ç½® ====================
# ä½¿ç”¨å·²ç™»å½•çš„Chromeé…ç½®ï¼ˆåçˆ¬ç­–ç•¥ï¼‰

if platform.system() == 'Darwin':  # Mac
    CHROME_USER_DATA_DIR = os.path.expanduser("~/Library/Application Support/Google/Chrome")
elif platform.system() == 'Windows':
    CHROME_USER_DATA_DIR = os.path.expanduser("~/AppData/Local/Google/Chrome/User Data")
else:  # Linux
    CHROME_USER_DATA_DIR = os.path.expanduser("~/.config/google-chrome")

CHROME_PROFILE = "Default"  # æˆ– "Profile 1", "Profile 2" ç­‰

# ==================== ç•™å­¦è¾…å¯¼èµ›é“ä¸“å±å…³é”®è¯ï¼ˆæ”¾å®½ç‰ˆï¼‰ ====================
# å¿…é¡»å‘½ä¸­ä»¥ä¸‹å…³é”®è¯ä¹‹ä¸€ï¼Œæ‰è®¤ä¸ºæ˜¯ç•™å­¦è¾…å¯¼ç›¸å…³å†…å®¹

STUDY_ABROAD_KEYWORDS = [
    # æ ¸å¿ƒè¯ï¼ˆæ”¾å®½ï¼‰
    'ç•™å­¦', 'è¾…å¯¼', 'ç½‘è¯¾', 'è®ºæ–‡', 'ä½œä¸š', 'è¯¾ç¨‹',
    'æ•™è‚²', 'åŸ¹è®­', 'å­¦æœ¯', 'è€ƒè¯•', 'è¡¥ä¹ ',
    
    # åœ°åŒº
    'è‹±å›½', 'æ¾³æ´²', 'ç¾å›½', 'åŠ æ‹¿å¤§', 'é¦™æ¸¯', 'æ–°åŠ å¡',
    'æ¾³å¤§åˆ©äºš', 'è‹±è”é‚¦', 'æµ·å¤–',
    
    # å­¦æ ¡ç±»å‹
    'å¤§å­¦', 'æœ¬ç§‘', 'ç¡•å£«', 'ç ”ç©¶ç”Ÿ', 'Master', 'PhD', 'åšå£«',
    'University', 'College', 'ç•™å­¦ç”Ÿ',
    
    # å…·ä½“å­¦æ ¡ï¼ˆå¸¸è§ï¼‰
    'æ‚‰å°¼', 'å¢¨å°”æœ¬', 'UNSW', 'ANU', 'UQ', 'è«çº³ä»€', 'æ–°å—',
    'å¸å›½ç†å·¥', 'UCL', 'KCL', 'LSE', 'æ›¼å¤§', 'çˆ±ä¸å ¡', 'åå¨',
    'å¤šä¼¦å¤š', 'UBC', 'éº¦å‰å°”', 'æ»‘é“å¢',
    'æ¸¯å¤§', 'æ¸¯ä¸­æ–‡', 'æ¸¯ç§‘æŠ€', 'NUS', 'NTU', 'æ¸¯ç†å·¥',
    
    # æœåŠ¡ç±»å‹ï¼ˆç•™å­¦ä¸“å±ï¼‰
    'è®ºæ–‡è¾…å¯¼', 'ç½‘è¯¾è¾…å¯¼', 'è¯¾ç¨‹è¾…å¯¼', 'ä½œä¸šè¾…å¯¼', 'è€ƒå‰è¾…å¯¼',
    'GPA', 'å­¦åˆ†', 'æŒ‚ç§‘', 'è¡¥è€ƒ', 'Appeal', 'ç”³è¯‰',
    'è¯¾ä¸š', 'å­¦æœ¯', 'ç•™å­¦ç”Ÿè¾…å¯¼',
    
    # å­¦ç§‘ï¼ˆç•™å­¦ç”Ÿå¸¸è§ï¼‰
    'å•†ç§‘', 'ä¼šè®¡', 'é‡‘è', 'Economics', 'ç»æµå­¦',
    'è®¡ç®—æœº', 'CS', 'å·¥ç¨‹', 'Engineering', 'IT',
    'ç»Ÿè®¡', 'æ•°å­¦',
    
    # è¯„ä»·ç›¸å…³ï¼ˆæ”¾å®½ï¼‰
    'æ€ä¹ˆæ ·', 'é è°±', 'æ¨è', 'å¥½ä¸å¥½', 'è¯„ä»·',
    'çœŸå®', 'ä½“éªŒ', 'é¿é›·', 'å£ç¢‘',
]

# å›½å†…è€ƒè¯èµ›é“ï¼ˆå¿…é¡»æ’é™¤ï¼‰
DOMESTIC_EXAM_KEYWORDS = [
    'åŸºé‡‘ä»ä¸š', 'è¯åˆ¸ä»ä¸š', 'é“¶è¡Œä»ä¸š', 'æœŸè´§ä»ä¸š',
    'ä¼šè®¡å¸ˆ', 'CPA', 'ç¨åŠ¡å¸ˆ', 'å®¡è®¡å¸ˆ', 'ACCA',
    'æ•™å¸ˆèµ„æ ¼', 'æ•™èµ„', 'æ™®é€šè¯',
    'å…¬åŠ¡å‘˜', 'äº‹ä¸šå•ä½', 'è€ƒç¼–', 'å›½è€ƒ', 'çœè€ƒ',
    'è€ƒç ”', 'å››å…­çº§', 'CET', 'è‹±è¯­å››å…­çº§',
    'é©¾ç…§', 'é©¾è€ƒ',
    'å¥åº·ç®¡ç†å¸ˆ', 'å¿ƒç†å’¨è¯¢å¸ˆ', 'è¥å…»å¸ˆ',
    'å»ºé€ å¸ˆ', 'é€ ä»·å¸ˆ', 'ç›‘ç†å·¥ç¨‹å¸ˆ',
]

# æ•™è‚²ç›¸å…³å…³é”®è¯ï¼ˆé€šç”¨ï¼Œç”¨äºåŸºç¡€è¿‡æ»¤ï¼‰
EDUCATION_KEYWORDS = STUDY_ABROAD_KEYWORDS + [
    # æœåŠ¡ç±»å‹ï¼ˆé€šç”¨ï¼‰
    'è¾…å¯¼', 'ç½‘è¯¾', 'è®ºæ–‡', 'ä½œä¸š', 'è¯¾ç¨‹', 'è¡¥ä¹ ',
    'å­¦æœ¯', 'è€ƒè¯•', 'æŒ‚ç§‘', 'GPA', 'å­¦åˆ†', 'æ¯•ä¸š', 'ç­”ç–‘',
    # è¯„ä»·ç›¸å…³
    'é è°±', 'æ€ä¹ˆæ ·', 'å¥½ä¸å¥½', 'æ¨è', 'é¿é›·', 'è¸©å‘',
    'é€€è´¹', 'é€€æ¬¾', 'ä»·æ ¼', 'æ”¶è´¹', 'å¯¼å¸ˆ', 'è€å¸ˆ', 'æ•™æˆ'
]

# å¿…é¡»æ’é™¤çš„å¹²æ‰°è¯ï¼ˆå‘½ä¸­ä»»æ„1ä¸ªå°±ä¸¢å¼ƒï¼‰
EXCLUDE_KEYWORDS = [
    'å’–å•¡', 'å¾·è®­é‹', 'é‹å­', 'ç©¿æ­', 'å¾’æ­¥', 'éª‘è¡Œ',
    'èŒ¶è·¯', 'é…’ä¸š', 'æ—…æ¸¸', 'æ™¯åŒº', 'ç¾é£Ÿ', 'é¤å…',
    'æ‰‹æœº', 'iPhone', 'æ•°ç ', 'æŠ¤è‚¤', 'ç¾å¦†', 'æœè£…',
    'å“ç‰Œ', 'è”å', 'ç§è‰', 'å¼€ç®±', 'æµ‹è¯„', 'OOTD'
]

# ==================== å“ç‰Œæ¶ˆæ­§é…ç½® ====================
# ç²¾å‡†åˆ¤æ–­æ˜¯å¦æ˜¯ç›®æ ‡å“ç‰Œçš„æ•™è‚²å†…å®¹ï¼Œæ’é™¤åŒåä½†ä¸åŒä¸šåŠ¡çš„å“ç‰Œ

BRAND_DISAMBIGUATION = {
    'è·¯è§…': {
        # æˆ‘ä»¬è¦æ‰¾çš„ï¼šç•™å­¦è¾…å¯¼æœºæ„
        'target_context': ['ç•™å­¦', 'è¾…å¯¼', 'ç½‘è¯¾', 'è®ºæ–‡', 'ä½œä¸š', 'è€ƒè¯•', 'GPA', 'è¡¥ä¹ ', 'è¯¾ç¨‹', 'å­¦æœ¯'],
        # éœ€è¦æ’é™¤çš„åŒåå“ç‰Œ/å†…å®¹
        'exclude_patterns': [
            'è·¯è§…æ–¯',      # å¾·è®­é‹å“ç‰Œ
            'LUMES',       # å¾·è®­é‹è‹±æ–‡
            'å¾·è®­é‹',
            'å’–å•¡',
            'å’–å•¡è½¦',
            'èŒ¶è·¯è§…',      # èŒ¶æ–‡åŒ–
            'ä¸‡é‡ŒèŒ¶è·¯',
            'ä¹”å®¶å¤§é™¢',
            'é…’ä¸š',
            'å¾’æ­¥',
            'éª‘è¡Œ',
            'ç©¿æ­',
            'OOTD',
        ]
    },
    'è€ƒè€Œæ€': {
        'target_context': ['ç•™å­¦', 'è¾…å¯¼', 'å¤§å­¦', 'ç¡•å£«', 'è®ºæ–‡', 'ç½‘è¯¾', 'è¯¾ç¨‹', 'è€ƒè¯•'],
        'exclude_patterns': []  # è¿™ä¸ªå“ç‰Œåæ¯”è¾ƒç‹¬ç‰¹ï¼Œå¹²æ‰°å°‘
    },
    'è¾…æ— å¿§': {
        'target_context': ['ç•™å­¦', 'è¾…å¯¼', 'å¤§å­¦', 'ç¡•å£«', 'è®ºæ–‡', 'ç½‘è¯¾', 'è¯¾ç¨‹', 'è€ƒè¯•'],
        'exclude_patterns': [
            'æ£€è½¦æ— å¿§',   # æ±½è½¦æœåŠ¡
            'å€ºè½¦æ— å¿§',
            'æ·è½¦æ— å¿§',
            'äººè½¦æ— å¿§',
        ]
    },
    'ä¸‡èƒ½ç­é•¿': {
        'target_context': ['ç•™å­¦', 'è¾…å¯¼', 'å¤§å­¦', 'æ¾³æ´²', 'è‹±å›½', 'è®ºæ–‡', 'ç½‘è¯¾', 'è¯¾ç¨‹'],
        'exclude_patterns': [
            'å°å­¦',
            'ä¸­å­¦',
            'ç­é•¿ç«é€‰',
            'ç­çº§',
        ]
    },
    'æµ·é©¬è¯¾å ‚': {
        'target_context': ['ç•™å­¦', 'è¾…å¯¼', 'è®ºæ–‡', 'ç½‘è¯¾', 'GPA', 'è¯¾ç¨‹', 'è€ƒè¯•'],
        'exclude_patterns': [
            'æµ·é©¬ä½“',      # è„‘ç§‘å­¦
            'æµ·é©¬æ±½è½¦',
        ]
    }
}

# å…¨å±€é»‘åå•ï¼ˆä»»ä½•å“ç‰Œéƒ½æ’é™¤ï¼‰
GLOBAL_BLACKLIST = [
    # æœè£…/é‹ç±»
    'å¾·è®­é‹', 'é‹å­', 'ç©¿æ­', 'OOTD', 'æœè£…', 'è¡£æœ', 'LUMES', 'è·¯è§…æ–¯',
    # é¤é¥®/æ—…æ¸¸
    'å’–å•¡', 'é¤å…', 'ç¾é£Ÿ', 'å¾’æ­¥', 'éª‘è¡Œ', 'æ—…æ¸¸', 'æ™¯åŒº', 'èŒ¶è·¯', 'é…’ä¸š', 'ä¹”å®¶å¤§é™¢',
    # æ•°ç /3C
    'iPhone', 'æ‰‹æœº', 'æ•°ç ', 'ç§‘æŠ€',
    # K12æ•™è‚²ï¼ˆæˆ‘ä»¬æ˜¯ç•™å­¦èµ›é“ï¼‰
    'å°å‡åˆ', 'ä¸­å°å­¦', 'å¹¼å„¿å›­', 'å°å­¦', 'åˆä¸­', 'é«˜ä¸­', 'çº¢é¢†å·¾å¥–ç« ', 'å°‘å…ˆé˜Ÿ', 'å…¥å›¢', 'ç­ä¸»ä»»',
    'è¡èµ·åŒæ¡¨', 'ç«¥å¹´', 'ç«¥å£°',
    # å…¶ä»–æ— å…³
    'æµ·é©¬ä½“', 'æµ·é©¬æ±½è½¦', 'çˆ¬å±±', 'å¼‚æ€§',
]

# æ—¶é—´èŒƒå›´ï¼ˆæœ€è¿‘ä¸€å‘¨ï¼‰
DAYS_BACK = 7
CURRENT_DATE = datetime.now().strftime("%Y-%m-%d")


class MarketRadarHaimaClassroom:
    """å¸‚åœºé›·è¾¾ç³»ç»Ÿï¼ˆåŸºäº Qwenï¼‰"""
    
    def __init__(self, use_debug_port: bool = True):
        """
        åˆå§‹åŒ–æµè§ˆå™¨å’Œ AI å®¢æˆ·ç«¯
        
        Args:
            use_debug_port: æ˜¯å¦ä½¿ç”¨è°ƒè¯•ç«¯å£è¿æ¥å·²æ‰“å¼€çš„ Chromeï¼ˆç”¨äºå°çº¢ä¹¦é‡‡é›†ï¼‰
        """
        # é…ç½® DashScope
        dashscope.api_key = DASHSCOPE_API_KEY
        logger.info("é˜¿é‡Œé€šä¹‰åƒé—® (Qwen) åˆå§‹åŒ–æˆåŠŸ")
        
        # é…ç½®æµè§ˆå™¨ï¼ˆä½¿ç”¨å·²ç™»å½•çš„Chromeé…ç½® - åçˆ¬ç­–ç•¥ï¼‰
        try:
            if use_debug_port:
                # å°è¯•è¿æ¥æœ¬åœ° 9222 ç«¯å£çš„ Chromeï¼ˆç”¨äºå°çº¢ä¹¦é‡‡é›†ï¼‰
                try:
                    self.page = ChromiumPage(addr='127.0.0.1:9222')
                    logger.info("æˆåŠŸè¿æ¥åˆ°æœ¬åœ° Chrome è°ƒè¯•ç«¯å£ (9222)")
                    logger.info("æç¤ºï¼šè¯·ç¡®ä¿ Chrome å·²ä»¥è°ƒè¯•æ¨¡å¼å¯åŠ¨ï¼Œå¹¶å·²ç™»å½•å°çº¢ä¹¦è´¦å·")
                    # æ³¨å…¥åæ£€æµ‹JS
                    self._inject_anti_detect()
                except Exception as e:
                    logger.warning(f"è¿æ¥æœ¬åœ° Chrome è°ƒè¯•ç«¯å£å¤±è´¥: {str(e)}")
                    logger.warning("=" * 80)
                    logger.warning("ã€é‡è¦æç¤ºã€‘è¯·å…ˆå¯åŠ¨ Chrome è°ƒè¯•æ¨¡å¼ï¼š")
                    logger.warning("Mac: open -n /Applications/Google\\ Chrome.app --args --remote-debugging-port=9222")
                    logger.warning("Windows: \"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\" --remote-debugging-port=9222")
                    logger.warning("=" * 80)
                    # é™çº§ä¸ºä½¿ç”¨Chromeç”¨æˆ·æ•°æ®ç›®å½•
                    self._init_with_user_data()
            else:
                # ä½¿ç”¨Chromeç”¨æˆ·æ•°æ®ç›®å½•ï¼ˆå·²ç™»å½•é…ç½®ï¼‰
                self._init_with_user_data()
        except Exception as e:
            logger.error(f"æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            logger.error("æç¤ºï¼šå¦‚æœé‡åˆ°è¿æ¥é”™è¯¯ï¼Œè¯·å…ˆæ‰‹åŠ¨å¯åŠ¨ Chrome è°ƒè¯•æ¨¡å¼")
            self.page = None
        
        # å­˜å‚¨é‡‡é›†çš„æ•°æ®
        self.douyin_data = []
        self.xhs_data = []
        self.wechat_data = []
        
        logger.info(f"å¸‚åœºé›·è¾¾ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œå½“å‰æ—¥æœŸ: {CURRENT_DATE}")
    
    def _init_with_user_data(self):
        """ä½¿ç”¨Chromeç”¨æˆ·æ•°æ®ç›®å½•åˆå§‹åŒ–æµè§ˆå™¨ï¼ˆåçˆ¬ç­–ç•¥ï¼‰"""
        try:
            options = ChromiumOptions()
            options.headless(False)
            
            # å…³é”®ï¼ä½¿ç”¨å·²ç™»å½•çš„Chromeé…ç½®
            # æ³¨æ„ï¼šå¦‚æœChromeæ­£åœ¨è¿è¡Œï¼Œéœ€è¦ä½¿ç”¨ä¸åŒçš„Profileæˆ–ä¸´æ—¶ç›®å½•
            if os.path.exists(CHROME_USER_DATA_DIR):
                # å°è¯•ä½¿ç”¨ä¸´æ—¶Profileç›®å½•ï¼Œé¿å…ä¸æ­£åœ¨è¿è¡Œçš„Chromeå†²çª
                # æˆ–è€…ä½¿ç”¨Profile 1ï¼ˆå¦‚æœDefaultæ­£åœ¨ä½¿ç”¨ï¼‰
                profile_to_use = CHROME_PROFILE
                
                # æ£€æŸ¥Defaultæ˜¯å¦è¢«å ç”¨ï¼Œå¦‚æœæ˜¯ï¼Œå°è¯•Profile 1
                default_lock = os.path.join(CHROME_USER_DATA_DIR, CHROME_PROFILE, 'SingletonLock')
                if os.path.exists(default_lock):
                    logger.warning(f"æ£€æµ‹åˆ°Chromeå¯èƒ½æ­£åœ¨è¿è¡Œï¼Œå°è¯•ä½¿ç”¨Profile 1")
                    profile_to_use = "Profile 1"
                
                try:
                    options.set_user_data_path(CHROME_USER_DATA_DIR)
                    options.set_argument(f'--profile-directory={profile_to_use}')
                    logger.info(f"ä½¿ç”¨Chromeç”¨æˆ·æ•°æ®ç›®å½•: {CHROME_USER_DATA_DIR} (Profile: {profile_to_use})")
                except:
                    # å¦‚æœè®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
                    logger.warning("æ— æ³•è®¾ç½®ç”¨æˆ·æ•°æ®ç›®å½•ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            else:
                logger.warning(f"Chromeç”¨æˆ·æ•°æ®ç›®å½•ä¸å­˜åœ¨: {CHROME_USER_DATA_DIR}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            
            # åæ£€æµ‹è®¾ç½®
            options.set_argument('--disable-blink-features=AutomationControlled')
            options.set_argument('--disable-infobars')
            options.set_argument('--no-first-run')
            options.set_argument('--no-default-browser-check')
            
            # éšæœºçª—å£å¤§å°ï¼ˆæ¨¡æ‹ŸçœŸäººï¼‰
            width = random.randint(1200, 1600)
            height = random.randint(800, 1000)
            options.set_argument(f'--window-size={width},{height}')
            
            # å°è¯•åˆ›å»ºæµè§ˆå™¨å®ä¾‹
            try:
                self.page = ChromiumPage(addr_or_opts=options)
                # æ³¨å…¥åæ£€æµ‹JS
                self._inject_anti_detect()
                logger.info("æµè§ˆå™¨åˆå§‹åŒ–æˆåŠŸï¼ˆä½¿ç”¨å·²ç™»å½•Chromeé…ç½® + åæ£€æµ‹ï¼‰")
            except Exception as e:
                # å¦‚æœå¤±è´¥ï¼Œå¯èƒ½æ˜¯Chromeæ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨æ™®é€šæ¨¡å¼
                logger.warning(f"ä½¿ç”¨Chromeç”¨æˆ·æ•°æ®ç›®å½•åˆ›å»ºæµè§ˆå™¨å¤±è´¥: {str(e)}")
                raise
            
        except Exception as e:
            logger.warning(f"ä½¿ç”¨Chromeç”¨æˆ·æ•°æ®ç›®å½•å¤±è´¥: {str(e)}ï¼Œé™çº§ä¸ºæ™®é€šæ¨¡å¼")
            options = ChromiumOptions()
            options.headless(False)
            options.set_argument('--disable-blink-features=AutomationControlled')
            self.page = ChromiumPage(addr_or_opts=options)
            self._inject_anti_detect()
            logger.info("æµè§ˆå™¨åˆå§‹åŒ–æˆåŠŸï¼ˆæ™®é€šæ¨¡å¼ + åæ£€æµ‹ï¼‰")
    
    def _inject_anti_detect(self):
        """æ³¨å…¥åæ£€æµ‹è„šæœ¬"""
        if not self.page:
            return
        
        js = """
        Object.defineProperty(navigator, 'webdriver', {
            get: () => undefined
        });
        Object.defineProperty(navigator, 'languages', {
            get: () => ['zh-CN', 'zh', 'en']
        });
        Object.defineProperty(navigator, 'plugins', {
            get: () => [1, 2, 3, 4, 5]
        });
        window.chrome = {
            runtime: {}
        };
        """
        try:
            self.page.run_js(js)
            logger.debug("åæ£€æµ‹JSæ³¨å…¥æˆåŠŸ")
        except Exception as e:
            logger.debug(f"åæ£€æµ‹JSæ³¨å…¥å¤±è´¥: {str(e)}")
    
    def human_like_delay(self, min_sec=2, max_sec=5):
        """æ¨¡æ‹Ÿäººç±»éšæœºå»¶è¿Ÿ"""
        delay = random.uniform(min_sec, max_sec)
        # åŠ å…¥å¾®å°çš„éšæœºæ³¢åŠ¨
        delay += random.uniform(-0.5, 0.5)
        time.sleep(max(0.5, delay))
    
    def human_like_scroll(self):
        """æ¨¡æ‹Ÿäººç±»æ»šåŠ¨"""
        if not self.page:
            return
        
        for _ in range(random.randint(2, 4)):
            # éšæœºæ»šåŠ¨è·ç¦»
            scroll_distance = random.randint(200, 500)
            try:
                self.page.scroll.down(scroll_distance)
            except:
                pass
            
            # éšæœºåœé¡¿
            time.sleep(random.uniform(0.5, 1.5))
            
            # å¶å°”å¾€ä¸Šæ»šä¸€ç‚¹ï¼ˆæ›´åƒçœŸäººï¼‰
            if random.random() < 0.3:
                try:
                    self.page.scroll.up(random.randint(50, 100))
                except:
                    pass
                time.sleep(random.uniform(0.3, 0.8))
    
    def move_mouse_randomly(self):
        """éšæœºç§»åŠ¨é¼ æ ‡ï¼ˆæ›´åƒçœŸäººï¼‰"""
        if not self.page:
            return
        
        try:
            # è·å–é¡µé¢å°ºå¯¸
            width = self.page.run_js('return window.innerWidth') or 1200
            height = self.page.run_js('return window.innerHeight') or 800
            
            # éšæœºç§»åŠ¨å‡ æ¬¡
            for _ in range(random.randint(2, 5)):
                x = random.randint(100, max(200, width - 100))
                y = random.randint(100, max(200, height - 100))
                self.page.run_js(f'''
                    var event = new MouseEvent('mousemove', {{
                        'clientX': {x},
                        'clientY': {y}
                    }});
                    document.dispatchEvent(event);
                ''')
                time.sleep(random.uniform(0.1, 0.3))
        except:
            pass
    
    def parse_time(self, time_str: str) -> Optional[datetime]:
        """
        è§£ææ—¶é—´å­—ç¬¦ä¸²ï¼Œè¿”å› datetime å¯¹è±¡
        
        Args:
            time_str: æ—¶é—´å­—ç¬¦ä¸²ï¼Œå¯èƒ½æ˜¯"2å°æ—¶å‰"ã€"æ˜¨å¤©"ã€"2025-12-10"ç­‰æ ¼å¼
        
        Returns:
            datetime å¯¹è±¡ï¼Œå¦‚æœæ— æ³•è§£æè¿”å› None
        """
        if not time_str:
            return None
        
        time_str = time_str.strip()
        now = datetime.now()
        
        try:
            # å¤„ç†"Xå°æ—¶å‰"ã€"Xåˆ†é’Ÿå‰"
            if "åˆ†é’Ÿå‰" in time_str:
                match = re.search(r'(\d+)åˆ†é’Ÿå‰', time_str)
                if match:
                    minutes = int(match.group(1))
                    return now - timedelta(minutes=minutes)
            
            if "å°æ—¶å‰" in time_str:
                match = re.search(r'(\d+)å°æ—¶å‰', time_str)
                if match:
                    hours = int(match.group(1))
                    return now - timedelta(hours=hours)
            
            # å¤„ç†"æ˜¨å¤©"
            if "æ˜¨å¤©" in time_str:
                return now - timedelta(days=1)
            
            # å¤„ç†"Xå¤©å‰"
            match = re.search(r'(\d+)å¤©å‰', time_str)
            if match:
                days = int(match.group(1))
                return now - timedelta(days=days)
            
            # å¤„ç†æ ‡å‡†æ—¥æœŸæ ¼å¼ "2025-12-10"
            date_match = re.search(r'(\d{4})-(\d{1,2})-(\d{1,2})', time_str)
            if date_match:
                year, month, day = map(int, date_match.groups())
                return datetime(year, month, day)
            
            # å¤„ç†"12-10"æ ¼å¼ï¼ˆå‡è®¾æ˜¯ä»Šå¹´ï¼‰
            date_match = re.search(r'(\d{1,2})-(\d{1,2})', time_str)
            if date_match:
                month, day = map(int, date_match.groups())
                return datetime(now.year, month, day)
            
            return None
            
        except Exception as e:
            logger.warning(f"æ—¶é—´è§£æå¤±è´¥: {time_str}, é”™è¯¯: {str(e)}")
            return None
    
    def _find_videos_in_json(self, data, videos=None):
        """
        é€’å½’ä»JSONä¸­æŸ¥æ‰¾è§†é¢‘ä¿¡æ¯
        
        Args:
            data: JSONæ•°æ®ï¼ˆdictæˆ–listï¼‰
            videos: è§†é¢‘åˆ—è¡¨ï¼ˆç”¨äºé€’å½’ï¼‰
        
        Returns:
            è§†é¢‘åˆ—è¡¨
        """
        if videos is None:
            videos = []
        
        if isinstance(data, dict):
            # æ£€æŸ¥æ˜¯å¦æ˜¯è§†é¢‘å¯¹è±¡
            if 'aweme_id' in data or ('id' in data and 'desc' in data):
                videos.append(data)
            else:
                for value in data.values():
                    self._find_videos_in_json(value, videos)
        elif isinstance(data, list):
            for item in data:
                self._find_videos_in_json(item, videos)
        
        return videos
    
    def is_recent(self, time_str: str) -> bool:
        """
        åˆ¤æ–­æ—¶é—´å­—ç¬¦ä¸²æ˜¯å¦åœ¨æœ€è¿‘3å¤©å†…
        
        Args:
            time_str: æ—¶é—´å­—ç¬¦ä¸²
        
        Returns:
            æ˜¯å¦åœ¨æœ€è¿‘3å¤©å†…
        """
        parsed_time = self.parse_time(time_str)
        if not parsed_time:
            return True  # æ— æ³•è§£ææ—¶é»˜è®¤ä¿ç•™
        
        days_ago = datetime.now() - timedelta(days=DAYS_BACK)
        return parsed_time >= days_ago
    
    def is_education_related(self, title: str, content: str = "") -> bool:
        """
        åˆ¤æ–­å†…å®¹æ˜¯å¦ä¸æ•™è‚²ç›¸å…³ï¼ˆç¬¬ä¸€å±‚è¿‡æ»¤ï¼šè§„åˆ™è¿‡æ»¤ï¼‰
        
        Args:
            title: æ ‡é¢˜
            content: å†…å®¹/æ‘˜è¦
        
        Returns:
            æ˜¯å¦ä¸æ•™è‚²ç›¸å…³
        """
        if not title:
            return False
        
        text = f"{title} {content}".lower()
        
        # æ’é™¤æ˜æ˜¾æ— å…³çš„
        for kw in EXCLUDE_KEYWORDS:
            if kw in text:
                logger.debug(f"  æ’é™¤ï¼ˆåŒ…å«å¹²æ‰°è¯ '{kw}'ï¼‰: {title[:50]}")
                return False
        
        # å¿…é¡»åŒ…å«æ•™è‚²å…³é”®è¯
        for kw in EDUCATION_KEYWORDS:
            if kw in text:
                return True
        
        # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè¿”å›False
        logger.debug(f"  æ’é™¤ï¼ˆæœªåŒ…å«æ•™è‚²å…³é”®è¯ï¼‰: {title[:50]}")
        return False
    
    def is_study_abroad_content(self, title: str, content: str = "", brand: str = "") -> tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦æ˜¯ç•™å­¦è¾…å¯¼èµ›é“å†…å®¹ï¼ˆæ”¾å®½ç‰ˆè¿‡æ»¤ï¼‰
        
        Args:
            title: æ ‡é¢˜
            content: å†…å®¹/æ‘˜è¦
            brand: å“ç‰Œåï¼ˆç”¨äºåˆ¤æ–­å“ç‰Œåæ˜¯å¦åœ¨æ ‡é¢˜ä¸­ï¼‰
        
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, åŸå› è¯´æ˜)
        """
        if not title:
            return False, "æ ‡é¢˜ä¸ºç©º"
        
        text = f"{title} {content}".lower()
        title_lower = title.lower()
        
        # ç¬¬ä¸€æ­¥ï¼šæ’é™¤å›½å†…è€ƒè¯èµ›é“
        for kw in DOMESTIC_EXAM_KEYWORDS:
            if kw in text:
                return False, f"æ’é™¤: {kw}"
        
        # ç¬¬äºŒæ­¥ï¼šå¦‚æœå“ç‰Œååœ¨æ ‡é¢˜ä¸­ï¼Œç›´æ¥é€šè¿‡ï¼ˆæ”¾å®½ï¼‰
        if brand:
            brand_lower = brand.lower()
            if brand_lower in title_lower:
                return True, "å“ç‰Œååœ¨æ ‡é¢˜ä¸­"
        
        # ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥ç•™å­¦å…³é”®è¯ï¼ˆæ”¾å®½ï¼‰
        hit_keywords = []
        for kw in STUDY_ABROAD_KEYWORDS:
            if kw.lower() in text:
                hit_keywords.append(kw)
        
        if hit_keywords:
            return True, f"å‘½ä¸­: {', '.join(hit_keywords[:3])}"
        
        # ç¬¬å››æ­¥ï¼šå¦‚æœå†…å®¹è¾ƒé•¿ä¸”åŒ…å«å“ç‰Œåï¼Œä¹Ÿé€šè¿‡ï¼ˆæ”¾å®½ï¼‰
        if brand and len(text) > 50:
            brand_lower = brand.lower()
            if brand_lower in text:
                return True, "å†…å®¹è¾ƒé•¿ä¸”åŒ…å«å“ç‰Œåï¼Œä¿ç•™è§‚å¯Ÿ"
        
        return False, "æœªå‘½ä¸­å…³é”®è¯"
    
    def is_target_brand_content(self, brand_name: str, title: str, content: str = "") -> tuple[bool, str]:
        """
        ç²¾å‡†åˆ¤æ–­æ˜¯å¦æ˜¯ç›®æ ‡å“ç‰Œçš„æ•™è‚²å†…å®¹ï¼ˆå“ç‰Œæ¶ˆæ­§ï¼‰
        
        Args:
            brand_name: å“ç‰Œå
            title: æ ‡é¢˜
            content: å†…å®¹/æ‘˜è¦
        
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, åŸå› è¯´æ˜)
        """
        if not title:
            return False, "æ ‡é¢˜ä¸ºç©º"
        
        text = f"{title} {content}".lower()
        config = BRAND_DISAMBIGUATION.get(brand_name, {})
        
        # ç¬¬ä¸€æ­¥ï¼šå…¨å±€é»‘åå•è¿‡æ»¤
        for word in GLOBAL_BLACKLIST:
            if word.lower() in text:
                return False, f"å…¨å±€é»‘åå•: {word}"
        
        # ç¬¬äºŒæ­¥ï¼šå“ç‰Œä¸“å±æ’é™¤è¯
        for pattern in config.get('exclude_patterns', []):
            if pattern.lower() in text:
                return False, f"å“ç‰Œæ’é™¤è¯: {pattern}"
        
        # ç¬¬ä¸‰æ­¥ï¼šå¿…é¡»å‘½ä¸­æ•™è‚²åœºæ™¯è¯
        target_words = config.get('target_context', EDUCATION_KEYWORDS)
        hit_words = [w for w in target_words if w in text]
        
        if not hit_words:
            return False, "æœªå‘½ä¸­æ•™è‚²åœºæ™¯è¯"
        
        return True, f"å‘½ä¸­: {', '.join(hit_words[:3])}"
    
    def strict_content_filter(self, brand_name: str, item: dict) -> tuple[bool, str]:
        """
        ä¸¥æ ¼è¿‡æ»¤æ— å…³å†…å®¹ï¼ˆå››å±‚è¿‡æ»¤ï¼‰
        
        Args:
            brand_name: å“ç‰Œå
            item: æ•°æ®é¡¹
        
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, åŸå› è¯´æ˜)
        """
        title = item.get('title', '')
        content = item.get('content', '') or item.get('snippet', '')
        
        # ç¬¬ä¸€å±‚ï¼šå¿…é¡»æœ‰å®è´¨å†…å®¹
        if len(title) < 5:
            return False, "æ ‡é¢˜è¿‡çŸ­"
        
        # ç¬¬äºŒå±‚ï¼šç•™å­¦èµ›é“è¿‡æ»¤ï¼ˆæœ€é‡è¦ï¼æ’é™¤å›½å†…è€ƒè¯ï¼Œä½†æ”¾å®½æ¡ä»¶ï¼‰
        is_study_abroad, reason = self.is_study_abroad_content(title, content, brand_name)
        if not is_study_abroad:
            return False, reason
        
        # ç¬¬ä¸‰å±‚ï¼šåŸºç¡€æ•™è‚²è¿‡æ»¤ï¼ˆå¤§å¹…æ”¾å®½ï¼‰
        # å¦‚æœå·²ç»é€šè¿‡ç•™å­¦èµ›é“è¿‡æ»¤ï¼Œä¸”å“ç‰Œååœ¨æ ‡é¢˜ä¸­ï¼Œç›´æ¥è·³è¿‡åŸºç¡€æ•™è‚²è¿‡æ»¤
        if brand_name and brand_name.lower() in title.lower():
            pass  # å“ç‰Œååœ¨æ ‡é¢˜ä¸­ï¼Œç›´æ¥é€šè¿‡
        # å¦‚æœæ ‡é¢˜åŒ…å«"æ•™è‚²"ã€"è¾…å¯¼"ã€"è¯¾ç¨‹"ç­‰æ ¸å¿ƒè¯ï¼Œä¹Ÿç›´æ¥é€šè¿‡
        elif any(kw in title.lower() for kw in ['æ•™è‚²', 'è¾…å¯¼', 'è¯¾ç¨‹', 'åŸ¹è®­', 'å­¦ä¹ ', 'æ•™å­¦']):
            pass  # åŒ…å«æ ¸å¿ƒæ•™è‚²è¯ï¼Œç›´æ¥é€šè¿‡
        elif not self.is_education_related(title, content):
            # å…¶ä»–æƒ…å†µæ‰è¿›è¡ŒåŸºç¡€æ•™è‚²è¿‡æ»¤
            return False, "æœªé€šè¿‡åŸºç¡€æ•™è‚²è¿‡æ»¤"
        
        # ç¬¬å››å±‚ï¼šå“ç‰Œæ¶ˆæ­§è¿‡æ»¤
        is_valid, reason = self.is_target_brand_content(brand_name, title, content)
        if not is_valid:
            return False, reason
        
        return True, "é€šè¿‡"
    
    def manual_login(self):
        """
        ç¬¬ä¸€é˜¶æ®µï¼šäººå·¥ç™»å½• (Blocking Wait)
        æ‰“å¼€ä¸‰ä¸ªæ ‡ç­¾é¡µï¼Œç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ç™»å½•
        """
        if not self.page:
            raise RuntimeError("æµè§ˆå™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œç™»å½•")
        
        logger.info("=" * 80)
        logger.info("ç¬¬ä¸€é˜¶æ®µï¼šäººå·¥ç™»å½•")
        logger.info("=" * 80)
        
        # æ‰“å¼€æŠ–éŸ³æ ‡ç­¾é¡µ (Tab 1)
        logger.info("æ­£åœ¨æ‰“å¼€æŠ–éŸ³...")
        self.page.get('https://www.douyin.com')
        time.sleep(3)
        print("âœ… æŠ–éŸ³æ ‡ç­¾é¡µå·²æ‰“å¼€")
        
        # æ‰“å¼€å°çº¢ä¹¦æ ‡ç­¾é¡µ (Tab 2)
        logger.info("æ­£åœ¨æ‰“å¼€å°çº¢ä¹¦...")
        self.page.new_tab()
        time.sleep(1)
        self.page.get('https://www.xiaohongshu.com')
        time.sleep(3)
        print("âœ… å°çº¢ä¹¦æ ‡ç­¾é¡µå·²æ‰“å¼€")
        
        # æ‰“å¼€æœç‹—å¾®ä¿¡æ ‡ç­¾é¡µ (Tab 3)
        logger.info("æ­£åœ¨æ‰“å¼€æœç‹—å¾®ä¿¡...")
        self.page.new_tab()
        time.sleep(1)
        self.page.get('https://weixin.sogou.com')
        time.sleep(3)
        print("âœ… æœç‹—å¾®ä¿¡æ ‡ç­¾é¡µå·²æ‰“å¼€")
        
        # ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ç™»å½•
        print("\n" + "=" * 80)
        print("ğŸ”´ ã€é‡è¦ã€‘è¯·æ‰‹åŠ¨å®Œæˆä»¥ä¸‹æ“ä½œï¼š")
        print("")
        print("1ï¸âƒ£  æŠ–éŸ³ï¼šæ‰«ç æˆ–è¾“å…¥è´¦å·å¯†ç ç™»å½•ï¼Œç¡®ä¿èƒ½çœ‹åˆ°é¦–é¡µæ¨èå†…å®¹")
        print("2ï¸âƒ£  å°çº¢ä¹¦ï¼šæ‰«ç æˆ–è¾“å…¥è´¦å·å¯†ç ç™»å½•ï¼Œç¡®ä¿èƒ½çœ‹åˆ°é¦–é¡µæ¨èå†…å®¹")
        print("3ï¸âƒ£  æœç‹—å¾®ä¿¡ï¼šå¦‚æœå‡ºç°éªŒè¯ç ï¼Œè¯·æ‰‹åŠ¨å®ŒæˆéªŒè¯")
        print("")
        print("âš ï¸  è¯·ç¡®ä¿ä¸‰ä¸ªå¹³å°éƒ½å·²æˆåŠŸç™»å½•ï¼")
        print("   ç™»å½•å®Œæˆåï¼Œè¯·å›åˆ°è¿™é‡ŒæŒ‰ã€å›è½¦é”®ã€‘å¼€å§‹è‡ªåŠ¨åŒ–é‡‡é›†...")
        print("=" * 80)
        
        # é˜»å¡ç­‰å¾…ç”¨æˆ·æŒ‰å›è½¦
        try:
            input("\nğŸ‘‰ ç¡®è®¤å·²å…¨éƒ¨ç™»å½•åï¼ŒæŒ‰å›è½¦é”®ç»§ç»­...")
        except EOFError:
            # éäº¤äº’å¼ç¯å¢ƒï¼Œç­‰å¾…60ç§’
            logger.warning("æ£€æµ‹åˆ°éäº¤äº’å¼ç¯å¢ƒï¼Œç­‰å¾…60ç§’åè‡ªåŠ¨ç»§ç»­...")
            for i in range(60, 0, -10):
                print(f"â³ ç­‰å¾…ä¸­... {i}ç§’åè‡ªåŠ¨ç»§ç»­")
                time.sleep(10)
        
        logger.info("ç”¨æˆ·ç¡®è®¤ç™»å½•å®Œæˆï¼Œå¼€å§‹æ‰§è¡Œé‡‡é›†")
        time.sleep(2)  # é¢å¤–ç­‰å¾…2ç§’ç¡®ä¿é¡µé¢ç¨³å®š
    
    def crawl_douyin(self) -> List[Dict[str, Any]]:
        """
        ç¬¬äºŒé˜¶æ®µï¼šæŠ–éŸ³é‡‡é›†ï¼ˆçœŸäººæ·±æ½œæ¨¡å¼ï¼‰
        å½»åº•é‡å†™ï¼šä½¿ç”¨æš´åŠ›æ–‡æœ¬æå–ï¼Œä¸¥ç¦ä½¿ç”¨ HTML
        """
        if not self.page:
            logger.error("æµè§ˆå™¨æœªåˆå§‹åŒ–")
            return []
        
        logger.info("=" * 80)
        logger.info("ç¬¬äºŒé˜¶æ®µï¼šæŠ–éŸ³é‡‡é›†ï¼ˆçœŸäººæ·±æ½œæ¨¡å¼ï¼‰")
        logger.info("=" * 80)
        
        results = []
        
        try:
            # åˆ‡æ¢åˆ°æŠ–éŸ³æ ‡ç­¾é¡µ
            self.page.get('https://www.douyin.com')
            time.sleep(3)
            
            for brand_name in KEYWORDS:
                # ä½¿ç”¨ç»„åˆå…³é”®è¯æœç´¢
                search_queries = SEARCH_QUERIES.get(brand_name, [brand_name])
                logger.info(f"å“ç‰Œ: {brand_name}ï¼Œä½¿ç”¨ {len(search_queries)} ä¸ªç»„åˆå…³é”®è¯æœç´¢")
                
                for keyword in search_queries:
                    try:
                        logger.info(f"æœç´¢å…³é”®è¯: {keyword}")
                        print(f"[æŠ–éŸ³æ·±æ½œ] æœç´¢å…³é”®è¯: {keyword}")
                        
                        # ä¼˜åŒ–ï¼šè®¿é—®ç»¼åˆæœç´¢é¡µï¼ˆä¸æ˜¯è§†é¢‘é¡µï¼‰ï¼Œå¹¶è®¾ç½®æ—¶é—´æ’åº
                        # ç¬¬ä¸€æ­¥ï¼šå…ˆè®¿é—®é¦–é¡µï¼Œå»ºç«‹sessionï¼ˆåçˆ¬ç­–ç•¥ï¼‰
                        try:
                            self.page.get("https://www.douyin.com/")
                            self.human_like_delay(3, 5)
                            self.move_mouse_randomly()
                        except:
                            pass
                        
                        # ç¬¬äºŒæ­¥ï¼šè®¿é—®æœç´¢é¡µ
                        search_url = f"https://www.douyin.com/search/{keyword}"
                        logger.info(f"  è®¿é—®æœç´¢é¡µ: {search_url}")
                        print(f"[æŠ–éŸ³æœç´¢] è®¿é—®æœç´¢é¡µ: {search_url}")
                        self.page.get(search_url)
                        self.human_like_delay(4, 6)
                        self.move_mouse_randomly()
                        
                        # ç¬¬ä¸‰æ­¥ï¼šç‚¹å‡»"ç»¼åˆ"Tabï¼ˆä¸æ˜¯è§†é¢‘Tabï¼‰
                        try:
                            logger.info("  å°è¯•ç‚¹å‡»'ç»¼åˆ'Tab...")
                            print("[æŠ–éŸ³æœç´¢] å°è¯•ç‚¹å‡»'ç»¼åˆ'Tab...")
                            # å°è¯•å¤šç§æ–¹å¼æ‰¾åˆ°"ç»¼åˆ"Tab
                            general_tab = None
                            tab_selectors = [
                                'text:ç»¼åˆ',
                                'xpath://div[contains(text(), "ç»¼åˆ")]',
                                'xpath://span[contains(text(), "ç»¼åˆ")]',
                                'css:[data-e2e="search-result-tab-general"]',
                            ]
                            for selector in tab_selectors:
                                try:
                                    general_tab = self.page.ele(selector, timeout=2)
                                    if general_tab:
                                        logger.info(f"  âœ“ æ‰¾åˆ°'ç»¼åˆ'Tabï¼ˆä½¿ç”¨: {selector}ï¼‰")
                                        print(f"[æŠ–éŸ³æœç´¢] âœ“ æ‰¾åˆ°'ç»¼åˆ'Tab")
                                        general_tab.click()
                                        time.sleep(2)
                                        break
                                except:
                                    continue
                            
                            if not general_tab:
                                logger.warning("  âš ï¸ æœªæ‰¾åˆ°'ç»¼åˆ'Tabï¼Œå¯èƒ½å·²åœ¨ç»¼åˆé¡µé¢")
                                print("[æŠ–éŸ³æœç´¢] âš ï¸ æœªæ‰¾åˆ°'ç»¼åˆ'Tabï¼Œå¯èƒ½å·²åœ¨ç»¼åˆé¡µé¢")
                        except Exception as e:
                            logger.warning(f"  ç‚¹å‡»'ç»¼åˆ'Tabå¤±è´¥: {str(e)}")
                            print(f"[æŠ–éŸ³æœç´¢] ç‚¹å‡»'ç»¼åˆ'Tabå¤±è´¥: {str(e)}")
                        
                        # ç¬¬å››æ­¥ï¼šå°è¯•ç‚¹å‡»"æœ€æ–°"æ’åºæŒ‰é’®
                        try:
                            logger.info("  å°è¯•ç‚¹å‡»'æœ€æ–°'æ’åº...")
                            print("[æŠ–éŸ³æœç´¢] å°è¯•ç‚¹å‡»'æœ€æ–°'æ’åº...")
                            sort_btn = None
                            sort_selectors = [
                                'text:æœ€æ–°',
                                'text:æŒ‰æ—¶é—´',
                                'xpath://div[contains(text(), "æœ€æ–°")]',
                                'css:[data-e2e="search-result-sort-time"]',
                            ]
                            for selector in sort_selectors:
                                try:
                                    sort_btn = self.page.ele(selector, timeout=2)
                                    if sort_btn:
                                        logger.info(f"  âœ“ æ‰¾åˆ°'æœ€æ–°'æ’åºï¼ˆä½¿ç”¨: {selector}ï¼‰")
                                        print(f"[æŠ–éŸ³æœç´¢] âœ“ æ‰¾åˆ°'æœ€æ–°'æ’åº")
                                        sort_btn.click()
                                        time.sleep(2)
                                        break
                                except:
                                    continue
                            
                            if not sort_btn:
                                logger.warning("  âš ï¸ æœªæ‰¾åˆ°'æœ€æ–°'æ’åºæŒ‰é’®")
                                print("[æŠ–éŸ³æœç´¢] âš ï¸ æœªæ‰¾åˆ°'æœ€æ–°'æ’åºæŒ‰é’®")
                        except Exception as e:
                            logger.warning(f"  ç‚¹å‡»'æœ€æ–°'æ’åºå¤±è´¥: {str(e)}")
                            print(f"[æŠ–éŸ³æœç´¢] ç‚¹å‡»'æœ€æ–°'æ’åºå¤±è´¥: {str(e)}")
                        
                        # æ‰“å°å½“å‰é¡µé¢URLç¡®è®¤
                        logger.info(f"  å½“å‰é¡µé¢URL: {self.page.url}")
                        print(f"[æŠ–éŸ³æœç´¢] å½“å‰é¡µé¢URL: {self.page.url}")
                        
                        logger.info(f"å½“å‰é¡µé¢ URL: {self.page.url}")
                        print(f"[æŠ–éŸ³æ·±æ½œ] å½“å‰é¡µé¢ URL: {self.page.url}")
                        
                        # ç­‰å¾…å†…å®¹åŠ è½½
                        try:
                            self.page.wait.ele_displayed('css:div[data-e2e="scroll-list"]', timeout=10)
                            logger.info("  âœ“ é¡µé¢å†…å®¹å·²åŠ è½½")
                        except:
                            logger.warning("  âš ï¸ æœªæ£€æµ‹åˆ°å†…å®¹å®¹å™¨ï¼Œç»§ç»­å°è¯•...")
                        
                        # äººç±»è¡Œä¸ºæ¨¡æ‹Ÿï¼šæ»šåŠ¨åŠ è½½æ›´å¤šå†…å®¹
                        self.human_like_scroll()
                        self.move_mouse_randomly()
                        
                        # ä½¿ç”¨å¤šç§é€‰æ‹©å™¨æŸ¥æ‰¾å†…å®¹ï¼ˆç»¼åˆæœç´¢é¡µé¢ï¼‰
                        # æ ¹æ®è°ƒè¯•ç»“æœï¼Œä½¿ç”¨ div.search-result-card æˆ– div[contains(@class, "search-result")]
                        result_items = []
                        video_urls = []
                        
                        try:
                            print("[æŠ–éŸ³æœç´¢] å°è¯•å¤šç§é€‰æ‹©å™¨æŸ¥æ‰¾å†…å®¹...")
                            
                            # ç­–ç•¥1ï¼šæŸ¥æ‰¾æœç´¢ç»“æœå¡ç‰‡ï¼ˆç»¼åˆæœç´¢é¡µé¢ï¼‰
                            selectors_to_try = [
                                ('css:div.search-result-card', 'æœç´¢ç»“æœå¡ç‰‡'),
                                ('xpath://div[contains(@class, "search-result")]', 'æœç´¢ç»“æœå®¹å™¨'),
                                ('css:div[data-e2e="scroll-list"] > div', 'æ»šåŠ¨åˆ—è¡¨é¡¹'),
                            ]
                            
                            for selector, desc in selectors_to_try:
                                try:
                                    items = self.page.eles(selector, timeout=5)
                                    if items and len(items) > 0:
                                        result_items = items
                                        logger.info(f"  [{desc}] æ‰¾åˆ° {len(items)} ä¸ªç»“æœé¡¹")
                                        print(f"[æŠ–éŸ³æœç´¢] [{desc}] æ‰¾åˆ° {len(items)} ä¸ªç»“æœé¡¹")
                                        break
                                except Exception as e:
                                    logger.debug(f"  é€‰æ‹©å™¨ {desc} å¤±è´¥: {str(e)}")
                                    continue
                            
                            # ä»ç»“æœé¡¹ä¸­æå–é“¾æ¥
                            for item in result_items[:20]:  # æœ€å¤šå¤„ç†20ä¸ª
                                try:
                                    # å°è¯•å¤šç§æ–¹å¼æå–é“¾æ¥
                                    link = None
                                    link_selectors = [
                                        'css:a',
                                        'xpath:.//a[contains(@href, "/video/")]',
                                        'xpath:.//a[contains(@href, "/user/")]',
                                        'xpath:.//a',
                                    ]
                                    
                                    for link_sel in link_selectors:
                                        try:
                                            link_elem = item.ele(link_sel, timeout=1)
                                            if link_elem:
                                                href = link_elem.attr('href') or ''
                                                if href:
                                                    # å¤„ç†ç›¸å¯¹é“¾æ¥
                                                    if not href.startswith('http'):
                                                        if href.startswith('//'):
                                                            href = 'https:' + href
                                                        elif href.startswith('/'):
                                                            href = 'https://www.douyin.com' + href
                                                        else:
                                                            continue
                                                    
                                                    # åªä¿ç•™è§†é¢‘é“¾æ¥æˆ–ç”¨æˆ·é“¾æ¥ï¼ˆç»¼åˆæœç´¢å¯èƒ½åŒ…å«ç”¨æˆ·ï¼‰
                                                    if ('/video/' in href or '/user/' in href) and 'douyin.com' in href:
                                                        link = href
                                                        break
                                        except:
                                            continue
                                    
                                    if link and link not in video_urls:
                                        video_urls.append(link)
                                        print(f"[æŠ–éŸ³æœç´¢] âœ“ æ‰¾åˆ°é“¾æ¥: {link[:60]}...")
                                        
                                        if len(video_urls) >= 10:
                                            break
                                            
                                except Exception as e:
                                    logger.debug(f"  å¤„ç†ç»“æœé¡¹æ—¶å‡ºé”™: {str(e)}")
                                    continue
                            
                            video_urls = video_urls[:10]  # å…ˆå–10ä¸ªï¼Œåç»­ä¼šè¿‡æ»¤
                            logger.info(f"æ‰¾åˆ° {len(video_urls)} ä¸ªé“¾æ¥")
                            print(f"[æŠ–éŸ³æœç´¢] æœ€ç»ˆæ‰¾åˆ° {len(video_urls)} ä¸ªé“¾æ¥")
                            
                            if not video_urls:
                                # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œæ‰“å°è°ƒè¯•ä¿¡æ¯
                                logger.warning("  âš ï¸ æœªæ‰¾åˆ°ä»»ä½•é“¾æ¥ï¼Œæ‰“å°é¡µé¢ä¿¡æ¯...")
                                try:
                                    page_html_preview = self.page.html[:1000] if hasattr(self.page, 'html') else "æ— æ³•è·å–HTML"
                                    logger.warning(f"é¡µé¢å‰1000å­—ç¬¦: {page_html_preview}")
                                except:
                                    pass
                            
                        except Exception as e:
                            logger.warning(f"æå–é“¾æ¥å¤±è´¥: {str(e)}")
                            print(f"[æŠ–éŸ³æœç´¢] æå–å¤±è´¥: {str(e)}")
                            continue
                        
                        if not video_urls:
                            logger.warning(f"æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘ï¼Œè·³è¿‡å…³é”®è¯: {keyword}")
                            print(f"[æŠ–éŸ³æ·±æ½œ] æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘ï¼Œè·³è¿‡å…³é”®è¯: {keyword}")
                            continue
                        
                        # å¾ªç¯é‡‡é›†ï¼šçœŸäººæ·±æ½œæ¨¡å¼
                        for idx, video_url in enumerate(video_urls, 1):
                            new_tab = None
                            try:
                                logger.info(f"  å¤„ç†å†…å®¹ {idx}/{len(video_urls)}: {video_url[:60]}...")
                                print(f"[æŠ–éŸ³æœç´¢] æ­£åœ¨å¤„ç†å†…å®¹ {idx}/{len(video_urls)}: {video_url[:60]}...")
                                
                                # å¦‚æœæ˜¯ç”¨æˆ·é“¾æ¥ï¼Œè·³è¿‡ï¼ˆç»¼åˆæœç´¢å¯èƒ½åŒ…å«ç”¨æˆ·ï¼‰
                                if '/user/' in video_url:
                                    logger.info(f"    è·³è¿‡ç”¨æˆ·é“¾æ¥: {video_url}")
                                    continue
                                
                                # æ‰“å¼€æ–°æ ‡ç­¾é¡µ
                                new_tab = self.page.new_tab()
                                new_tab.get(video_url)
                                
                                # å¼ºåˆ¶ç­‰å¾…ï¼šå¿…é¡»ç­‰å¤Ÿæ—¶é—´
                                print(f"  [æŠ–éŸ³æœç´¢] å¼ºåˆ¶ç­‰å¾… 3 ç§’ï¼Œç¡®ä¿é¡µé¢æ¸²æŸ“...")
                                time.sleep(3)
                                
                                # æå–æ ‡é¢˜ï¼ˆç»ˆæä¼˜åŒ–ï¼šRENDER_DATA + DOM + HTMLæ­£åˆ™ï¼‰
                                title = ""
                                try:
                                    # æ–¹æ³•1ï¼šä» RENDER_DATA æå–ï¼ˆæœ€å‡†ç¡®ï¼‰
                                    try:
                                        html = new_tab.html
                                        import json
                                        import urllib.parse
                                        
                                        # æŸ¥æ‰¾ RENDER_DATA script æ ‡ç­¾
                                        render_match = re.search(r'<script id="RENDER_DATA"[^>]*>(.+?)</script>', html)
                                        if render_match:
                                            try:
                                                json_str = urllib.parse.unquote(render_match.group(1))
                                                data = json.loads(json_str)
                                                
                                                # é€’å½’æŸ¥æ‰¾è§†é¢‘ä¿¡æ¯
                                                videos = self._find_videos_in_json(data)
                                                if videos:
                                                    video = videos[0]  # å–ç¬¬ä¸€ä¸ª
                                                    desc = video.get('desc') or video.get('title', '')
                                                    if desc and len(desc) > 5:
                                                        title = desc.strip()
                                                        print(f"  [æŠ–éŸ³æ·±æ½œ] ä»RENDER_DATAæå–åˆ°æ ‡é¢˜: {title[:50]}...")
                                            except Exception as e:
                                                logger.debug(f"  RENDER_DATAè§£æå¤±è´¥: {str(e)}")
                                    except:
                                        pass
                                    
                                    # æ–¹æ³•2ï¼šä»DOMå…ƒç´ æå–ï¼ˆå¤‡é€‰ï¼‰
                                    if not title:
                                        try:
                                            title_selectors = [
                                                'tag:h1',
                                                'tag:div@class*=title',
                                                'tag:p@class*=title',
                                                'tag:span@class*=title',
                                                'css:div[class*="title"]',
                                                'css:p[class*="title"]',
                                                'css:span[class*="title"]',
                                            ]
                                            for sel in title_selectors:
                                                try:
                                                    title_elem = new_tab.ele(sel, timeout=1)
                                                    if title_elem:
                                                        title_text = title_elem.text or ""
                                                        if title_text and len(title_text.strip()) > 5:
                                                            title = title_text.strip()
                                                            print(f"  [æŠ–éŸ³æ·±æ½œ] ä»DOMæå–åˆ°æ ‡é¢˜: {title[:50]}...")
                                                            break
                                                except:
                                                    continue
                                        except:
                                            pass
                                    
                                    # æ–¹æ³•3ï¼šä»é¡µé¢æ–‡æœ¬ä¸­æå–ï¼ˆå…œåº•ï¼‰
                                    if not title:
                                        try:
                                            # è·å–é¡µé¢æ‰€æœ‰æ–‡æœ¬ï¼Œæ‰¾æœ€é•¿çš„æ®µè½ä½œä¸ºæ ‡é¢˜
                                            body_elem = new_tab.ele('tag:body', timeout=2)
                                            if body_elem:
                                                full_text = body_elem.text or ""
                                                lines = [line.strip() for line in full_text.split('\n') if line.strip()]
                                                # æ‰¾é•¿åº¦åœ¨10-200ä¹‹é—´çš„æ–‡æœ¬ä½œä¸ºæ ‡é¢˜å€™é€‰
                                                candidates = [line for line in lines if 10 <= len(line) <= 200]
                                                if candidates:
                                                    # ä¼˜å…ˆé€‰æ‹©åŒ…å«å…³é”®è¯çš„
                                                    for candidate in candidates:
                                                        if any(kw in candidate for kw in [brand_name, keyword]):
                                                            title = candidate
                                                            break
                                                    # å¦‚æœæ²¡æœ‰åŒ…å«å…³é”®è¯çš„ï¼Œé€‰ç¬¬ä¸€ä¸ª
                                                    if not title and candidates:
                                                        title = candidates[0]
                                                        print(f"  [æŠ–éŸ³æ·±æ½œ] ä»é¡µé¢æ–‡æœ¬æå–åˆ°æ ‡é¢˜: {title[:50]}...")
                                        except:
                                            pass
                                except Exception as e:
                                    logger.debug(f"  æå–æ ‡é¢˜å¤±è´¥: {str(e)}")
                                    pass
                                
                                # æå–å‘å¸ƒæ—¶é—´
                                date_str = ""
                                try:
                                    date_selectors = ['tag:span@class*=time', 'tag:time', 'tag:div@class*=date']
                                    for sel in date_selectors:
                                        try:
                                            date_elem = new_tab.ele(sel, timeout=1)
                                            if date_elem:
                                                date_str = date_elem.text or ""
                                                break
                                        except:
                                            continue
                                except:
                                    pass
                                
                                # ä¸¥æ ¼æ—¶é—´è¿‡æ»¤ï¼šåªä¿ç•™æœ€è¿‘3å¤©
                                if date_str:
                                    if not self.is_recent(date_str):
                                        logger.info(f"    è§†é¢‘è¶…å‡º3å¤©èŒƒå›´ï¼Œè·³è¿‡: {date_str}")
                                        print(f"  [æŠ–éŸ³æ·±æ½œ] è§†é¢‘è¶…å‡º3å¤©èŒƒå›´ï¼Œè·³è¿‡: {date_str}")
                                        try:
                                            new_tab.close()
                                        except:
                                            pass
                                        continue
                                else:
                                    # å¦‚æœæ²¡æœ‰æ—¶é—´ä¿¡æ¯ï¼Œå°è¯•ä»é¡µé¢æå–
                                    try:
                                        time_elems = new_tab.eles('tag:span@class*=time', timeout=1)
                                        for te in time_elems[:3]:
                                            time_text = te.text or ""
                                            if time_text and not self.is_recent(time_text):
                                                logger.info(f"    è§†é¢‘è¶…å‡º3å¤©èŒƒå›´ï¼ˆä»é¡µé¢æå–ï¼‰ï¼Œè·³è¿‡: {time_text}")
                                                try:
                                                    new_tab.close()
                                                except:
                                                    pass
                                                continue
                                    except:
                                        pass
                                
                                # æ»šåŠ¨è¯„è®ºåŒºï¼ˆå…³é”®æ­¥éª¤ï¼‰
                                print(f"  [æŠ–éŸ³æ·±æ½œ] æ»šåŠ¨è¯„è®ºåŒºåŠ è½½å†…å®¹...")
                                try:
                                    new_tab.scroll.down(1000)
                                    time.sleep(2)
                                    new_tab.scroll.down(500)
                                    time.sleep(1)
                                except Exception as e:
                                    print(f"  [æŠ–éŸ³æ·±æ½œ] æ»šåŠ¨å¤±è´¥: {str(e)}")
                                
                                # æ–‡æœ¬æå–ï¼ˆä¸¥ç¦ä½¿ç”¨ HTMLï¼‰+ äºŒæ¬¡æ¸…æ´—
                                print(f"  [æŠ–éŸ³ä¼˜åŒ–] å¼€å§‹æå–è¯„è®ºæ–‡æœ¬ï¼ˆä¸¥ç¦ä½¿ç”¨HTMLï¼‰...")
                                comments = []
                                
                                # å°è¯•ç‚¹å‡»"å±•å¼€æ›´å¤šè¯„è®º"
                                try:
                                    expand_btns = new_tab.eles('xpath://button[contains(text(), "å±•å¼€") or contains(text(), "æ›´å¤š") or contains(@class, "expand")]', timeout=2)
                                    for btn in expand_btns[:3]:  # ç‚¹å‡»å‰3ä¸ªå±•å¼€æŒ‰é’®
                                        try:
                                            btn.click()
                                            time.sleep(1)
                                            print(f"  [æŠ–éŸ³ä¼˜åŒ–] âœ“ ç‚¹å‡»å±•å¼€æŒ‰é’®")
                                        except:
                                            continue
                                except:
                                    pass
                                
                                try:
                                    # ç­–ç•¥1ï¼šå°è¯•æŸ¥æ‰¾è¯„è®ºå®¹å™¨ï¼ˆä½¿ç”¨ class*="comment" æˆ– data-e2e="comment"ï¼‰
                                    comment_selectors = [
                                        'xpath://div[contains(@class, "comment")]',
                                        'xpath://div[@data-e2e="comment"]',
                                        'xpath://div[contains(@class, "comment-item")]',
                                    ]
                                    
                                    comment_items = []
                                    for selector in comment_selectors:
                                        try:
                                            items = new_tab.eles(selector, timeout=3)
                                            if items:
                                                comment_items = items
                                                print(f"  [æŠ–éŸ³ä¼˜åŒ–] ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(items)} ä¸ªè¯„è®ºå…ƒç´ ")
                                                break
                                        except:
                                            continue
                                    
                                    # ä»è¯„è®ºå…ƒç´ ä¸­æå–æ–‡æœ¬
                                    for item in comment_items[:30]:  # æ£€æŸ¥å‰30ä¸ª
                                        try:
                                            text = item.text or ""
                                            text = self._clean_html_text(text)  # äºŒæ¬¡æ¸…æ´—HTMLæ®‹ç•™
                                            text = text.strip()
                                            
                                            # è¿‡æ»¤æ¡ä»¶ï¼šé•¿åº¦ 5-200ï¼Œä¸”ä¸åŒ…å«ç³»ç»Ÿè¯
                                            if 5 <= len(text) <= 200:
                                                system_words = ['å…³æ³¨', 'ç‚¹èµ', 'æ”¶è—', 'åˆ†äº«', 'è¯„è®º', 'å›å¤', 'æŸ¥çœ‹æ›´å¤š', 'å±•å¼€', 'æ”¶èµ·', 'è½¬å‘', 'ä¸¾æŠ¥', 'æŠ–éŸ³', 'è®°å½•ç¾å¥½ç”Ÿæ´»']
                                                if not any(sys_word in text for sys_word in system_words):
                                                    if text not in comments:
                                                        comments.append(text)
                                                        print(f"  [æŠ–éŸ³ä¼˜åŒ–] âœ“ æ‰¾åˆ°è¯„è®º: {text[:50]}...")
                                                        print(f"  [æŠ–éŸ³ä¼˜åŒ–]   åŸå§‹æ–‡æœ¬å‰200å­—ç¬¦: {text[:200]}")
                                                        if len(comments) >= 5:
                                                            break
                                        except:
                                            continue
                                
                                except Exception as e:
                                    print(f"  [æŠ–éŸ³ä¼˜åŒ–] ç­–ç•¥1å¤±è´¥: {str(e)}")
                            
                                # ç­–ç•¥2ï¼šå…œåº•ç­–ç•¥ - è·å–æ•´ä¸ªé¡µé¢æ–‡æœ¬ï¼ŒäºŒæ¬¡æ¸…æ´—åè¿‡æ»¤
                                if not comments:
                                    print(f"  [æŠ–éŸ³ä¼˜åŒ–] ç­–ç•¥1æœªæ‰¾åˆ°è¯„è®ºï¼Œä½¿ç”¨å…œåº•ç­–ç•¥...")
                                    try:
                                        body_elem = new_tab.ele('tag:body', timeout=2)
                                        if body_elem:
                                            full_text = body_elem.text or ""
                                            print(f"  [æŠ–éŸ³ä¼˜åŒ–] é¡µé¢æ–‡æœ¬æ€»é•¿åº¦: {len(full_text)} å­—ç¬¦")
                                            
                                            # æŒ‰è¡Œåˆ†å‰²ï¼ŒäºŒæ¬¡æ¸…æ´—ï¼Œä¿ç•™é•¿åº¦ 5-200 çš„è¡Œ
                                            lines = full_text.split('\n')
                                            for line in lines:
                                                line = self._clean_html_text(line)  # äºŒæ¬¡æ¸…æ´—
                                                line = line.strip()
                                                
                                                if 5 <= len(line) <= 200:
                                                    system_words = ['å…³æ³¨', 'ç‚¹èµ', 'æ”¶è—', 'åˆ†äº«', 'è¯„è®º', 'å›å¤', 'æŸ¥çœ‹æ›´å¤š', 'å±•å¼€', 'æ”¶èµ·', 'è½¬å‘', 'ä¸¾æŠ¥', 'æŠ–éŸ³', 'è®°å½•ç¾å¥½ç”Ÿæ´»']
                                                    if not any(sys_word in line for sys_word in system_words):
                                                        # æ£€æŸ¥æ˜¯å¦åƒè¯„è®ºï¼ˆåŒ…å«å¸¸è§è¯„è®ºå…³é”®è¯ï¼‰
                                                        if any(kw in line for kw in ['è¯´', 'è§‰å¾—', 'çœŸçš„', 'å¤ª', 'å¥½', 'å·®', 'é¿é›·', 'å‘', 'é€€è´¹', 'éª—å±€', 'æŠ•è¯‰', 'ä¸è¦', 'åƒä¸‡åˆ«', 'ï¼Ÿ', 'ï¼']):
                                                            if line not in comments:
                                                                comments.append(line)
                                                                print(f"  [æŠ–éŸ³ä¼˜åŒ–] âœ“ å…œåº•æ‰¾åˆ°è¯„è®º: {line[:50]}...")
                                                                print(f"  [æŠ–éŸ³ä¼˜åŒ–]   åŸå§‹æ–‡æœ¬å‰200å­—ç¬¦: {line[:200]}")
                                                                if len(comments) >= 5:
                                                                    break
                                    except Exception as e:
                                        print(f"  [æŠ–éŸ³ä¼˜åŒ–] å…œåº•ç­–ç•¥å¤±è´¥: {str(e)}")
                                
                                comments = comments[:5]  # é™åˆ¶ä¸ºå‰5æ¡
                                print(f"  [æŠ–éŸ³ä¼˜åŒ–] æœ€ç»ˆæå–åˆ° {len(comments)} æ¡è¯„è®º")
                                
                                # å…³é—­æ ‡ç­¾é¡µ
                                try:
                                    new_tab.close()
                                except:
                                    pass
                                
                                if title or video_url:
                                    # ä¸¥æ ¼å†…å®¹è¿‡æ»¤ï¼ˆä¸‰å±‚è¿‡æ»¤ï¼‰
                                    snippet_text = " ".join(comments[:3]) if comments else ""
                                    item_data = {
                                        "title": title,
                                        "content": snippet_text,
                                        "snippet": snippet_text
                                    }
                                    is_valid, reason = self.strict_content_filter(brand_name, item_data)
                                    
                                    if not is_valid:
                                        logger.info(f"  âœ— è¿‡æ»¤: {reason} - {title[:50] if title else 'æ— æ ‡é¢˜'}...")
                                        print(f"[æŠ–éŸ³æ·±æ½œ] âœ— è¿‡æ»¤: {reason} - {title[:50] if title else 'æ— æ ‡é¢˜'}...")
                                        try:
                                            new_tab.close()
                                        except:
                                            pass
                                        continue
                                    
                                    # æå–äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµæ•°ç­‰ï¼‰
                                    likes = "0"
                                    try:
                                        like_elems = new_tab.eles('tag:span@class*=like', timeout=1)
                                        for le in like_elems[:1]:
                                            like_text = le.text or ""
                                            if like_text and any(c.isdigit() for c in like_text):
                                                likes = like_text
                                                break
                                    except:
                                        pass
                                    
                                    result = {
                                        "platform": "æŠ–éŸ³",
                                        "keyword": brand_name,  # ä½¿ç”¨å“ç‰Œåè€Œä¸æ˜¯æœç´¢å…³é”®è¯
                                        "search_query": keyword,  # è®°å½•å®é™…æœç´¢çš„å…³é”®è¯
                                        "title": title.strip() or f"è§†é¢‘ {idx}",
                                        "url": video_url,
                                        "date": date_str.strip(),
                                        "likes": likes,  # æ–°å¢ç‚¹èµæ•°
                                        "comments": comments,  # çº¯æ–‡æœ¬åˆ—è¡¨
                                        "comment_count": len(comments),
                                        "is_valid": True
                                    }
                                    results.append(result)
                                    logger.info(f"  âœ“ é‡‡é›†æˆåŠŸ: {title[:50] if title else 'æ— æ ‡é¢˜'}... (è¯„è®º: {len(comments)}æ¡, ç‚¹èµ: {likes})")
                                    print(f"[æŠ–éŸ³æ·±æ½œ] âœ“ é‡‡é›†æˆåŠŸ: {title[:50] if title else 'æ— æ ‡é¢˜'}... (è¯„è®º: {len(comments)}æ¡, ç‚¹èµ: {likes})")
                                    
                                    time.sleep(random.uniform(1, 2))
                                    
                            except Exception as e:
                                logger.warning(f"  å¤„ç†è§†é¢‘ {idx} å¤±è´¥: {str(e)}")
                                print(f"  [æŠ–éŸ³æ·±æ½œ] å¤„ç†è§†é¢‘ {idx} å¤±è´¥: {str(e)}")
                                # ç¡®ä¿å…³é—­æ ‡ç­¾é¡µ
                                try:
                                    if new_tab:
                                        new_tab.close()
                                except:
                                    pass
                                continue
                        
                        time.sleep(random.uniform(2, 3))
                    
                    except Exception as e:
                        logger.error(f"é‡‡é›†å…³é”®è¯ {keyword} å¤±è´¥: {str(e)}")
                        print(f"[æŠ–éŸ³æ·±æ½œ] é‡‡é›†å…³é”®è¯ {keyword} å¤±è´¥: {str(e)}")
                        continue
                
                # æ¯ä¸ªå“ç‰Œæœç´¢å®Œæˆåç¨ä½œåœé¡¿
                time.sleep(random.uniform(1, 2))
            
        except Exception as e:
            logger.error(f"æŠ–éŸ³é‡‡é›†å¼‚å¸¸: {str(e)}", exc_info=True)
            print(f"[æŠ–éŸ³æ·±æ½œ] é‡‡é›†å¼‚å¸¸: {str(e)}")
        
        logger.info(f"æŠ–éŸ³é‡‡é›†å®Œæˆï¼Œå…±æ‰¾åˆ° {len(results)} æ¡æœ‰æ•ˆæ•°æ®")
        print(f"[æŠ–éŸ³æ·±æ½œ] é‡‡é›†å®Œæˆï¼Œå…±æ‰¾åˆ° {len(results)} æ¡æœ‰æ•ˆæ•°æ®")
        self.douyin_data = results
        return results
    
    def _clean_html_text(self, text: str) -> str:
        """
        äºŒæ¬¡æ¸…æ´—HTMLæ®‹ç•™æ–‡æœ¬
        
        Args:
            text: åŸå§‹æ–‡æœ¬ï¼ˆå¯èƒ½åŒ…å«HTMLæ ‡ç­¾æ®‹ç•™ï¼‰
        
        Returns:
            æ¸…æ´—åçš„çº¯æ–‡æœ¬
        """
        if not text:
            return ""
        
        # ç§»é™¤HTMLæ ‡ç­¾æ®‹ç•™
        text = re.sub(r'<[^>]+>', '', text)  # ç§»é™¤ <tag> æ ‡ç­¾
        text = re.sub(r'&[a-zA-Z]+;', '', text)  # ç§»é™¤ &nbsp; ç­‰å®ä½“
        text = re.sub(r'class\s*=\s*["\'][^"\']*["\']', '', text)  # ç§»é™¤ class="xxx"
        text = re.sub(r'id\s*=\s*["\'][^"\']*["\']', '', text)  # ç§»é™¤ id="xxx"
        text = re.sub(r'style\s*=\s*["\'][^"\']*["\']', '', text)  # ç§»é™¤ style="xxx"
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        return text
    
    def get_xhs_comments(self, page) -> List[str]:
        """
        æå–å°çº¢ä¹¦è¯¦æƒ…é¡µçš„è¯„è®ºï¼ˆæ–‡æœ¬å—æš´åŠ›æå–æ³•ï¼‰
        
        Args:
            page: ChromiumPage å¯¹è±¡ï¼ˆè¯¦æƒ…é¡µï¼‰
        
        Returns:
            è¯„è®ºåˆ—è¡¨
        """
        comments = []
        print("  [å°çº¢ä¹¦è¯„è®ºæå–] å¼€å§‹æå–è¯„è®º...")
        
        try:
            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(3)
            print("  [å°çº¢ä¹¦è¯„è®ºæå–] é¡µé¢ç­‰å¾…å®Œæˆ")
            
            # å°è¯•å®šä½è¯„è®ºå®¹å™¨
            print("  [å°çº¢ä¹¦è¯„è®ºæå–] å°è¯•å®šä½è¯„è®ºå®¹å™¨...")
            comment_container = None
            try:
                # æŸ¥æ‰¾åŒ…å«"è¯„è®º"æ–‡æœ¬çš„ div
                comment_container = page.ele('xpath://div[contains(text(), "è¯„è®º")]', timeout=3)
                if comment_container:
                    print("  [å°çº¢ä¹¦è¯„è®ºæå–] æ‰¾åˆ°è¯„è®ºå®¹å™¨ï¼ˆé€šè¿‡æ–‡æœ¬å®šä½ï¼‰")
            except:
                pass
            
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯• class åŒ…å« comments
            if not comment_container:
                try:
                    comment_container = page.ele('xpath://div[contains(@class, "comment")]', timeout=2)
                    if comment_container:
                        print("  [å°çº¢ä¹¦è¯„è®ºæå–] æ‰¾åˆ°è¯„è®ºå®¹å™¨ï¼ˆé€šè¿‡ class å®šä½ï¼‰")
                except:
                    pass
            
            # æš´åŠ›æ–¹æ¡ˆï¼šç›´æ¥è·å–é¡µé¢æ–‡æœ¬å—
            if not comment_container:
                print("  [å°çº¢ä¹¦è¯„è®ºæå–] æœªæ‰¾åˆ°ç‰¹å®šå®¹å™¨ï¼Œä½¿ç”¨æš´åŠ›æ–‡æœ¬æå–æ³•...")
                try:
                    # è·å–é¡µé¢æ‰€æœ‰ div
                    all_divs = page.eles('tag:div', timeout=3)
                    print(f"  [å°çº¢ä¹¦è¯„è®ºæå–] æ‰¾åˆ° {len(all_divs)} ä¸ª div å…ƒç´ ")
                    
                    system_words = ['å…³æ³¨', 'ç‚¹èµ', 'æ”¶è—', 'åˆ†äº«', 'è¯„è®º', 'å›å¤', 'æŸ¥çœ‹æ›´å¤š', 'å±•å¼€', 'æ”¶èµ·']
                    
                    for div in all_divs:
                        try:
                            text = div.text or ""
                            text = text.strip()
                            
                            # è¿‡æ»¤æ¡ä»¶ï¼šå­—æ•°åœ¨ 10-50 å­—ï¼Œä¸”ä¸åŒ…å«ç³»ç»Ÿè¯
                            if 10 <= len(text) <= 50:
                                # æ’é™¤ç³»ç»Ÿè¯
                                if not any(sys_word in text for sys_word in system_words):
                                    # æ£€æŸ¥æ˜¯å¦åƒè¯„è®ºï¼ˆåŒ…å«å¸¸è§è¯„è®ºå…³é”®è¯ï¼‰
                                    if any(kw in text for kw in ['è¯´', 'è§‰å¾—', 'çœŸçš„', 'å¤ª', 'å¥½', 'å·®', 'é¿é›·', 'å‘', 'é€€è´¹', 'éª—å±€', 'æŠ•è¯‰', 'ä¸è¦', 'åƒä¸‡åˆ«']):
                                        if text not in comments:
                                            comments.append(text)
                                            print(f"  [å°çº¢ä¹¦è¯„è®ºæå–] âœ“ æ‰¾åˆ°è¯„è®º: {text[:50]}...")
                                            if len(comments) >= 5:
                                                break
                        except:
                            continue
                    
                    print(f"  [å°çº¢ä¹¦è¯„è®ºæå–] æš´åŠ›æå–å®Œæˆï¼Œæ‰¾åˆ° {len(comments)} æ¡è¯„è®º")
                    
                except Exception as e:
                    print(f"  [å°çº¢ä¹¦è¯„è®ºæå–] æš´åŠ›æå–å¤±è´¥: {str(e)}")
            else:
                # å¦‚æœæ‰¾åˆ°äº†è¯„è®ºå®¹å™¨ï¼Œåœ¨å®¹å™¨å†…æå–
                print("  [å°çº¢ä¹¦è¯„è®ºæå–] åœ¨è¯„è®ºå®¹å™¨å†…æå–...")
                try:
                    comment_items = comment_container.eles('tag:div', timeout=2)
                    print(f"  [å°çº¢ä¹¦è¯„è®ºæå–] è¯„è®ºå®¹å™¨å†…æ‰¾åˆ° {len(comment_items)} ä¸ªå­å…ƒç´ ")
                    
                    for item in comment_items[:10]:
                        text = item.text or ""
                        text = text.strip()
                        if 10 <= len(text) <= 200 and text:
                            if text not in comments:
                                comments.append(text)
                                print(f"  [å°çº¢ä¹¦è¯„è®ºæå–] âœ“ æ‰¾åˆ°è¯„è®º: {text[:50]}...")
                                if len(comments) >= 5:
                                    break
                except Exception as e:
                    print(f"  [å°çº¢ä¹¦è¯„è®ºæå–] å®¹å™¨å†…æå–å¤±è´¥: {str(e)}")
            
            # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•æ­£åˆ™æå–é¡µé¢ HTML
            if not comments:
                print("  [å°çº¢ä¹¦è¯„è®ºæå–] å°è¯•ä» HTML ä¸­æ­£åˆ™æå–...")
                try:
                    page_html = page.html or ""
                    # æŸ¥æ‰¾"è¯„è®º"å…³é”®å­—ä¹‹åçš„æ–‡æœ¬
                    comment_match = re.search(r'è¯„è®º[^<]*', page_html, re.IGNORECASE)
                    if comment_match:
                        comment_section = page_html[comment_match.start():comment_match.start()+500]
                        # æå–å¯èƒ½çš„è¯„è®ºæ–‡æœ¬
                        text_blocks = re.findall(r'>([^<>]{10,50})<', comment_section)
                        for block in text_blocks[:5]:
                            block = block.strip()
                            if block and len(block) >= 10:
                                comments.append(block)
                                print(f"  [å°çº¢ä¹¦è¯„è®ºæå–] âœ“ ä»HTMLæå–è¯„è®º: {block[:50]}...")
                except Exception as e:
                    print(f"  [å°çº¢ä¹¦è¯„è®ºæå–] HTML æå–å¤±è´¥: {str(e)}")
            
            comments = comments[:5]
            print(f"  [å°çº¢ä¹¦è¯„è®ºæå–] æœ€ç»ˆæå–åˆ° {len(comments)} æ¡è¯„è®º")
            
        except Exception as e:
            print(f"  [å°çº¢ä¹¦è¯„è®ºæå–] æå–è¿‡ç¨‹å‡ºé”™: {str(e)}")
        
        return comments
    
    def get_douyin_comments(self, page) -> List[str]:
        """
        æå–æŠ–éŸ³è§†é¢‘è¯¦æƒ…é¡µçš„è¯„è®ºï¼ˆä¾§è¾¹æ æ»šåŠ¨æ³•ï¼‰
        
        Args:
            page: ChromiumPage å¯¹è±¡ï¼ˆè§†é¢‘è¯¦æƒ…é¡µï¼‰
        
        Returns:
            è¯„è®ºåˆ—è¡¨
        """
        comments = []
        print("  [æŠ–éŸ³è¯„è®ºæå–] å¼€å§‹æå–è¯„è®º...")
        
        try:
            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(3)
            print("  [æŠ–éŸ³è¯„è®ºæå–] é¡µé¢ç­‰å¾…å®Œæˆ")
            
            # å®šä½è¯„è®ºåŒºï¼ˆé€šå¸¸åœ¨å³ä¾§ä¾§è¾¹æ ï¼‰
            print("  [æŠ–éŸ³è¯„è®ºæå–] å°è¯•å®šä½è¯„è®ºåŒº...")
            comment_container = None
            
            try:
                # å°è¯•å¤šç§æ–¹å¼å®šä½è¯„è®ºåŒº
                selectors = [
                    'xpath://div[contains(@class, "comment")]',
                    'xpath://div[contains(text(), "è¯„è®º")]',
                    'xpath://div[@id*="comment"]',
                ]
                
                for selector in selectors:
                    try:
                        comment_container = page.ele(selector, timeout=2)
                        if comment_container:
                            print(f"  [æŠ–éŸ³è¯„è®ºæå–] æ‰¾åˆ°è¯„è®ºå®¹å™¨ï¼ˆä½¿ç”¨: {selector}ï¼‰")
                            break
                    except:
                        continue
            except Exception as e:
                print(f"  [æŠ–éŸ³è¯„è®ºæå–] å®šä½è¯„è®ºå®¹å™¨å¤±è´¥: {str(e)}")
            
            # å¦‚æœæ‰¾åˆ°è¯„è®ºå®¹å™¨ï¼Œç§»åŠ¨é¼ æ ‡å¹¶æ»šåŠ¨
            if comment_container:
                try:
                    print("  [æŠ–éŸ³è¯„è®ºæå–] ç§»åŠ¨é¼ æ ‡åˆ°è¯„è®ºåŒº...")
                    comment_container.scroll.to_see()
                    time.sleep(1)
                    
                    print("  [æŠ–éŸ³è¯„è®ºæå–] å‘ä¸‹æ»šåŠ¨åŠ è½½è¯„è®º...")
                    page.scroll.down(500)
                    time.sleep(2)
                    page.scroll.down(500)
                    time.sleep(2)
                    print("  [æŠ–éŸ³è¯„è®ºæå–] æ»šåŠ¨å®Œæˆ")
                except Exception as e:
                    print(f"  [æŠ–éŸ³è¯„è®ºæå–] æ»šåŠ¨æ“ä½œå¤±è´¥: {str(e)}")
            else:
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œç›´æ¥æ»šåŠ¨é¡µé¢
                print("  [æŠ–éŸ³è¯„è®ºæå–] æœªæ‰¾åˆ°è¯„è®ºå®¹å™¨ï¼Œç›´æ¥æ»šåŠ¨é¡µé¢...")
                try:
                    page.scroll.to_bottom()
                    time.sleep(2)
                    page.scroll.up(300)
                    time.sleep(1)
                except:
                    pass
            
            # æå–è¯„è®ºæ–‡æœ¬
            print("  [æŠ–éŸ³è¯„è®ºæå–] å¼€å§‹æå–è¯„è®ºæ–‡æœ¬...")
            try:
                # å°è¯•æŸ¥æ‰¾è¯„è®ºå…ƒç´ 
                comment_selectors = [
                    'tag:p',
                    'tag:span',
                    'tag:div',
                ]
                
                for selector in comment_selectors:
                    try:
                        elems = page.eles(selector, timeout=3)
                        print(f"  [æŠ–éŸ³è¯„è®ºæå–] ä½¿ç”¨ {selector} æ‰¾åˆ° {len(elems)} ä¸ªå…ƒç´ ")
                        
                        for elem in elems[:100]:  # æ£€æŸ¥å‰100ä¸ªå…ƒç´ 
                            try:
                                text = elem.text or ""
                                text = text.strip()
                                
                                # è¿‡æ»¤æ¡ä»¶ï¼šé•¿åº¦åœ¨ 5-200 å­—ï¼Œä¸”ä¸åŒ…å«ç³»ç»Ÿè¯
                                if 5 <= len(text) <= 200:
                                    system_words = ['å…³æ³¨', 'ç‚¹èµ', 'æ”¶è—', 'åˆ†äº«', 'è¯„è®º', 'å›å¤', 'æŸ¥çœ‹æ›´å¤š', 'å±•å¼€', 'æ”¶èµ·', 'è½¬å‘']
                                    if not any(sys_word in text for sys_word in system_words):
                                        # æ£€æŸ¥æ˜¯å¦åƒè¯„è®ºï¼ˆåŒ…å«å¸¸è§è¯„è®ºå…³é”®è¯æˆ–è¡¨æƒ…ï¼‰
                                        if any(kw in text for kw in ['è¯´', 'è§‰å¾—', 'çœŸçš„', 'å¤ª', 'å¥½', 'å·®', 'é¿é›·', 'å‘', 'é€€è´¹', 'éª—å±€', 'æŠ•è¯‰', 'ä¸è¦', 'åƒä¸‡åˆ«']) or 'emoji' in str(type(elem)):
                                            if text not in comments:
                                                comments.append(text)
                                                print(f"  [æŠ–éŸ³è¯„è®ºæå–] âœ“ æ‰¾åˆ°è¯„è®º: {text[:50]}...")
                                                if len(comments) >= 5:
                                                    break
                            except:
                                continue
                        
                        if comments:
                            break
                    except:
                        continue
                
                print(f"  [æŠ–éŸ³è¯„è®ºæå–] æå–å®Œæˆï¼Œæ‰¾åˆ° {len(comments)} æ¡è¯„è®º")
                
            except Exception as e:
                print(f"  [æŠ–éŸ³è¯„è®ºæå–] æå–è¯„è®ºæ–‡æœ¬å¤±è´¥: {str(e)}")
            
            # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•ä»é¡µé¢æ–‡æœ¬ä¸­æå–
            if not comments:
                print("  [æŠ–éŸ³è¯„è®ºæå–] å°è¯•ä»é¡µé¢æ–‡æœ¬ä¸­æå–...")
                try:
                    page_text = page.html or ""
                    # æŸ¥æ‰¾å¯èƒ½çš„è¯„è®ºæ¨¡å¼
                    comment_patterns = [
                        r'([^<>]{10,100}(?:è¯´|è§‰å¾—|çœŸçš„|å¤ª|å¥½|å·®|é¿é›·|å‘|é€€è´¹)[^<>]{0,50})',
                    ]
                    
                    for pattern in comment_patterns:
                        matches = re.findall(pattern, page_text)
                        for match in matches[:5]:
                            match = match.strip()
                            if match and 10 <= len(match) <= 200:
                                comments.append(match)
                                print(f"  [æŠ–éŸ³è¯„è®ºæå–] âœ“ ä»æ–‡æœ¬æå–è¯„è®º: {match[:50]}...")
                except Exception as e:
                    print(f"  [æŠ–éŸ³è¯„è®ºæå–] æ–‡æœ¬æå–å¤±è´¥: {str(e)}")
            
            comments = comments[:5]
            print(f"  [æŠ–éŸ³è¯„è®ºæå–] æœ€ç»ˆæå–åˆ° {len(comments)} æ¡è¯„è®º")
            
        except Exception as e:
            print(f"  [æŠ–éŸ³è¯„è®ºæå–] æå–è¿‡ç¨‹å‡ºé”™: {str(e)}")
        
        return comments
    
    def fetch_from_bing(self, keyword: str) -> List[Dict[str, Any]]:
        """
        å¤‡ç”¨æ–¹æ¡ˆï¼šä» Bing æœç´¢è·å–å°çº¢ä¹¦å†…å®¹
        
        Args:
            keyword: æœç´¢å…³é”®è¯
        
        Returns:
            åŒ…å«æ ‡é¢˜ã€é“¾æ¥ã€æ¥æºçš„å­—å…¸åˆ—è¡¨
        """
        if not BING_BACKUP_AVAILABLE:
            logger.warning("Bing å¤‡ç”¨æ–¹æ¡ˆä¸å¯ç”¨ï¼ˆç¼ºå°‘ requests æˆ– BeautifulSoupï¼‰")
            return []
        
        results = []
        try:
            logger.info(f"[Bingå¤‡ç”¨] æœç´¢å…³é”®è¯: {keyword}")
            
            # æ„é€ æœç´¢è¯ï¼šsite:xiaohongshu.com {keyword} after:2023-10-01
            search_query = f"site:xiaohongshu.com {keyword}"
            bing_url = f"https://www.bing.com/search?q={search_query}&count=10"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            
            response = requests.get(bing_url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æŸ¥æ‰¾æœç´¢ç»“æœ
            search_results = soup.find_all('li', class_='b_algo')[:10]
            
            for result in search_results:
                try:
                    # æå–æ ‡é¢˜
                    title_elem = result.find('h2')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    
                    # æå–é“¾æ¥
                    link_elem = title_elem.find('a')
                    if not link_elem:
                        continue
                    
                    url = link_elem.get('href', '')
                    
                    # æå–æ‘˜è¦
                    snippet_elem = result.find('p')
                    snippet = snippet_elem.get_text(strip=True) if snippet_elem else ""
                    
                    # åªä¿ç•™å°çº¢ä¹¦é“¾æ¥
                    if 'xiaohongshu.com' in url:
                        results.append({
                            "platform": "å°çº¢ä¹¦",
                            "keyword": keyword,
                            "title": title,
                            "url": url,
                            "snippet": snippet,
                            "date": "",
                            "has_negative": False,
                            "comments": [],
                            "comment_count": 0
                        })
                        logger.info(f"  [Bingå¤‡ç”¨] âœ“ æ‰¾åˆ°: {title[:50]}...")
                        
                except Exception as e:
                    logger.debug(f"  å¤„ç† Bing ç»“æœå¤±è´¥: {str(e)}")
                    continue
            
            logger.info(f"[Bingå¤‡ç”¨] å…±æ‰¾åˆ° {len(results)} æ¡ç»“æœ")
            
        except Exception as e:
            logger.warning(f"Bing å¤‡ç”¨æ–¹æ¡ˆå¤±è´¥: {str(e)}")
        
        return results
    
    def _get_xhs_note_detail(self, note_url: str, brand_name: str) -> Dict[str, Any]:
        """
        è·å–å°çº¢ä¹¦ç¬”è®°è¯¦æƒ…ï¼ˆæ ‡é¢˜ã€å†…å®¹ã€è¯„è®ºã€äº’åŠ¨æ•°æ®ï¼‰
        
        Args:
            note_url: ç¬”è®°URL
            brand_name: å“ç‰Œå
        
        Returns:
            è¯¦æƒ…æ•°æ®å­—å…¸
        """
        detail = {}
        new_tab = None
        
        try:
            new_tab = self.page.new_tab()
            new_tab.get(note_url)
            time.sleep(random.uniform(3, 5))
            
            # æå–æ ‡é¢˜
            try:
                title_ele = new_tab.ele('tag:h1', timeout=3)
                if not title_ele:
                    title_ele = new_tab.ele('tag:div@class*=title', timeout=3)
                if title_ele:
                    detail['title'] = title_ele.text.strip()
            except:
                pass
            
            # æå–æ­£æ–‡å†…å®¹
            try:
                content_ele = new_tab.ele('tag:div@class*=desc', timeout=3)
                if not content_ele:
                    content_ele = new_tab.ele('tag:div@class*=content', timeout=3)
                if content_ele:
                    detail['content'] = content_ele.text.strip()[:500]  # æˆªå–å‰500å­—
            except:
                pass
            
            # æå–ä½œè€…
            try:
                author_ele = new_tab.ele('tag:span@class*=author', timeout=2)
                if not author_ele:
                    author_ele = new_tab.ele('tag:a@class*=user', timeout=2)
                if author_ele:
                    detail['author'] = author_ele.text.strip()
            except:
                pass
            
            # æå–å‘å¸ƒæ—¶é—´
            try:
                time_ele = new_tab.ele('tag:span@class*=time', timeout=2)
                if time_ele:
                    detail['date'] = time_ele.text.strip()
            except:
                pass
            
            # æå–äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµã€æ”¶è—ã€è¯„è®ºæ•°ï¼‰
            try:
                # ç‚¹èµæ•°
                like_ele = new_tab.ele('tag:span@class*=like', timeout=2)
                if like_ele:
                    detail['likes'] = like_ele.text.strip() or "0"
                
                # æ”¶è—æ•°
                collect_ele = new_tab.ele('tag:span@class*=collect', timeout=2)
                if collect_ele:
                    detail['collects'] = collect_ele.text.strip() or "0"
                
                # è¯„è®ºæ•°
                comment_count_ele = new_tab.ele('tag:span@class*=comment', timeout=2)
                if comment_count_ele:
                    detail['comment_count'] = comment_count_ele.text.strip() or "0"
            except:
                pass
            
            # è·å–çƒ­é—¨è¯„è®ºï¼ˆå‰5æ¡ï¼‰
            comments = []
            try:
                # æ»šåŠ¨åˆ°è¯„è®ºåŒº
                new_tab.scroll.down(500)
                time.sleep(2)
                
                comment_items = new_tab.eles('tag:div@class*=comment', timeout=3)
                for item in comment_items[:5]:
                    try:
                        content_ele = item.ele('tag:p', timeout=1)
                        if not content_ele:
                            content_ele = item.ele('tag:span', timeout=1)
                        if content_ele:
                            comment_text = content_ele.text.strip()
                            if comment_text and 10 <= len(comment_text) <= 200:
                                # æå–ç‚¹èµæ•°
                                like_count = "0"
                                try:
                                    like_ele = item.ele('tag:span@class*=like', timeout=1)
                                    if like_ele:
                                        like_count = like_ele.text.strip() or "0"
                                except:
                                    pass
                                
                                comments.append({
                                    'content': comment_text[:200],
                                    'likes': like_count
                                })
                    except:
                        continue
                
                detail['top_comments'] = comments
                detail['comment_count'] = len(comments)
            except:
                pass
            
            new_tab.close()
            
        except Exception as e:
            logger.debug(f"  è·å–è¯¦æƒ…å¤±è´¥: {str(e)}")
            if new_tab:
                try:
                    new_tab.close()
                except:
                    pass
        
        return detail
    
    def crawl_xhs(self) -> List[Dict[str, Any]]:
        """
        ç¬¬äºŒé˜¶æ®µï¼šå°çº¢ä¹¦é‡‡é›†ï¼ˆåˆ—è¡¨é¡µæŠ“å– - ä¸è¿›å…¥è¯¦æƒ…é¡µï¼‰
        
        æ ¸å¿ƒç­–ç•¥ï¼š
        1. ä½¿ç”¨ DrissionPage æ¥ç®¡å·²ç™»å½•çš„ Chrome æµè§ˆå™¨ï¼ˆç«¯å£ 9222ï¼‰
        2. åªæŠ“å–åˆ—è¡¨é¡µèƒ½çœ‹åˆ°çš„æ ‡é¢˜ã€é“¾æ¥ã€ä½œè€…å
        3. ä¸è¿›å…¥è¯¦æƒ…é¡µï¼Œé¿å…è¢«é£æ§å±è”½
        4. å¦‚æœåˆ—è¡¨é¡µè·å–å¤±è´¥ï¼Œä½¿ç”¨ Bing æœç´¢ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
        """
        if not self.page:
            logger.error("æµè§ˆå™¨æœªåˆå§‹åŒ–")
            return []
        
        logger.info("=" * 80)
        logger.info("ç¬¬äºŒé˜¶æ®µï¼šå°çº¢ä¹¦é‡‡é›†ï¼ˆåˆ—è¡¨é¡µæŠ“å–æ¨¡å¼ï¼‰")
        logger.info("=" * 80)
        
        results = []
        
        try:
            for brand_name in KEYWORDS:
                # ä½¿ç”¨ç»„åˆå…³é”®è¯æœç´¢
                search_queries = SEARCH_QUERIES.get(brand_name, [brand_name])
                logger.info(f"å“ç‰Œ: {brand_name}ï¼Œä½¿ç”¨ {len(search_queries)} ä¸ªç»„åˆå…³é”®è¯æœç´¢")
                
                for keyword in search_queries:
                    try:
                        logger.info(f"æœç´¢å…³é”®è¯: {keyword}")
                        print(f"[å°çº¢ä¹¦åˆ—è¡¨é¡µ] æœç´¢å…³é”®è¯: {keyword}")
                        
                        # å…ˆè®¿é—®é¦–é¡µï¼Œå»ºç«‹sessionï¼ˆåçˆ¬ç­–ç•¥ï¼‰
                        try:
                            self.page.get("https://www.xiaohongshu.com/explore")
                            self.human_like_delay(3, 5)
                            self.move_mouse_randomly()
                        except:
                            pass
                        
                        # è®¿é—®å°çº¢ä¹¦æœç´¢ç»“æœé¡µ
                        search_url = f"https://www.xiaohongshu.com/search_result?keyword={keyword}&source=web_search_result_notes"
                        logger.info(f"  è®¿é—®æœç´¢é¡µ: {search_url}")
                        print(f"[å°çº¢ä¹¦æœç´¢] è®¿é—®æœç´¢é¡µ: {search_url}")
                        self.page.get(search_url)
                        self.human_like_delay(4, 6)
                        self.move_mouse_randomly()
                        
                        logger.info(f"  å½“å‰é¡µé¢ URL: {self.page.url}")
                        print(f"[å°çº¢ä¹¦æœç´¢] å½“å‰é¡µé¢ URL: {self.page.url}")
                        
                        # å°è¯•ç‚¹å‡»"æœ€æ–°"æ’åºï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        try:
                            logger.info("  å°è¯•ç‚¹å‡»'æœ€æ–°'æ’åº...")
                            print("[å°çº¢ä¹¦æœç´¢] å°è¯•ç‚¹å‡»'æœ€æ–°'æ’åº...")
                            sort_btn = None
                            sort_selectors = [
                                'text:æœ€æ–°',
                                'text:æŒ‰æ—¶é—´',
                                'xpath://div[contains(text(), "æœ€æ–°")]',
                            ]
                            for selector in sort_selectors:
                                try:
                                    sort_btn = self.page.ele(selector, timeout=2)
                                    if sort_btn:
                                        logger.info(f"  âœ“ æ‰¾åˆ°'æœ€æ–°'æ’åº")
                                        print(f"[å°çº¢ä¹¦æœç´¢] âœ“ æ‰¾åˆ°'æœ€æ–°'æ’åº")
                                        sort_btn.click()
                                        time.sleep(2)
                                        break
                                except:
                                    continue
                        except Exception as e:
                            logger.warning(f"  ç‚¹å‡»'æœ€æ–°'æ’åºå¤±è´¥: {str(e)}")
                            print(f"[å°çº¢ä¹¦æœç´¢] ç‚¹å‡»'æœ€æ–°'æ’åºå¤±è´¥: {str(e)}")
                        
                        # Smart Wait: ç­‰å¾…é¡µé¢å…ƒç´ åŠ è½½ï¼ˆæ£€æµ‹ .note-item æ˜¯å¦å‡ºç°ï¼‰
                        print("[å°çº¢ä¹¦æœç´¢] Smart Wait: ç­‰å¾…ç¬”è®°å¡ç‰‡åŠ è½½...")
                        note_items = []
                        max_wait_time = 10  # æœ€å¤šç­‰å¾…10ç§’
                        wait_interval = 1
                        waited_time = 0
                        
                        # å°è¯•å¤šç§é€‰æ‹©å™¨æŸ¥æ‰¾ç¬”è®°å¡ç‰‡
                        selectors_to_try = [
                            'css:section.note-item',
                            'css:div.note-item',
                            'css:div[class*="note-item"]',
                            'css:a.cover',
                            'css:div[class*="note"]',
                            'xpath://section[contains(@class, "note")]',
                            'xpath://div[contains(@class, "note-item")]',
                            'xpath://a[contains(@href, "/explore/")]',
                        ]
                        
                        while waited_time < max_wait_time:
                            try:
                                for selector in selectors_to_try:
                                    try:
                                        items = self.page.eles(selector, timeout=2)
                                        if items and len(items) > 0:
                                            note_items = items
                                            logger.info(f"  âœ“ æ‰¾åˆ° {len(items)} ä¸ªç¬”è®°å¡ç‰‡ï¼ˆä½¿ç”¨: {selector}ï¼‰")
                                            print(f"[å°çº¢ä¹¦æœç´¢] âœ“ æ‰¾åˆ° {len(items)} ä¸ªç¬”è®°å¡ç‰‡ï¼ˆä½¿ç”¨: {selector}ï¼‰")
                                            break
                                    except:
                                        continue
                                
                                if note_items:
                                    break
                                
                                time.sleep(wait_interval)
                                waited_time += wait_interval
                                print(f"  [å°çº¢ä¹¦æœç´¢] ç­‰å¾…ä¸­... ({waited_time}/{max_wait_time}ç§’)")
                                
                            except Exception as e:
                                logger.debug(f"  Smart Wait æ£€æµ‹å¤±è´¥: {str(e)}")
                                time.sleep(wait_interval)
                                waited_time += wait_interval
                        
                        if not note_items:
                            logger.warning(f"æœªæ‰¾åˆ°ç¬”è®°å¡ç‰‡ï¼Œå°è¯•æ»šåŠ¨åŠ è½½...")
                            print("[å°çº¢ä¹¦æœç´¢] æœªæ‰¾åˆ°ç¬”è®°å¡ç‰‡ï¼Œå°è¯•æ»šåŠ¨åŠ è½½...")
                        
                        # äººç±»è¡Œä¸ºæ¨¡æ‹Ÿï¼šæ»šåŠ¨åŠ è½½æ›´å¤šå†…å®¹
                        self.human_like_scroll()
                        self.move_mouse_randomly()
                        
                        # æ»šåŠ¨åå†æ¬¡å°è¯•æŸ¥æ‰¾ç¬”è®°å¡ç‰‡
                        if not note_items:
                            for selector in selectors_to_try[:3]:  # åªè¯•å‰3ä¸ª
                                try:
                                    items = self.page.eles(selector, timeout=2)
                                    if items and len(items) > 0:
                                        note_items = items
                                        logger.info(f"  âœ“ æ»šåŠ¨åæ‰¾åˆ° {len(items)} ä¸ªç¬”è®°å¡ç‰‡")
                                        print(f"[å°çº¢ä¹¦æœç´¢] âœ“ æ»šåŠ¨åæ‰¾åˆ° {len(items)} ä¸ªç¬”è®°å¡ç‰‡")
                                        break
                                except:
                                    continue
                        
                        # Data Extraction: ä»åˆ—è¡¨é¡µæå–æ•°æ®ï¼ˆä¸è¿›å…¥è¯¦æƒ…é¡µï¼‰
                        print("[å°çº¢ä¹¦åˆ—è¡¨é¡µ] å¼€å§‹æå–åˆ—è¡¨é¡µæ•°æ®...")
                        keyword_results = []
                        
                        if note_items:
                            print(f"[å°çº¢ä¹¦åˆ—è¡¨é¡µ] æ‰¾åˆ° {len(note_items)} ä¸ªç¬”è®°å¡ç‰‡ï¼Œå¼€å§‹æå–...")
                            
                            for idx, card in enumerate(note_items[:10], 1):  # æœ€å¤šå¤„ç†10ä¸ª
                                try:
                                    # æå–æ ‡é¢˜ï¼ˆç»ˆæä¼˜åŒ–ï¼šå¤šç§æ–¹å¼ + HTMLæ­£åˆ™å¤‡é€‰ï¼‰
                                    title = ""
                                    try:
                                        # æ–¹æ³•1ï¼šä»å¡ç‰‡å…ƒç´ ç›´æ¥æå–ï¼ˆå¤šç§é€‰æ‹©å™¨ï¼‰
                                        title_selectors = [
                                            'css:a.title span',
                                            'css:span.title',
                                            'css:div.title span',
                                            'css:p.title',
                                            'css:a span[class*="title"]',
                                            'css:a.title',
                                            'css:span.title',
                                            'css:div.title',
                                            'tag:h2',
                                            'tag:h3',
                                            'tag:a',
                                            'tag:div@class*=title',
                                            'tag:span@class*=title',
                                            'xpath://a[contains(@href, "/explore/")]//span',
                                            'xpath://div[contains(@class, "title")]',
                                        ]
                                        
                                        for sel in title_selectors:
                                            try:
                                                title_elem = card.ele(sel, timeout=1)
                                                if title_elem:
                                                    title_text = title_elem.text or ""
                                                    # å¦‚æœæ‰¾åˆ°æ ‡é¢˜ï¼Œæ¸…ç†ä¸€ä¸‹
                                                    if title_text and len(title_text.strip()) > 3:
                                                        title = title_text.strip()
                                                        logger.debug(f"    ä½¿ç”¨ {sel} æå–åˆ°æ ‡é¢˜: {title[:30]}")
                                                        break
                                            except:
                                                continue
                                        
                                        # æ–¹æ³•2ï¼šè·å–å¡ç‰‡å†…ç¬¬ä¸€ä¸ªæœ‰æ„ä¹‰çš„æ–‡æœ¬ï¼ˆè¿‡æ»¤æ‰æ•°å­—å’Œå¤ªçŸ­çš„æ–‡æœ¬ï¼‰
                                        if not title:
                                            try:
                                                all_spans = card.eles('css:span')
                                                for span in all_spans:
                                                    text = span.text.strip() if span.text else ""
                                                    # è¿‡æ»¤æ‰æ•°å­—ï¼ˆç‚¹èµæ•°ï¼‰å’Œå¤ªçŸ­çš„æ–‡æœ¬
                                                    if len(text) > 5 and not text.isdigit() and not text.startswith('@'):
                                                        title = text
                                                        logger.debug(f"    ä»spanæå–åˆ°æ ‡é¢˜: {title[:30]}")
                                                        break
                                            except:
                                                pass
                                        
                                        # æ–¹æ³•3ï¼šä»é“¾æ¥çš„titleå±æ€§è·å–
                                        if not title:
                                            try:
                                                link_ele = card.ele('css:a', timeout=1)
                                                if link_ele:
                                                    title = link_ele.attr('title') or ""
                                                    if title:
                                                        logger.debug(f"    ä»é“¾æ¥titleå±æ€§æå–åˆ°æ ‡é¢˜: {title[:30]}")
                                            except:
                                                pass
                                        
                                        # æ–¹æ³•4ï¼šä»é“¾æ¥æ–‡æœ¬æå–
                                        if not title:
                                            try:
                                                link_elem = card.ele('tag:a', timeout=1)
                                                if link_elem:
                                                    link_text = link_elem.text or ""
                                                    if link_text and len(link_text.strip()) > 3:
                                                        title = link_text.strip()
                                                        logger.debug(f"    ä»é“¾æ¥æ–‡æœ¬æå–åˆ°æ ‡é¢˜: {title[:30]}")
                                            except:
                                                pass
                                        
                                        # æ–¹æ³•5ï¼šä»HTMLæ­£åˆ™æå–ï¼ˆå¦‚æœå‰é¢éƒ½å¤±è´¥ï¼‰
                                        if not title:
                                            try:
                                                card_html = card.html
                                                # åŒ¹é… href + æ ‡é¢˜æ–‡æœ¬çš„æ¨¡å¼
                                                title_patterns = [
                                                    r'href="(/explore/[a-f0-9]{24})"[^>]*>.*?<span[^>]*>([^<]{5,100})</span>',
                                                    r'<a[^>]*href="(/explore/[a-f0-9]{24})"[^>]*>.*?<span[^>]*>([^<]+)</span>',
                                                    r'title["\s:=]+["\']?([^"\']{5,100})["\']?',
                                                ]
                                                for pattern in title_patterns:
                                                    match = re.search(pattern, card_html, re.DOTALL | re.IGNORECASE)
                                                    if match:
                                                        if len(match.groups()) > 1:
                                                            title = match.group(2).strip()
                                                        else:
                                                            title = match.group(1).strip()
                                                        if title and len(title) > 3:
                                                            logger.debug(f"    ä»HTMLæ­£åˆ™æå–åˆ°æ ‡é¢˜: {title[:30]}")
                                                            break
                                            except:
                                                pass
                                    except Exception as e:
                                        logger.debug(f"  æå–æ ‡é¢˜å¤±è´¥: {str(e)}")
                                        pass
                                    
                                    # æå–é“¾æ¥
                                    url = ""
                                    try:
                                        link_elem = card.ele('tag:a', timeout=1)
                                        if link_elem:
                                            href = link_elem.attr('href') or ''
                                            
                                            # å¤„ç†ç›¸å¯¹é“¾æ¥
                                            if href:
                                                if not href.startswith('http'):
                                                    if href.startswith('//'):
                                                        href = 'https:' + href
                                                    elif href.startswith('/'):
                                                        href = 'https://www.xiaohongshu.com' + href
                                                    else:
                                                        continue
                                                
                                                if 'explore' in href and 'xiaohongshu.com' in href:
                                                    url = href
                                    except:
                                        pass
                                    
                                    # æå–ä½œè€…å
                                    author = ""
                                    try:
                                        author_selectors = [
                                            'tag:span@class*=author',
                                            'tag:div@class*=author',
                                            'tag:a@class*=user',
                                        ]
                                        
                                        for sel in author_selectors:
                                            try:
                                                author_elem = card.ele(sel, timeout=1)
                                                if author_elem:
                                                    author = author_elem.text or ""
                                                    if author:
                                                        break
                                            except:
                                                continue
                                    except:
                                        pass
                                    
                                    # æå–å°é¢æ–‡å­—ï¼ˆå¦‚æœæœ‰ï¼‰
                                    snippet = ""
                                    try:
                                        desc_elem = card.ele('tag:div@class*=desc', timeout=1)
                                        if desc_elem:
                                            snippet = desc_elem.text or ""
                                    except:
                                        pass
                                    
                                    # åªä¿å­˜æœ‰æ ‡é¢˜æˆ–é“¾æ¥çš„æ•°æ®
                                    if title or url:
                                        # å¦‚æœæ ‡é¢˜ä¸ºç©ºï¼Œå°è¯•ä»é“¾æ¥æˆ–å…¶ä»–åœ°æ–¹æå–
                                        if not title or len(title.strip()) < 3:
                                            # å°è¯•ä»é“¾æ¥æ–‡æœ¬æå–
                                            try:
                                                link_elem = card.ele('tag:a', timeout=1)
                                                if link_elem:
                                                    link_text = link_elem.text or ""
                                                    if link_text and len(link_text.strip()) > 3:
                                                        title = link_text.strip()
                                            except:
                                                pass
                                        
                                        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ ‡é¢˜ï¼Œè·³è¿‡
                                        if not title or len(title.strip()) < 3:
                                            logger.debug(f"  è·³è¿‡ï¼ˆæ ‡é¢˜ä¸ºç©ºæˆ–è¿‡çŸ­ï¼‰: {url[:50] if url else 'æ— é“¾æ¥'}")
                                            continue
                                        
                                        # ä¸¥æ ¼å†…å®¹è¿‡æ»¤ï¼ˆå››å±‚è¿‡æ»¤ï¼‰
                                        item_data = {
                                            "title": title,
                                            "content": snippet,
                                            "snippet": snippet
                                        }
                                        is_valid, reason = self.strict_content_filter(brand_name, item_data)
                                        
                                        if not is_valid:
                                            logger.info(f"  âœ— è¿‡æ»¤: {reason} - {title[:50] if title else 'æ— æ ‡é¢˜'}...")
                                            print(f"[å°çº¢ä¹¦æœç´¢] âœ— è¿‡æ»¤: {reason} - {title[:50] if title else 'æ— æ ‡é¢˜'}...")
                                            continue
                                        
                                        # æ£€æŸ¥æ˜¯å¦åŒ…å«è´Ÿé¢å…³é”®è¯
                                        negative_keywords = ['é¿é›·', 'å‘', 'é€€è´¹', 'éª—å±€', 'æŠ•è¯‰', 'å·®è¯„', 'åƒåœ¾', 'ä¸è¦', 'åƒä¸‡åˆ«', 'åµæ¶']
                                        has_negative = any(kw in (title + snippet) for kw in negative_keywords)
                                        
                                        result = {
                                            "platform": "å°çº¢ä¹¦",
                                            "keyword": brand_name,  # ä½¿ç”¨å“ç‰Œåè€Œä¸æ˜¯æœç´¢å…³é”®è¯
                                            "search_query": keyword,  # è®°å½•å®é™…æœç´¢çš„å…³é”®è¯
                                            "title": title.strip() or f"ç¬”è®° {idx}",
                                            "url": url,
                                            "date": "",  # åˆ—è¡¨é¡µé€šå¸¸æ²¡æœ‰å‘å¸ƒæ—¶é—´
                                            "snippet": snippet.strip(),
                                            "content": snippet.strip(),  # æ·»åŠ contentå­—æ®µç”¨äºè¯¦æƒ…
                                            "author": author.strip(),  # æ–°å¢ä½œè€…å­—æ®µ
                                            "has_negative": has_negative,
                                            "comments": [],  # åˆ—è¡¨é¡µä¸æŠ“å–è¯„è®ºï¼Œåç»­ä¼šè¡¥å……
                                            "comment_count": 0,
                                            "likes": "0",  # åˆ—è¡¨é¡µæš‚ä¸è·å–ï¼Œåç»­è¡¥å……
                                            "is_valid": True
                                        }
                                        
                                        keyword_results.append(result)
                                        logger.info(f"  âœ“ æå–æˆåŠŸ: {title[:50] if title else 'æ— æ ‡é¢˜'}... (ä½œè€…: {author[:20] if author else 'æœªçŸ¥'})")
                                        print(f"[å°çº¢ä¹¦åˆ—è¡¨é¡µ] âœ“ æå–æˆåŠŸ: {title[:50] if title else 'æ— æ ‡é¢˜'}... (ä½œè€…: {author[:20] if author else 'æœªçŸ¥'})")
                                        
                                        if len(keyword_results) >= 5:
                                            break
                                        
                                except Exception as e:
                                    logger.debug(f"  å¤„ç†ç¬”è®°å¡ç‰‡ {idx} å¤±è´¥: {str(e)}")
                                    continue
                        
                        # å¦‚æœåˆ—è¡¨é¡µè·å–å¤±è´¥ï¼Œä½¿ç”¨ Bing å¤‡ç”¨æ–¹æ¡ˆ
                        if not keyword_results:
                            logger.warning(f"åˆ—è¡¨é¡µæœªè·å–åˆ°æ•°æ®ï¼Œå¯ç”¨ Bing å¤‡ç”¨æ–¹æ¡ˆ...")
                            print(f"[å°çº¢ä¹¦åˆ—è¡¨é¡µ] åˆ—è¡¨é¡µæœªè·å–åˆ°æ•°æ®ï¼Œå¯ç”¨ Bing å¤‡ç”¨æ–¹æ¡ˆ...")
                            bing_results = self.fetch_from_bing(keyword)
                            # å¯¹Bingç»“æœä¹Ÿè¿›è¡Œä¸¥æ ¼è¿‡æ»¤
                            for bing_item in bing_results:
                                is_valid, reason = self.strict_content_filter(brand_name, bing_item)
                                if is_valid:
                                    bing_item['keyword'] = brand_name
                                    bing_item['search_query'] = keyword
                                    bing_item['is_valid'] = True
                                    keyword_results.append(bing_item)
                        
                        # å°è¯•è·å–è¯¦æƒ…é¡µå†…å®¹ï¼ˆæœ€å¤š3ä¸ªï¼Œé¿å…è¢«é£æ§ï¼‰
                        for item in keyword_results[:3]:
                            if item.get('url'):
                                try:
                                    detail = self._get_xhs_note_detail(item['url'], brand_name)
                                    if detail:
                                        item.update(detail)
                                        time.sleep(random.uniform(3, 5))  # æ¯ä¸ªè¯¦æƒ…é¡µé—´éš”ä¹…ä¸€ç‚¹
                                except Exception as e:
                                    logger.debug(f"  è·å–è¯¦æƒ…å¤±è´¥: {str(e)}")
                                    continue
                        
                        results.extend(keyword_results)
                        time.sleep(random.uniform(2, 3))
                    
                    except Exception as e:
                        logger.error(f"é‡‡é›†å…³é”®è¯ {keyword} å¤±è´¥: {str(e)}")
                        print(f"[å°çº¢ä¹¦åˆ—è¡¨é¡µ] é‡‡é›†å…³é”®è¯ {keyword} å¤±è´¥: {str(e)}")
                        continue
                
                # æ¯ä¸ªå“ç‰Œæœç´¢å®Œæˆåç¨ä½œåœé¡¿
                time.sleep(random.uniform(1, 2))
            
        except Exception as e:
            logger.error(f"å°çº¢ä¹¦é‡‡é›†å¼‚å¸¸: {str(e)}", exc_info=True)
            print(f"[å°çº¢ä¹¦åˆ—è¡¨é¡µ] é‡‡é›†å¼‚å¸¸: {str(e)}")
        
        logger.info(f"å°çº¢ä¹¦é‡‡é›†å®Œæˆï¼Œå…±æ‰¾åˆ° {len(results)} æ¡æœ‰æ•ˆæ•°æ®")
        print(f"[å°çº¢ä¹¦åˆ—è¡¨é¡µ] é‡‡é›†å®Œæˆï¼Œå…±æ‰¾åˆ° {len(results)} æ¡æœ‰æ•ˆæ•°æ®")
        self.xhs_data = results
        return results
    
    def crawl_wechat(self) -> List[Dict[str, Any]]:
        """
        ç¬¬äºŒé˜¶æ®µï¼šæœç‹—å¾®ä¿¡é‡‡é›†
        æŠ“å–æ–‡ç« æ ‡é¢˜ã€æ‘˜è¦ã€æ—¶é—´ï¼ˆæ— éœ€è¿›å…¥è¯¦æƒ…é¡µï¼‰
        """
        if not self.page:
            logger.error("æµè§ˆå™¨æœªåˆå§‹åŒ–")
            return []
        
        logger.info("=" * 80)
        logger.info("ç¬¬äºŒé˜¶æ®µï¼šæœç‹—å¾®ä¿¡é‡‡é›†")
        logger.info("=" * 80)
        
        results = []
        
        try:
            # åˆ‡æ¢åˆ°æœç‹—å¾®ä¿¡æ ‡ç­¾é¡µ
            self.page.get('https://weixin.sogou.com')
            time.sleep(3)
            
            for brand_name in KEYWORDS:
                # ä½¿ç”¨ç»„åˆå…³é”®è¯æœç´¢
                search_queries = SEARCH_QUERIES.get(brand_name, [brand_name])
                logger.info(f"å“ç‰Œ: {brand_name}ï¼Œä½¿ç”¨ {len(search_queries)} ä¸ªç»„åˆå…³é”®è¯æœç´¢")
                
                for keyword in search_queries:
                    try:
                        logger.info(f"æœç´¢å…³é”®è¯: {keyword}")
                        
                        # è®¿é—®æœç´¢ç»“æœé¡µ
                        search_url = f"https://weixin.sogou.com/weixin?type=2&query={keyword}"
                        logger.info(f"  è®¿é—®æœç´¢é¡µ: {search_url}")
                        print(f"[æœç‹—å¾®ä¿¡æœç´¢] è®¿é—®æœç´¢é¡µ: {search_url}")
                        self.page.get(search_url)
                        time.sleep(random.uniform(3, 5))
                        
                        # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°å½“å‰é¡µé¢çŠ¶æ€
                        logger.info(f"  å½“å‰é¡µé¢ URL: {self.page.url}")
                        print(f"[æœç‹—å¾®ä¿¡æœç´¢] å½“å‰é¡µé¢ URL: {self.page.url}")
                        
                        # å¤„ç†å¯èƒ½çš„éªŒè¯ç 
                        try:
                            verify_img = self.page.ele('tag:img@id=seccodeImage', timeout=2)
                            if verify_img:
                                logger.warning("âš ï¸ æ£€æµ‹åˆ°éªŒè¯ç ï¼Œè¯·æ‰‹åŠ¨å®ŒæˆéªŒè¯åæŒ‰å›è½¦ç»§ç»­...")
                                try:
                                    input("éªŒè¯å®ŒæˆåæŒ‰å›è½¦ç»§ç»­...")
                                except EOFError:
                                    time.sleep(10)
                        except:
                            pass
                        
                        # æå–æ–‡ç« åˆ—è¡¨ï¼ˆå‰5æ¡ï¼‰- ä½¿ç”¨ class="txt-box" ç­–ç•¥
                        txt_boxes = []
                        try:
                            # æ–°é€»è¾‘ï¼šç›´æ¥æŸ¥æ‰¾åŒ…å« class="txt-box" çš„ div å…ƒç´ 
                            txt_boxes = self.page.eles('tag:div@class=txt-box', timeout=5)
                            logger.info(f"é¡µé¢ä¸­å…±æ‰¾åˆ° {len(txt_boxes)} ä¸ª txt-box å…ƒç´ ")
                            
                            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…
                            if not txt_boxes:
                                txt_boxes = self.page.eles('tag:div@class*=txt-box', timeout=5)
                                logger.info(f"ä½¿ç”¨éƒ¨åˆ†åŒ¹é…æ‰¾åˆ° {len(txt_boxes)} ä¸ª txt-box å…ƒç´ ")
                            
                            # é™åˆ¶ä¸ºå‰5ä¸ª
                            txt_boxes = txt_boxes[:5]
                            
                            # å¦‚æœæœªæ‰¾åˆ°ï¼Œæ‰“å°è°ƒè¯•ä¿¡æ¯
                            if not txt_boxes:
                                logger.warning(f"âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ° txt-box å…ƒç´ ")
                                try:
                                    page_html_preview = self.page.html[:500] if hasattr(self.page, 'html') else "æ— æ³•è·å–HTML"
                                    logger.warning(f"é¡µé¢å‰500å­—ç¬¦é¢„è§ˆ: {page_html_preview}")
                                except:
                                    logger.warning("æ— æ³•è·å–é¡µé¢HTMLé¢„è§ˆ")
                            
                        except Exception as e:
                            logger.warning(f"æå–æ–‡ç« åˆ—è¡¨å¤±è´¥: {str(e)}")
                            # æ‰“å°è°ƒè¯•ä¿¡æ¯
                            try:
                                page_html_preview = self.page.html[:500] if hasattr(self.page, 'html') else "æ— æ³•è·å–HTML"
                                logger.warning(f"é”™è¯¯æ—¶é¡µé¢å‰500å­—ç¬¦é¢„è§ˆ: {page_html_preview}")
                            except:
                                pass
                            continue
                        
                        if not txt_boxes:
                            logger.warning(f"æœªæ‰¾åˆ°ä»»ä½•æ–‡ç« ï¼Œè·³è¿‡å…³é”®è¯: {keyword}")
                            continue
                        
                        # æå–æ–‡ç« ä¿¡æ¯
                        for idx, txt_box in enumerate(txt_boxes, 1):
                            try:
                                # åœ¨ txt-box ä¸‹æŸ¥æ‰¾ h3 a è·å–æ ‡é¢˜å’Œé“¾æ¥
                                title = ""
                                url = ""
                                
                                try:
                                    # æŸ¥æ‰¾ h3 ä¸‹çš„ a æ ‡ç­¾
                                    h3_elem = txt_box.ele('tag:h3', timeout=1)
                                    if h3_elem:
                                        link_elem = h3_elem.ele('tag:a', timeout=1)
                                        if link_elem:
                                            url = link_elem.attr('href') or ""
                                            title = link_elem.text or ""
                                        
                                        # å¦‚æœ h3 ä¸‹æ²¡æœ‰ aï¼Œç›´æ¥å– h3 æ–‡æœ¬
                                        if not title:
                                            title = h3_elem.text or ""
                                except Exception as e:
                                    logger.debug(f"    æå–æ ‡é¢˜å¤±è´¥: {str(e)}")
                                
                                # å¤„ç†é“¾æ¥
                                if url and not url.startswith('http'):
                                    if url.startswith('//'):
                                        url = 'https:' + url
                                    elif url.startswith('/'):
                                        url = 'https://weixin.sogou.com' + url
                                
                                # åœ¨ txt-box ä¸‹æŸ¥æ‰¾ p è·å–æ‘˜è¦
                                snippet = ""
                                try:
                                    p_elem = txt_box.ele('tag:p', timeout=1)
                                    if p_elem:
                                        snippet = p_elem.text or ""
                                except:
                                    pass
                                
                                # æå–å‘å¸ƒæ—¶é—´ï¼ˆé€šå¸¸åœ¨ txt-box åŒçº§æˆ–çˆ¶çº§ï¼‰
                                date_str = ""
                                try:
                                    # å°è¯•åœ¨ txt-box å†…æŸ¥æ‰¾æ—¶é—´
                                    date_elem = txt_box.ele('tag:span@class*=time', timeout=1)
                                    if not date_elem:
                                        date_elem = txt_box.ele('tag:span', timeout=1)
                                    if date_elem:
                                        date_text = date_elem.text or ""
                                        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¥æœŸæ ¼å¼
                                        if any(kw in date_text for kw in ['-', 'å¹´', 'æœˆ', 'æ—¥', 'å‰', 'å°æ—¶', 'åˆ†é’Ÿ']):
                                            date_str = date_text
                                except:
                                    pass
                                
                                # æ—¶é—´è¿‡æ»¤ï¼šåªä¿ç•™æœ€è¿‘ä¸€å‘¨å†…
                                if date_str and not self.is_recent(date_str):
                                    logger.info(f"    æ–‡ç« è¶…å‡º{DAYS_BACK}å¤©èŒƒå›´ï¼Œè·³è¿‡: {date_str}")
                                    continue
                                
                                if title or url:
                                    # ä¸¥æ ¼å†…å®¹è¿‡æ»¤
                                    item_data = {
                                        "title": title,
                                        "content": snippet,
                                        "snippet": snippet
                                    }
                                    is_valid, reason = self.strict_content_filter(brand_name, item_data)
                                    
                                    if not is_valid:
                                        logger.info(f"  âœ— è¿‡æ»¤: {reason} - {title[:50] if title else 'æ— æ ‡é¢˜'}...")
                                        continue
                                    
                                    result = {
                                        "platform": "æœç‹—å¾®ä¿¡",
                                        "keyword": brand_name,  # ä½¿ç”¨å“ç‰Œåè€Œä¸æ˜¯æœç´¢å…³é”®è¯
                                        "search_query": keyword,  # è®°å½•å®é™…æœç´¢çš„å…³é”®è¯
                                        "title": title.strip() or f"æ–‡ç«  {idx}",
                                        "url": url or "",
                                        "date": date_str.strip(),
                                        "snippet": snippet.strip(),
                                        "content": snippet.strip(),  # æ·»åŠ contentå­—æ®µ
                                        "comments": [],  # å¾®ä¿¡æ–‡ç« ä¸æŠ“è¯„è®º
                                        "comment_count": 0,
                                        "is_valid": True
                                    }
                                    results.append(result)
                                    logger.info(f"  âœ“ é‡‡é›†æˆåŠŸ: {title[:50] if title else 'æ— æ ‡é¢˜'}...")
                                
                            except Exception as e:
                                logger.warning(f"  å¤„ç†æ–‡ç«  {idx} å¤±è´¥: {str(e)}")
                                continue
                        
                        time.sleep(random.uniform(2, 3))
                    
                    except Exception as e:
                        logger.error(f"é‡‡é›†å…³é”®è¯ {keyword} å¤±è´¥: {str(e)}")
                        continue
                
                # æ¯ä¸ªå“ç‰Œæœç´¢å®Œæˆåç¨ä½œåœé¡¿
                time.sleep(random.uniform(1, 2))
            
        except Exception as e:
            logger.error(f"æœç‹—å¾®ä¿¡é‡‡é›†å¼‚å¸¸: {str(e)}", exc_info=True)
        
        logger.info(f"æœç‹—å¾®ä¿¡é‡‡é›†å®Œæˆï¼Œå…±æ‰¾åˆ° {len(results)} æ¡æœ‰æ•ˆæ•°æ®")
        self.wechat_data = results
        return results
    
    def save_raw_data(self):
        """ä¿å­˜åŸå§‹æ•°æ®åˆ° CSV"""
        all_data = self.douyin_data + self.xhs_data + self.wechat_data
        
        if not all_data:
            logger.warning("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return
        
        # è½¬æ¢ä¸º DataFrame
        df_data = []
        for item in all_data:
            # å¤„ç†è¯„è®ºæ•°æ®ï¼ˆå¯èƒ½æ˜¯åˆ—è¡¨æˆ–å­—å…¸åˆ—è¡¨ï¼‰
            comments_text = ""
            if item.get("comments"):
                comments_list = item.get("comments", [])
                if comments_list and isinstance(comments_list[0], dict):
                    # å¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼ˆåŒ…å«contentå’Œlikesï¼‰
                    comments_text = "\n".join([f"{c.get('content', '')} (ğŸ‘{c.get('likes', '0')})" for c in comments_list])
                else:
                    # å¦‚æœæ˜¯çº¯æ–‡æœ¬åˆ—è¡¨
                    comments_text = "\n".join(comments_list)
            
            row = {
                "å¹³å°": item.get("platform", ""),
                "å…³é”®è¯": item.get("keyword", ""),  # å“ç‰Œå
                "æœç´¢å…³é”®è¯": item.get("search_query", ""),  # å®é™…æœç´¢çš„å…³é”®è¯
                "æ ‡é¢˜": item.get("title", ""),
                "é“¾æ¥": item.get("url", ""),
                "å‘å¸ƒæ—¶é—´": item.get("date", ""),
                "æ‘˜è¦": item.get("snippet", "") or item.get("content", ""),
                "å†…å®¹": item.get("content", ""),  # æ–°å¢å†…å®¹å­—æ®µ
                "ä½œè€…": item.get("author", ""),  # æ–°å¢ä½œè€…å­—æ®µï¼ˆå°çº¢ä¹¦ï¼‰
                "ç‚¹èµæ•°": item.get("likes", "0"),  # æ–°å¢ç‚¹èµæ•°
                "æ”¶è—æ•°": item.get("collects", "0"),  # æ–°å¢æ”¶è—æ•°ï¼ˆå°çº¢ä¹¦ï¼‰
                "åŒ…å«è´Ÿé¢": item.get("has_negative", False),
                "è¯„è®ºæ•°": item.get("comment_count", 0),
                "è¯„è®ºå†…å®¹": comments_text
            }
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        df.to_csv('raw_data_classroom.csv', index=False, encoding='utf-8-sig')
        logger.info(f"åŸå§‹æ•°æ®å·²ä¿å­˜åˆ°: raw_data_classroom.csv (å…± {len(df_data)} æ¡ï¼Œå·²è¿‡æ»¤éæ•™è‚²å†…å®¹)")
    
    def get_xhs_comments(self, note_url: str, max_comments: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–å°çº¢ä¹¦ç¬”è®°è¯„è®º
        
        Args:
            note_url: ç¬”è®°URL
            max_comments: æœ€å¤§è¯„è®ºæ•°
        
        Returns:
            è¯„è®ºåˆ—è¡¨
        """
        comments = []
        
        if not self.page:
            return comments
        
        try:
            # æ‰“å¼€ç¬”è®°è¯¦æƒ…é¡µ
            new_tab = self.page.new_tab()
            new_tab.get(note_url)
            time.sleep(5)
            
            # æ»šåŠ¨åˆ°è¯„è®ºåŒº
            new_tab.run_js('window.scrollBy(0, 500)')
            time.sleep(2)
            
            # æ‰¾è¯„è®ºå…ƒç´ 
            comment_selectors = [
                'css:div.comment-item',
                'css:div[class*="comment"]',
                'css:div.note-comment',
                'xpath://div[contains(@class, "comment")]',
            ]
            
            comment_eles = []
            for sel in comment_selectors:
                try:
                    comment_eles = new_tab.eles(sel, timeout=3)
                    if comment_eles:
                        logger.info(f"  æ‰¾åˆ° {len(comment_eles)} ä¸ªè¯„è®ºå…ƒç´ ï¼ˆä½¿ç”¨: {sel}ï¼‰")
                        break
                except:
                    continue
            
            for ele in comment_eles[:max_comments]:
                try:
                    # è¯„è®ºå†…å®¹
                    content = ""
                    content_ele = ele.ele('css:span.content, div.content, p', timeout=1)
                    if content_ele:
                        content = content_ele.text.strip()
                    
                    # ç”¨æˆ·å
                    username = ""
                    user_ele = ele.ele('css:span.name, a.user', timeout=1)
                    if user_ele:
                        username = user_ele.text.strip()
                    
                    # ç‚¹èµæ•°
                    likes = "0"
                    like_ele = ele.ele('css:span.like-count, span.count', timeout=1)
                    if like_ele:
                        likes = like_ele.text.strip()
                    
                    if content and len(content) > 5:
                        comments.append({
                            'username': username,
                            'content': content[:300],
                            'likes': likes,
                            'source': note_url
                        })
                except:
                    continue
            
            new_tab.close()
        except Exception as e:
            logger.debug(f"è¯„è®ºæŠ“å–å¤±è´¥: {str(e)}")
            try:
                new_tab.close()
            except:
                pass
        
        return comments
    
    def get_douyin_comments(self, video_url: str, max_comments: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–æŠ–éŸ³è§†é¢‘è¯„è®º
        
        Args:
            video_url: è§†é¢‘URL
            max_comments: æœ€å¤§è¯„è®ºæ•°
        
        Returns:
            è¯„è®ºåˆ—è¡¨
        """
        comments = []
        
        if not self.page:
            return comments
        
        try:
            # æ‰“å¼€è§†é¢‘è¯¦æƒ…é¡µ
            new_tab = self.page.new_tab()
            new_tab.get(video_url)
            time.sleep(5)
            
            # æ»šåŠ¨åŠ è½½è¯„è®º
            new_tab.run_js('window.scrollBy(0, 600)')
            time.sleep(2)
            
            # æ‰¾è¯„è®ºå…ƒç´ 
            comment_eles = new_tab.eles('css:div[class*="comment-item"], div[class*="comment-content"]', timeout=3)
            
            for ele in comment_eles[:max_comments]:
                try:
                    content = ele.text.strip() if ele.text else ""
                    
                    if content and len(content) > 5:
                        comments.append({
                            'content': content[:300],
                            'source': video_url
                        })
                except:
                    continue
            
            new_tab.close()
        except Exception as e:
            logger.debug(f"æŠ–éŸ³è¯„è®ºæŠ“å–å¤±è´¥: {str(e)}")
            try:
                new_tab.close()
            except:
                pass
        
        return comments
    
    def collect_user_comments(self, data_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æ”¶é›†ç”¨æˆ·è¯„è®ºï¼ˆç”¨äºæ—¥æŠ¥çš„"ç”¨æˆ·çœŸå®å£°éŸ³"æ¿å—ï¼‰
        
        Args:
            data_list: æ•°æ®åˆ—è¡¨
        
        Returns:
            è¯„è®ºåˆ—è¡¨
        """
        comments = []
        
        for item in data_list:
            platform = item.get('platform', '')
            brand = item.get('keyword', '')
            item_comments = item.get('comments', [])
            
            if not item_comments:
                continue
            
            for comment in item_comments:
                if isinstance(comment, dict):
                    # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼ˆåŒ…å«contentå’Œlikesï¼‰
                    content = comment.get('content', '')
                    likes = comment.get('likes', '0')
                else:
                    # å¦‚æœæ˜¯çº¯æ–‡æœ¬
                    content = str(comment)
                    likes = '0'
                
                if content and len(content) >= 10:
                    comments.append({
                        'content': content[:200],
                        'likes': likes,
                        'source': f"{brand} - {platform}"
                    })
        
        # æŒ‰ç‚¹èµæ•°æ’åºï¼ˆå¦‚æœæœ‰ï¼‰
        try:
            comments.sort(key=lambda x: int(str(x['likes']).replace('ä¸‡', '0000').replace('k', '000') or '0'), reverse=True)
        except:
            pass
        
        return comments[:20]  # è¿”å›å‰20æ¡
    
    def format_data_for_ai(self, data_list: List[Dict[str, Any]]) -> str:
        """
        å°†æ•°æ®æ ¼å¼åŒ–ä¸º AI æ˜“è¯»çš„æ–‡æœ¬æ ¼å¼
        
        Args:
            data_list: æ•°æ®åˆ—è¡¨
        
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬å­—ç¬¦ä¸²
        """
        if not data_list:
            return "ï¼ˆæš‚æ— æ•°æ®ï¼‰"
        
        context = ""
        negative_keywords = ['é¿é›·', 'å‘', 'é€€è´¹', 'éª—å±€', 'æŠ•è¯‰', 'å·®è¯„', 'åƒåœ¾', 'ä¸è¦', 'åƒä¸‡åˆ«', 'åµæ¶']
        
        # ä¼˜å…ˆå¤„ç†åŒ…å«è´Ÿé¢å…³é”®è¯çš„æ•°æ®
        priority_data = []
        normal_data = []
        
        for item in data_list:
            title = item.get('title', '')
            snippet = item.get('snippet', '')
            has_negative = item.get('has_negative', False)
            
            if has_negative or any(kw in (title + snippet) for kw in negative_keywords):
                priority_data.append(item)
            else:
                normal_data.append(item)
        
        # åˆå¹¶ï¼šä¼˜å…ˆæ•°æ®åœ¨å‰
        sorted_data = priority_data + normal_data
        
        # æˆªæ–­ä¿æŠ¤ï¼šå¦‚æœæ•°æ®å¤ªå¤šï¼Œåªå–å‰50æ¡
        if len(sorted_data) > 50:
            sorted_data = sorted_data[:50]
            logger.warning(f"æ•°æ®é‡è¿‡å¤§ï¼Œæˆªå–å‰50æ¡æœ€é‡è¦çš„æ•°æ®")
        
        for item in sorted_data:
            platform = item.get('platform', 'æœªçŸ¥å¹³å°')
            # ç‰¹åˆ«æ ‡æ³¨å°çº¢ä¹¦ï¼Œå› ä¸ºè¿™é‡Œé»‘æ–™æœ€å¤š
            if platform == 'å°çº¢ä¹¦':
                icon = "ğŸ“•"
            elif platform == 'æŠ–éŸ³':
                icon = "ğŸµ"
            elif platform == 'æœç‹—å¾®ä¿¡':
                icon = "ğŸŸ¢"
            else:
                icon = "ğŸ“„"
            
            context += f"ã€å¹³å°ï¼š{icon} {platform}ã€‘\n"
            context += f"å…³é”®è¯ï¼š{item.get('keyword', '')}\n"
            context += f"æ ‡é¢˜ï¼š{item.get('title', 'æ— æ ‡é¢˜')}\n"
            context += f"é“¾æ¥ï¼š{item.get('url', '')}\n"
            
            # æ·»åŠ æ‘˜è¦ï¼ˆå¦‚æœæœ‰ï¼‰
            snippet = item.get('snippet', '')
            if snippet:
                context += f"æ‘˜è¦ï¼š{snippet[:200]}\n"
            
            # é‡ç‚¹ï¼šå¦‚æœæœ‰è¯„è®ºï¼Œå¿…é¡»å…¨éƒ¨æ‹¼è¿›å»ï¼Œè¿™æ˜¯é”€å”®å›æ€¼çš„å…³é”®
            comments = item.get('comments', [])
            if comments:
                comments_text = "\n".join([f"  - {c}" for c in comments if c])
                context += f"ğŸ”¥ ç”¨æˆ·é«˜èµåæ§½ï¼š\n{comments_text}\n"
            
            # æ ‡è®°æ˜¯å¦åŒ…å«è´Ÿé¢
            if item.get('has_negative', False):
                context += "âš ï¸ åŒ…å«è´Ÿé¢å…³é”®è¯\n"
            
            context += "-------------------\n"
        
        # æ£€æŸ¥æ€»é•¿åº¦ï¼Œå¦‚æœè¶…è¿‡5000å­—ï¼Œæˆªå–
        if len(context) > 5000:
            logger.warning(f"æ ¼å¼åŒ–æ•°æ®è¿‡é•¿ ({len(context)} å­—ç¬¦)ï¼Œæˆªå–å‰5000å­—ç¬¦")
            context = context[:5000] + "\n...ï¼ˆæ•°æ®å·²æˆªæ–­ï¼‰"
        
        return context
    
    def load_data_from_csv(self) -> Dict[str, List[Dict[str, Any]]]:
        """
        ä» CSV æ–‡ä»¶åŠ è½½æ•°æ®ï¼ˆæ•°æ®æºåŒé‡ä¿éšœï¼‰
        
        Returns:
            åŒ…å« douyin_data, xhs_data, wechat_data çš„å­—å…¸
        """
        try:
            if not os.path.exists('raw_data_classroom.csv'):
                logger.warning("raw_data_classroom.csv æ–‡ä»¶ä¸å­˜åœ¨")
                return {"douyin_data": [], "xhs_data": [], "wechat_data": []}
            
            df = pd.read_csv('raw_data_classroom.csv', encoding='utf-8-sig')
            logger.info(f"ä» CSV åŠ è½½æ•°æ®ï¼Œå…± {len(df)} æ¡")
            
            douyin_data = []
            xhs_data = []
            wechat_data = []
            
            for _, row in df.iterrows():
                platform = row.get('å¹³å°', '')
                comments_text = row.get('è¯„è®ºå†…å®¹', '')
                comments = [c.strip() for c in comments_text.split('\n') if c.strip()] if comments_text else []
                
                item = {
                    "platform": platform,
                    "keyword": row.get('å…³é”®è¯', ''),
                    "title": row.get('æ ‡é¢˜', ''),
                    "url": row.get('é“¾æ¥', ''),
                    "date": row.get('å‘å¸ƒæ—¶é—´', ''),
                    "snippet": row.get('æ‘˜è¦', '') or row.get('å†…å®¹', ''),
                    "content": row.get('å†…å®¹', '') or row.get('æ‘˜è¦', ''),
                    "has_negative": row.get('åŒ…å«è´Ÿé¢', False) if isinstance(row.get('åŒ…å«è´Ÿé¢'), bool) else False,
                    "comments": comments,
                    "comment_count": len(comments),
                    "is_valid": True  # CSVä¸­çš„æ•°æ®å·²ç»ç»è¿‡è¿‡æ»¤ï¼Œé»˜è®¤éƒ½æ˜¯æœ‰æ•ˆçš„
                }
                
                if platform == 'æŠ–éŸ³':
                    douyin_data.append(item)
                elif platform == 'å°çº¢ä¹¦':
                    xhs_data.append(item)
                elif platform == 'æœç‹—å¾®ä¿¡':
                    wechat_data.append(item)
            
            logger.info(f"CSV æ•°æ®åŠ è½½å®Œæˆï¼šæŠ–éŸ³ {len(douyin_data)} æ¡ï¼Œå°çº¢ä¹¦ {len(xhs_data)} æ¡ï¼Œæœç‹—å¾®ä¿¡ {len(wechat_data)} æ¡")
            return {
                "douyin_data": douyin_data,
                "xhs_data": xhs_data,
                "wechat_data": wechat_data
            }
            
        except Exception as e:
            logger.error(f"ä» CSV åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
            return {"douyin_data": [], "xhs_data": [], "wechat_data": []}
    
    def generate_report(self) -> str:
        """
        ç¬¬ä¸‰é˜¶æ®µï¼šé˜¿é‡Œåƒé—® (Qwen) é”€å† åˆ†æ
        è°ƒç”¨ dashscope.Generation.call ç”ŸæˆæŠ¥å‘Š
        """
        logger.info("=" * 80)
        logger.info("ç¬¬ä¸‰é˜¶æ®µï¼šé˜¿é‡Œåƒé—® (Qwen) é”€å† åˆ†æ")
        logger.info("=" * 80)
        
        # æ•°æ®æºåŒé‡ä¿éšœï¼šä¼˜å…ˆä½¿ç”¨å†…å­˜æ•°æ®ï¼Œå¦‚æœä¸ºç©ºåˆ™ä» CSV è¯»å–
        douyin_data = self.douyin_data
        xhs_data = self.xhs_data
        wechat_data = self.wechat_data
        
        logger.info(f"å†…å­˜æ•°æ®ï¼šæŠ–éŸ³ {len(douyin_data)} æ¡ï¼Œå°çº¢ä¹¦ {len(xhs_data)} æ¡ï¼Œæœç‹—å¾®ä¿¡ {len(wechat_data)} æ¡")
        
        # å¦‚æœå†…å­˜æ•°æ®ä¸ºç©ºæˆ–å¾ˆå°‘ï¼Œä» CSV è¯»å–ä½œä¸ºè¡¥å……
        if (not douyin_data and not xhs_data and not wechat_data) or (len(douyin_data) + len(xhs_data) + len(wechat_data)) < 10:
            logger.warning("å†…å­˜æ•°æ®ä¸ºç©ºæˆ–ä¸è¶³ï¼Œå°è¯•ä» CSV æ–‡ä»¶åŠ è½½...")
            csv_data = self.load_data_from_csv()
            csv_douyin = csv_data.get('douyin_data', [])
            csv_xhs = csv_data.get('xhs_data', [])
            csv_wechat = csv_data.get('wechat_data', [])
            
            # åˆå¹¶å†…å­˜æ•°æ®å’ŒCSVæ•°æ®ï¼ˆå»é‡ï¼‰
            if not douyin_data:
                douyin_data = csv_douyin
            if not xhs_data:
                xhs_data = csv_xhs
            if not wechat_data:
                wechat_data = csv_wechat
            
            logger.info(f"ä» CSV åŠ è½½åï¼šæŠ–éŸ³ {len(douyin_data)} æ¡ï¼Œå°çº¢ä¹¦ {len(xhs_data)} æ¡ï¼Œæœç‹—å¾®ä¿¡ {len(wechat_data)} æ¡")
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        all_data_list = douyin_data + xhs_data + wechat_data
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®ï¼ˆæ”¾å®½ï¼šé»˜è®¤ä¿ç•™æ‰€æœ‰æ•°æ®ï¼Œé™¤éæ˜ç¡®æ ‡è®°ä¸ºæ— æ•ˆï¼‰
        # æ³¨æ„ï¼šCSVä¸­ä¿å­˜çš„æ•°æ®å·²ç»ç»è¿‡è¿‡æ»¤ï¼Œé»˜è®¤éƒ½æ˜¯æœ‰æ•ˆçš„
        valid_data = []
        for item in all_data_list:
            # å¦‚æœæ˜ç¡®æ ‡è®°ä¸ºæ— æ•ˆï¼Œè·³è¿‡
            if item.get('is_valid') is False:
                logger.debug(f"  è·³è¿‡æ— æ•ˆæ•°æ®: {item.get('title', '')[:50]}")
                continue
            # å¦åˆ™ä¿ç•™ï¼ˆåŒ…æ‹¬is_validä¸ºTrueæˆ–æœªè®¾ç½®çš„æƒ…å†µï¼‰
            # å¯¹äºä»CSVåŠ è½½çš„æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰is_validå­—æ®µï¼Œé»˜è®¤è®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
            valid_data.append(item)
        
        logger.info(f"æ•°æ®è¿‡æ»¤ï¼šåŸå§‹ {len(all_data_list)} æ¡ -> æœ‰æ•ˆ {len(valid_data)} æ¡")
        
        # å¦‚æœæœ‰æ•ˆæ•°æ®ä¸ºç©ºï¼Œä½†åŸå§‹æ•°æ®ä¸ä¸ºç©ºï¼Œè¯´æ˜å¯èƒ½æ‰€æœ‰æ•°æ®éƒ½æ²¡æœ‰is_validå­—æ®µ
        # è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ”¾å®½æ¡ä»¶ï¼šé»˜è®¤ä¿ç•™æ‰€æœ‰æ•°æ®
        if not valid_data and all_data_list:
            logger.warning("æ‰€æœ‰æ•°æ®éƒ½æ²¡æœ‰is_validå­—æ®µæˆ–éƒ½è¢«æ ‡è®°ä¸ºæ— æ•ˆï¼Œæ”¾å®½æ¡ä»¶ï¼šé»˜è®¤ä¿ç•™æ‰€æœ‰æ•°æ®")
            valid_data = all_data_list
            # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æœ‰is_valid=Trueæ ‡è®°
            for item in valid_data:
                if 'is_valid' not in item:
                    item['is_valid'] = True
        
        if not valid_data:
            logger.warning("æ‰€æœ‰æ•°æ®æºéƒ½ä¸ºç©ºæˆ–å…¨éƒ¨è¢«è¿‡æ»¤ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
            return f"""# æµ·é©¬è¯¾å ‚Â·å¸‚åœºé›·è¾¾æ—¥æŠ¥

**ç”Ÿæˆæ—¶é—´**: {CURRENT_DATE}

## âš ï¸ æ•°æ®é‡‡é›†ç»“æœ

- æŠ–éŸ³æ•°æ®: {len(douyin_data)} æ¡ï¼ˆæœ‰æ•ˆ: {len([i for i in douyin_data if i.get('is_valid', True)])} æ¡ï¼‰
- å°çº¢ä¹¦æ•°æ®: {len(xhs_data)} æ¡ï¼ˆæœ‰æ•ˆ: {len([i for i in xhs_data if i.get('is_valid', True)])} æ¡ï¼‰
- æœç‹—å¾®ä¿¡æ•°æ®: {len(wechat_data)} æ¡ï¼ˆæœ‰æ•ˆ: {len([i for i in wechat_data if i.get('is_valid', True)])} æ¡ï¼‰

*æ³¨ï¼šæœªé‡‡é›†åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œå¯èƒ½æ‰€æœ‰å†…å®¹éƒ½è¢«è¿‡æ»¤å™¨è¿‡æ»¤ã€‚*
"""
        
        # æ”¶é›†ç”¨æˆ·è¯„è®º
        user_comments = self.collect_user_comments(valid_data)
        
        # æ ¼å¼åŒ–æ•°æ®
        formatted_data = self.format_data_for_ai(valid_data)
        
        # è°ƒè¯•æ‰“å°
        logger.info(f"æ­£åœ¨å‘é€ç»™ AI çš„æ•°æ®é•¿åº¦: {len(formatted_data)} å­—ç¬¦")
        logger.info(f"æ•°æ®ç»Ÿè®¡ï¼šæŠ–éŸ³ {len(douyin_data)} æ¡ï¼ˆæœ‰æ•ˆ: {len([i for i in douyin_data if i.get('is_valid', True)])}ï¼‰ï¼Œå°çº¢ä¹¦ {len(xhs_data)} æ¡ï¼ˆæœ‰æ•ˆ: {len([i for i in xhs_data if i.get('is_valid', True)])}ï¼‰ï¼Œæœç‹—å¾®ä¿¡ {len(wechat_data)} æ¡ï¼ˆæœ‰æ•ˆ: {len([i for i in wechat_data if i.get('is_valid', True)])}ï¼‰")
        logger.info(f"æ”¶é›†åˆ°ç”¨æˆ·è¯„è®º: {len(user_comments)} æ¡")
        
        system_prompt = """ä½ ä¸æ˜¯é”€å”®ï¼Œä½ æ˜¯æµ·é©¬è¯¾å ‚çš„**é¦–å¸­æˆ˜ç•¥å®˜ (CSO)**ã€‚
ä½ æ‹¥æœ‰æ•é”çš„å¸‚åœºæ´å¯ŸåŠ›ã€‚è¯·æ ¹æ®é‡‡é›†åˆ°çš„å…¨ç½‘æ•°æ®ï¼ˆæŠ–éŸ³/å°çº¢ä¹¦/å¾®ä¿¡ï¼‰ï¼Œä¸ºç®¡ç†å±‚æ’°å†™ä¸€ä»½ã€Šå…¨ç½‘å¸‚åœºé›·è¾¾æ—¥æŠ¥ã€‹ã€‚

**é‡è¦è¯´æ˜**ï¼š
- æœ¬æ¬¡æ•°æ®å·²ç»è¿‡æ•™è‚²åœºæ™¯è¿‡æ»¤ï¼ŒåªåŒ…å«ä¸æ•™è‚²è¾…å¯¼ç›¸å…³çš„å†…å®¹
- å¦‚æœæŸä¸ªç«å“æ²¡æœ‰æ•°æ®ï¼Œè¯´æ˜è¿‘ä¸€å‘¨æ— æ•™è‚²ç›¸å…³å†…å®¹æ›´æ–°ï¼Œè¯·ç›´æ¥æ ‡æ³¨"æ— æ›´æ–°"
- ä¸è¦å±•ç¤ºæ— å…³å†…å®¹ï¼ˆå¦‚å’–å•¡ã€é‹å­ã€æ—…æ¸¸ç­‰ï¼‰

**åˆ†æé€»è¾‘ä¸è¾“å‡ºæ ¼å¼ (Markdown)**ï¼š

**ç¬¬ä¸€éƒ¨åˆ†ï¼šâš”ï¸ ç«å“åŠ¨ä½œç›‘æµ‹ (Competitor Moves)**
- æ ¸å¿ƒå…³æ³¨ï¼šç«å“ï¼ˆè·¯è§…ã€è€ƒè€Œæ€ã€è¾…æ— å¿§ã€ä¸‡èƒ½ç­é•¿ç­‰ï¼‰æœ€è¿‘å‘äº†ä»€ä¹ˆæ–°äº§å“ï¼Ÿæäº†ä»€ä¹ˆæ´»åŠ¨ï¼Ÿæœ‰ä»€ä¹ˆä»·æ ¼å˜åŠ¨ï¼Ÿ
- æ ¼å¼ï¼š`[å¹³å°] ç«å“åï¼šå…·ä½“åŠ¨ä½œ`ï¼Œå¿…é¡»åŒ…å«åŸæ–‡é“¾æ¥ã€‚
- **å¦‚æœæŸä¸ªç«å“æ²¡æœ‰æ•°æ®ï¼Œç›´æ¥å†™ï¼š`[å¹³å°] ç«å“åï¼šè¿‘ä¸€å‘¨æ— æ•™è‚²ç›¸å…³å†…å®¹æ›´æ–°`**
- æ¯æ¡æƒ…æŠ¥å¿…é¡»åŒ…å«åŸå§‹é“¾æ¥ï¼Œæ ¼å¼ï¼š`ğŸ”— [æŸ¥çœ‹åŸæ–‡](é“¾æ¥)`
- ä¼˜å…ˆåˆ†æå°çº¢ä¹¦å¹³å°çš„è´Ÿé¢è¯„ä»·ï¼Œå› ä¸ºé€šå¸¸æœ€çœŸå®
- è¯·æ ‡æ³¨äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµæ•°ã€è¯„è®ºæ•°ç­‰ï¼‰

**ç¬¬äºŒéƒ¨åˆ†ï¼šğŸ“¢ ç”¨æˆ·èˆ†æƒ…é€è§† (Voice of Customer)**

### ğŸ”´ è´Ÿé¢è¯„è®ºåŸå£°ï¼ˆæ‘˜å½•è‡ªå°çº¢ä¹¦åŠæŠ–éŸ³è¯„è®ºåŒºï¼‰
- **å¿…é¡»æ‘˜å½•**ï¼šä»æ•°æ®ä¸­æå– 3-5 æ¡æœ€å…·ä»£è¡¨æ€§çš„**è´Ÿé¢è¯„è®ºåŸè¯**ï¼Œä½œä¸º"ç”¨æˆ·åŸå£°"å±•ç¤ºã€‚
- æ ¼å¼ï¼šã€å¹³å°ç”¨æˆ· @xxxã€‘ï¼ˆè¯„è®ºäºxxxç¬”è®°/è§†é¢‘ä¸‹ï¼‰"è¯„è®ºå†…å®¹"
- å¦‚æœæ•°æ®ä¸­æ²¡æœ‰è¯„è®ºï¼Œè¯·æ˜ç¡®è¯´æ˜"æœ¬æ¬¡æœªé‡‡é›†åˆ°ç”¨æˆ·è¯„è®ºæ•°æ®"

### ğŸŒ¡ èˆ†æƒ…çƒ­è¯åˆ†æ
- æ ¸å¿ƒè´Ÿé¢çƒ­è¯ï¼šåˆ—å‡º5-8ä¸ªï¼ˆå¦‚ï¼šé€€è´¹éš¾ã€å¯¼å¸ˆæ°´ã€è™šå‡å†…æ¨ã€æœåŠ¡å·®ç­‰ï¼‰
- æƒ…ç»ªå…³é”®è¯ï¼šåˆ—å‡º3-5ä¸ªï¼ˆå¦‚ï¼šæ„¤æ€’ã€å¤±æœ›ã€æŠ•è¯‰ç­‰ï¼‰

### âœ… ç»“è®º
- ä¸€å¥è¯æ€»ç»“å½“å‰ç”¨æˆ·æƒ…ç»ªè¶‹åŠ¿

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šğŸ§­ æˆ‘ä»¬çš„æˆ˜ç•¥å¯ç¤º (Strategic Insights)**
- **è¿™æ˜¯æœ€é‡è¦çš„éƒ¨åˆ†**ã€‚åŸºäºä¸Šè¿°ç«å“åŠ¨ä½œå’Œç”¨æˆ·èˆ†æƒ…ï¼Œç»™æˆ‘ä»¬ï¼ˆæµ·é©¬è¯¾å ‚ï¼‰æå‡º 3 æ¡å…·ä½“çš„æˆ˜ç•¥å»ºè®®ã€‚
- æ¯æ¡å»ºè®®åŒ…å«ï¼š
  1. ã€æ ‡é¢˜ã€‘ç®€çŸ­æœ‰åŠ›çš„ç­–ç•¥åç§°
  2. **äº‹å®ä¾æ®**ï¼šåŸºäºæ•°æ®çš„æ”¯æ’‘
  3. **ç­–ç•¥å»ºè®®**ï¼šå…·ä½“çš„æ‰§è¡Œæ–¹æ¡ˆ
  4. **ç›®çš„**ï¼šé¢„æœŸè¾¾æˆçš„æ•ˆæœ
- *ä¸è¦å†™è¯æœ¯*ï¼Œè¦å†™ç­–ç•¥ã€‚
- ä¾‹å¦‚ï¼š'ç«å“Aå› ä¸ºé€€è´¹éš¾è¢«éª‚ -> å¯ç¤ºï¼šæˆ‘ä»¬åº”åœ¨å®£å‘ä¸­å¼ºè°ƒèµ„é‡‘ç›‘ç®¡å’Œé€æ˜é€€è´¹æµç¨‹ï¼Œå»ºç«‹ä¿¡ä»»å£å’ã€‚'

**é£æ ¼è¦æ±‚**ï¼š
- è¯­è¨€ç®€ç»ƒã€ä¸“ä¸šã€æ¯’è¾£ã€‚
- æ‹’ç»åºŸè¯ï¼Œç›´å‡»æœ¬è´¨ã€‚
- **å»ºè®®å¿…é¡»åŸºäºä»Šæ—¥æŠ“å–çš„å…·ä½“æ•°æ®ï¼Œä¸¥ç¦ç”Ÿæˆé€šç”¨å»ºè®®ã€‚**
- **å¦‚æœæ•°æ®é‡å°‘ï¼Œä¸è¦ç¼–é€ å†…å®¹ï¼Œå¦‚å®è¯´æ˜æ•°æ®æƒ…å†µã€‚**
- **æ‰€æœ‰é“¾æ¥å¿…é¡»å®Œæ•´ï¼Œç¡®ä¿å¯ä»¥ç‚¹å‡»è®¿é—®ã€‚**"""

        # æ„å»ºç”¨æˆ·è¯„è®ºæ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
        comments_text = ""
        if user_comments:
            comments_text = "\n\n**ç”¨æˆ·è¯„è®ºæ•°æ®**ï¼ˆå…±{}æ¡ï¼‰ï¼š\n".format(len(user_comments))
            for idx, comment in enumerate(user_comments[:10], 1):
                comments_text += f"{idx}. ã€Œ{comment['content']}ã€ (æ¥æº: {comment['source']}, ğŸ‘{comment['likes']})\n"
        else:
            comments_text = "\n\n**ç”¨æˆ·è¯„è®ºæ•°æ®**ï¼šæœ¬æ¬¡æœªé‡‡é›†åˆ°ç”¨æˆ·è¯„è®ºæ•°æ®ã€‚\n"
        
        user_prompt = f"""ä»¥ä¸‹æ˜¯ä»Šæ—¥é‡‡é›†åˆ°çš„æœ€æ–°ç«å“æƒ…æŠ¥æ•°æ®ï¼ˆæœ€è¿‘ä¸€å‘¨ï¼‰ï¼š

{formatted_data}
{comments_text}

è¯·æ ¹æ®ä»¥ä¸Šæ•°æ®ç”Ÿæˆã€Šå…¨ç½‘å¸‚åœºé›·è¾¾æ—¥æŠ¥ã€‹ï¼Œæ ¼å¼ä¸º Markdownã€‚
æ¯æ¡æƒ…æŠ¥å¿…é¡»åŒ…å«åŸå§‹é“¾æ¥ï¼Œä¸¥ç¦ç¼–é€ ä¿¡æ¯ã€‚
**ç‰¹åˆ«æ³¨æ„**ï¼š
1. å¦‚æœä¸Šè¿°ç”¨æˆ·è¯„è®ºæ•°æ®ä¸­æœ‰å†…å®¹ï¼Œå¿…é¡»æ‘˜å½• 3-5 æ¡æœ€å…·ä»£è¡¨æ€§çš„è¯„è®ºåŸè¯å±•ç¤ºã€‚
2. æˆ˜ç•¥å»ºè®®å¿…é¡»åŸºäºä¸Šè¿°å…·ä½“æ•°æ®ï¼Œä¸èƒ½å†™é€šç”¨å»ºè®®ã€‚
3. å¦‚æœæ•°æ®ä¸­æ²¡æœ‰è¯„è®ºï¼Œè¯·æ˜ç¡®è¯´æ˜"æœ¬æ¬¡æœªé‡‡é›†åˆ°ç”¨æˆ·è¯„è®ºæ•°æ®"ã€‚
4. ä¼˜å…ˆåˆ†æå°çº¢ä¹¦å¹³å°çš„è´Ÿé¢è¯„ä»·ï¼Œå› ä¸ºé€šå¸¸æœ€çœŸå®ã€‚
5. åœ¨"ç«å“åŠ¨ä½œç›‘æµ‹"éƒ¨åˆ†ï¼Œè¯·æ ‡æ³¨äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµæ•°ã€è¯„è®ºæ•°ç­‰ï¼‰ã€‚"""

        try:
            logger.info("è°ƒç”¨é˜¿é‡Œåƒé—® (qwen-plus) API ç”ŸæˆæŠ¥å‘Š...")
            
            # ä½¿ç”¨ dashscope.Generation.call
            response = Generation.call(
                model='qwen-plus',
                messages=[
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': user_prompt}
                ],
                result_format='message'
            )
            
            if response.status_code == 200:
                report = response.output.choices[0].message.content
                
                # æ·»åŠ æ ‡é¢˜å’Œæ—¥æœŸ
                full_report = f"# æµ·é©¬è¯¾å ‚Â·å¸‚åœºé›·è¾¾æ—¥æŠ¥\n\n**ç”Ÿæˆæ—¶é—´**: {CURRENT_DATE}\n\n---\n\n{report}"
                
                logger.info("é˜¿é‡Œåƒé—® æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
                return full_report
            else:
                raise Exception(f"API è°ƒç”¨å¤±è´¥: {response.status_code}, {response.message}")
            
        except Exception as e:
            logger.error(f"é˜¿é‡Œåƒé—® ç”Ÿæˆå¤±è´¥: {str(e)}")
            # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œè¿”å›åŸºç¡€æŠ¥å‘Š
            return f"""# æµ·é©¬è¯¾å ‚Â·å¸‚åœºé›·è¾¾æ—¥æŠ¥

**ç”Ÿæˆæ—¶é—´**: {CURRENT_DATE}

## æ•°æ®ç»Ÿè®¡

- æŠ–éŸ³æ•°æ®: {len(douyin_data)} æ¡
- å°çº¢ä¹¦æ•°æ®: {len(xhs_data)} æ¡
- æœç‹—å¾®ä¿¡æ•°æ®: {len(wechat_data)} æ¡

*æ³¨ï¼šAI åˆ†æå¤±è´¥ï¼Œè¯·æŸ¥çœ‹ raw_data_classroom.csv è·å–åŸå§‹æ•°æ®ã€‚*
"""
    
    def run(self, skip_login: bool = False):
        """
        æ‰§è¡Œå®Œæ•´çš„é‡‡é›†æµç¨‹
        
        Args:
            skip_login: æ˜¯å¦è·³è¿‡ç™»å½•æ­¥éª¤ï¼ˆå‡è®¾å·²ç™»å½•ï¼‰
        """
        logger.info("=" * 80)
        logger.info("æµ·é©¬è¯¾å ‚Â·å¸‚åœºé›·è¾¾æ—¥æŠ¥ - å¼€å§‹è¿è¡Œ")
        logger.info("=" * 80)
        
        try:
            if not skip_login:
                # ç¬¬ä¸€é˜¶æ®µï¼šäººå·¥ç™»å½•
                self.manual_login()
            else:
                logger.info("è·³è¿‡ç™»å½•æ­¥éª¤ï¼Œå‡è®¾æµè§ˆå™¨å·²ç™»å½•")
                # æ‰“å¼€ä¸‰ä¸ªæ ‡ç­¾é¡µï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
                try:
                    tabs = self.page.tab_ids
                    if len(tabs) == 0:
                        self.page.get('https://www.douyin.com')
                        time.sleep(2)
                        self.page.new_tab()
                        self.page.get('https://www.xiaohongshu.com')
                        time.sleep(2)
                        self.page.new_tab()
                        self.page.get('https://weixin.sogou.com')
                        time.sleep(2)
                except:
                    pass
            
            # ç¬¬äºŒé˜¶æ®µï¼šå¤šå¹³å°é‡‡é›†
            self.crawl_douyin()
            self.crawl_xhs()
            self.crawl_wechat()
            
            # ä¿å­˜åŸå§‹æ•°æ®
            self.save_raw_data()
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šç”ŸæˆæŠ¥å‘Š
            report = self.generate_report()
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = f"Market_Radar_Classroom_{CURRENT_DATE}.md"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
            print(f"\nâœ… é‡‡é›†å®Œæˆï¼")
            print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼šæŠ–éŸ³ {len(self.douyin_data)} æ¡ï¼Œå°çº¢ä¹¦ {len(self.xhs_data)} æ¡ï¼Œæœç‹—å¾®ä¿¡ {len(self.wechat_data)} æ¡")
            print(f"ğŸ“„ åŸå§‹æ•°æ®ï¼šraw_data_classroom.csv")
            print(f"ğŸ“‹ åˆ†ææŠ¥å‘Šï¼š{report_file}")
            
            logger.info("=" * 80)
            logger.info("å¸‚åœºé›·è¾¾æ—¥æŠ¥ç”Ÿæˆå®Œæˆ")
            logger.info("=" * 80)
            
            # æµ‹è¯•æ¨¡å¼ï¼šåªæ‰“å°æ¶ˆæ¯ï¼Œä¸å‘é€åˆ°é’‰é’‰
            self.send_to_dingtalk(report, test_mode=True)
            
        except Exception as e:
            logger.error(f"è¿è¡Œå¼‚å¸¸: {str(e)}", exc_info=True)
            raise
        finally:
            # ä¸è‡ªåŠ¨å…³é—­æµè§ˆå™¨ï¼Œè®©ç”¨æˆ·æŸ¥çœ‹ç»“æœ
            logger.info("æµè§ˆå™¨ä¿æŒæ‰“å¼€çŠ¶æ€ï¼Œè¯·æ‰‹åŠ¨å…³é—­")
    
    def send_to_dingtalk(self, report_content: str, test_mode: bool = True):
        """
        å‘é€æŠ¥å‘Šåˆ°é’‰é’‰ç¾¤ï¼ˆç¡®ä¿æ‰€æœ‰é“¾æ¥å®Œæ•´ï¼‰
        
        Args:
            report_content: æŠ¥å‘Šå†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰
            test_mode: æµ‹è¯•æ¨¡å¼ï¼Œå¦‚æœä¸ºTrueåˆ™åªæ‰“å°ä¸å‘é€
        """
        try:
            import requests
            
            # è¯»å–åŸå§‹æ•°æ®ï¼Œè¡¥å……é“¾æ¥ä¿¡æ¯
            try:
                csv_file = 'raw_data_classroom.csv'
                if os.path.exists(csv_file):
                    df = pd.read_csv(csv_file, encoding='utf-8-sig')
                    
                    # æ„å»ºé“¾æ¥è¡¥å……ä¿¡æ¯
                    links_section = "\n\n---\n\n## ğŸ“ å®Œæ•´åŸæ–‡é“¾æ¥æ¸…å•\n\n"
                    
                    # æŒ‰å¹³å°åˆ†ç»„
                    for platform in ['æŠ–éŸ³', 'å°çº¢ä¹¦', 'æœç‹—å¾®ä¿¡']:
                        platform_data = df[df['å¹³å°'] == platform]
                        if len(platform_data) > 0:
                            links_section += f"### {platform}å¹³å°\n\n"
                            for _, row in platform_data.head(10).iterrows():
                                title = str(row.get('æ ‡é¢˜', ''))[:60]
                                url = str(row.get('é“¾æ¥', ''))
                                keyword = str(row.get('å…³é”®è¯', ''))
                                
                                if url and url != 'nan' and url.strip():
                                    links_section += f"- **{keyword}** - {title}  ğŸ”— [æŸ¥çœ‹åŸæ–‡]({url})\n"
                            links_section += "\n"
                    
                    # å°†é“¾æ¥è¡¥å……ä¿¡æ¯æ·»åŠ åˆ°æŠ¥å‘Šæœ«å°¾
                    report_content = report_content.rstrip() + links_section
            except Exception as e:
                logger.warning(f"è¡¥å……é“¾æ¥ä¿¡æ¯å¤±è´¥: {str(e)}")
            
            # æµ‹è¯•æ¨¡å¼ï¼šåªæ‰“å°æ¶ˆæ¯ï¼Œä¸å‘é€
            if test_mode:
                print("\n" + "=" * 80)
                print("ã€æµ‹è¯•æ¨¡å¼ã€‘å®Œæ•´é’‰é’‰æ¶ˆæ¯å†…å®¹ï¼ˆå¸¦æ‰€æœ‰åŸæ–‡é“¾æ¥ï¼‰")
                print("=" * 80)
                print(report_content)
                print("=" * 80)
                logger.info("æµ‹è¯•æ¨¡å¼ï¼šæ¶ˆæ¯å·²æ‰“å°åˆ°æ§åˆ¶å°ï¼Œæœªå‘é€åˆ°é’‰é’‰")
                return
            
            # å‘é€åˆ°é’‰é’‰ï¼ˆéæµ‹è¯•æ¨¡å¼ï¼‰
            DINGTALK_WEBHOOK = "https://oapi.dingtalk.com/robot/send?access_token=ac8d1c6332c8a047b8786a930ab08d7f6db490843edca2de1bb65c68301c3113"
            payload = {
                "msgtype": "markdown",
                "markdown": {
                    "title": "æµ·é©¬è¯¾å ‚Â·å¸‚åœºé›·è¾¾æ—¥æŠ¥",
                    "text": report_content
                }
            }
            
            logger.info("æ­£åœ¨å‘é€æŠ¥å‘Šåˆ°é’‰é’‰ç¾¤...")
            response = requests.post(DINGTALK_WEBHOOK, json=payload, timeout=10)
            result = response.json()
            
            if result.get('errcode') == 0:
                logger.info("âœ“ é’‰é’‰æ¶ˆæ¯å‘é€æˆåŠŸ")
                print("âœ“ æŠ¥å‘Šå·²å‘é€åˆ°é’‰é’‰ç¾¤")
            else:
                logger.warning(f"âœ— é’‰é’‰æ¶ˆæ¯å‘é€å¤±è´¥: {result.get('errmsg')}")
                print(f"âœ— é’‰é’‰æ¶ˆæ¯å‘é€å¤±è´¥: {result.get('errmsg')}")
                
        except ImportError:
            logger.warning("requests åº“æœªå®‰è£…ï¼Œè·³è¿‡é’‰é’‰æ¨é€")
            print("âš   requests åº“æœªå®‰è£…ï¼Œè·³è¿‡é’‰é’‰æ¨é€")
        except Exception as e:
            logger.error(f"å‘é€é’‰é’‰æ¶ˆæ¯å¤±è´¥: {str(e)}")
            print(f"âœ— å‘é€é’‰é’‰æ¶ˆæ¯å¤±è´¥: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    import sys
    # å¦‚æœå‘½ä»¤è¡Œå‚æ•°åŒ…å« --skip-loginï¼Œåˆ™è·³è¿‡ç™»å½•æ­¥éª¤
    skip_login = '--skip-login' in sys.argv or '--skip' in sys.argv
    
    radar = MarketRadarHaimaClassroom()
    radar.run(skip_login=skip_login)


if __name__ == "__main__":
    main()
