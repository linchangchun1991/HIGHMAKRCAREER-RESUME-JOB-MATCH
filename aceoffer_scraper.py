#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AceOffer æ‹›è˜ä¿¡æ¯æŠ“å–è„šæœ¬
åŠŸèƒ½ï¼šä½¿ç”¨ Playwright æŠ“å– https://material.aceoffer.cn/recruit ä¸Šçš„æ‹›è˜ä¿¡æ¯

å®‰è£…ä¾èµ–ï¼š
    pip install playwright pandas openpyxl

å®‰è£…Playwrightæµè§ˆå™¨ï¼š
    playwright install chromium

ä½¿ç”¨æ–¹æ³•ï¼š
    python aceoffer_recruit_scraper.py
"""

import asyncio
import random
import re
import time
from datetime import datetime
from typing import List, Dict, Optional
import pandas as pd
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError

# ==================== é…ç½®åŒºåŸŸ ====================

# Chrome ç”¨æˆ·æ•°æ®ç›®å½•è·¯å¾„ï¼ˆè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
# ä½¿ç”¨ç‹¬ç«‹çš„ç”¨æˆ·æ•°æ®ç›®å½•ï¼Œé¿å…ä¸æ­£åœ¨è¿è¡Œçš„ Chrome å†²çª
# âš ï¸ æ³¨æ„ï¼šä½¿ç”¨ç‹¬ç«‹ç›®å½•éœ€è¦é‡æ–°ç™»å½•ç½‘ç«™
CHROME_USER_DATA_DIR = "/Users/changchun/Library/Application Support/Google/Chrome_Scraper"

# ç›®æ ‡URL
TARGET_URL = "https://material.aceoffer.cn/recruit"

# éšæœºç­‰å¾…æ—¶é—´èŒƒå›´ï¼ˆç§’ï¼‰- æ¨¡æ‹Ÿäººç±»æ“ä½œï¼Œé˜²æ­¢è¢«åçˆ¬ï¼ˆå·²ä¼˜åŒ–ä¸ºæ›´å¿«é€Ÿåº¦ï¼‰
RANDOM_WAIT_MIN = 0.5
RANDOM_WAIT_MAX = 1.5

# æœ€å¤§æŠ“å–é¡µæ•°ï¼ˆè®¾ç½®ä¸º None è¡¨ç¤ºæŠ“å–æ‰€æœ‰é¡µï¼‰
MAX_PAGES = 20  # æŠ“å–å‰20é¡µï¼ˆç¡®ä¿èƒ½æŠ“å–åˆ°100ä¸ªå²—ä½ï¼‰

# æ¯é¡µæœ€å¤§æŠ“å–æ•°é‡ï¼ˆè®¾ç½®ä¸º None è¡¨ç¤ºæŠ“å–æ‰€æœ‰ï¼Œæµ‹è¯•æ—¶å¯ä»¥è®¾ç½®è¾ƒå°å€¼ï¼‰
MAX_ITEMS_PER_PAGE = None  # æŠ“å–æ¯é¡µæ‰€æœ‰å¡ç‰‡

# æœ€å¤§æŠ“å–å²—ä½æ€»æ•°ï¼ˆè®¾ç½®ä¸º None è¡¨ç¤ºä¸é™åˆ¶ï¼‰
MAX_TOTAL_ITEMS = 100  # åªæŠ“å–å‰100ä¸ªå²—ä½

# æ˜¯å¦å¯ç”¨æ—¥æœŸè¿‡æ»¤ï¼ˆç½‘ç”³æˆªæ­¢çš„å²—ä½é€šå¸¸ä¸éœ€è¦æ—¥æœŸè¿‡æ»¤ï¼‰
ONLY_TODAY_UPDATED = False  # è®¾ç½®ä¸º True æ—¶å¯ç”¨æ—¥æœŸè¿‡æ»¤ï¼ŒFalse è¡¨ç¤ºæŠ“å–æ‰€æœ‰

# æ—¥æœŸè¿‡æ»¤å¤©æ•°ï¼ˆåªæŠ“å–æœ€è¿‘Nå¤©æ›´æ–°çš„å²—ä½ï¼‰
DATE_FILTER_DAYS = 2  # è®¾ç½®ä¸º 1 è¡¨ç¤ºåªæŠ“å–ä»Šå¤©ï¼Œè®¾ç½®ä¸º 2 è¡¨ç¤ºæŠ“å–æœ€è¿‘2å¤©ï¼Œä»¥æ­¤ç±»æ¨

# è¿ç»­ç©ºé¡µæ•°é˜ˆå€¼ï¼ˆå½“å¯ç”¨æ—¥æœŸè¿‡æ»¤æ—¶ï¼Œå¦‚æœè¿ç»­Né¡µæ²¡æœ‰ç›®æ ‡æ—¥æœŸèŒƒå›´å†…çš„å²—ä½ï¼Œåˆ™åœæ­¢ç¿»é¡µï¼‰
CONSECUTIVE_EMPTY_PAGES_THRESHOLD = 2  # è¿ç»­2é¡µæ²¡æœ‰ç›®æ ‡æ—¥æœŸèŒƒå›´å†…çš„å²—ä½å°±åœæ­¢

# Excelæ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›–æ›´æ–°ï¼‰
EXCEL_FILE_PATH = "ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶å…¬å¸åå•.xlsx"  # å›ºå®šæ–‡ä»¶åï¼Œç”¨äºè¦†ç›–æ›´æ–°

# ==================== CSSé€‰æ‹©å™¨é…ç½® ====================
# ä½¿ç”¨å¤šç§é€‰æ‹©å™¨ç»„åˆï¼Œè‡ªåŠ¨å°è¯•åŒ¹é…

# "ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶"æ ‡ç­¾é€‰æ‹©å™¨ï¼ˆéœ€è¦å…ˆç‚¹å‡»è¿™ä¸ªæ ‡ç­¾ï¼‰
NET_APPLY_TAB_SELECTOR = "text=ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶, button:has-text('ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶'), [class*='tab']:has-text('ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶')"

# åˆ—è¡¨å®¹å™¨é€‰æ‹©å™¨ï¼ˆ"ç½‘ç”³å¼€å¯"åˆ—è¡¨çš„å®¹å™¨ï¼‰
LIST_CONTAINER_SELECTOR = ".recruit-list, .job-list, [class*='list'], [class*='container'], .content, main"

# å•ä¸ªæ‹›è˜å¡ç‰‡é€‰æ‹©å™¨ï¼ˆå°è¯•å¤šç§å¯èƒ½çš„é€‰æ‹©å™¨ï¼‰
JOB_CARD_SELECTORS = [
    ".job-card",
    ".recruit-item", 
    "[class*='card']",
    "[class*='item']",
    "[class*='job']",
    "li[class*='item']",
    "div[class*='card']",
    ".el-card",
    ".ant-card"
]

# å…¬å¸åç§°é€‰æ‹©å™¨ï¼ˆåœ¨å¡ç‰‡å†…ï¼Œå°è¯•å¤šç§ï¼‰
COMPANY_NAME_SELECTORS = [
    ".company-name",
    "[class*='company']",
    "[class*='name']",
    "h3, h4, h5",
    ".title",
    "[class*='title']"
]

# å…¬å¸ç±»å‹å…³é”®è¯ï¼ˆä»æ ‡ç­¾ä¸­æå–ï¼‰
COMPANY_TYPE_KEYWORDS = ["å¤–èµ„", "å¤®/å›½ä¼", "å†…èµ„", "å›½ä¼", "å¤®ä¼", "å¤–ä¼"]

# å·¥ä½œåœ°ç‚¹é€‰æ‹©å™¨
LOCATION_SELECTORS = [
    ".location",
    "[class*='location']",
    "[class*='city']",
    "[class*='address']",
    ".address"
]

# æ‹›è˜ç±»å‹å…³é”®è¯ï¼ˆä»æ ‡ç­¾ä¸­æå–ï¼‰
RECRUIT_TYPE_KEYWORDS = ["æš‘æœŸå®ä¹ ", "ç§‹æ‹›æ­£å¼æ‰¹", "æ˜¥æ‹›", "å®ä¹ ", "æ ¡æ‹›", "ç¤¾æ‹›"]

# å²—ä½/æ ‡ç­¾å…³é”®è¯é€‰æ‹©å™¨ï¼ˆæå–æ‰€æœ‰æ ‡ç­¾ï¼‰
POSITION_TAG_SELECTORS = [
    ".tag",
    "[class*='tag']",
    "[class*='label']",
    ".label",
    "span[class*='tag']",
    ".el-tag",
    ".ant-tag"
]

# æ›´æ–°æ—¥æœŸé€‰æ‹©å™¨
UPDATE_DATE_SELECTORS = [
    ".update-date",
    "[class*='date']",
    "[class*='time']",
    "[class*='update']"
]

# "ç«‹å³æŠ•é€’"æŒ‰é’®é€‰æ‹©å™¨ï¼ˆä¼˜å…ˆä½¿ç”¨æ–‡æœ¬åŒ¹é…ï¼‰
APPLY_BUTTON_SELECTORS = [
    "button:has-text('ç«‹å³æŠ•é€’')",
    "a:has-text('ç«‹å³æŠ•é€’')",
    "*:has-text('ç«‹å³æŠ•é€’')",
    "[class*='apply']",
    "[class*='æŠ•é€’']",
    ".apply-btn",
    ".btn-apply"
]

# ä¸‹ä¸€é¡µæŒ‰é’®é€‰æ‹©å™¨
NEXT_PAGE_SELECTORS = [
    "button:has-text('ä¸‹ä¸€é¡µ')",
    "a:has-text('ä¸‹ä¸€é¡µ')",
    "button:has-text('Next')",
    ".next-page",
    "[class*='next']",
    ".pagination-next",
    ".el-pagination .btn-next"
]

# æ‹›è˜å¯¹è±¡é€‰æ‹©å™¨ï¼ˆåœ¨æ–°æ‰“å¼€çš„é¡µé¢ä¸­ï¼Œå¦‚æœå­˜åœ¨ï¼‰
RECRUIT_TARGET_SELECTORS = [
    ".recruit-target",
    "[class*='target']",
    "[class*='å¯¹è±¡']",
    "*:has-text('æ‹›è˜å¯¹è±¡')",
    "*:has-text('é¢å‘')"
]

# æŠ•é€’æˆªæ­¢æ—¶é—´é€‰æ‹©å™¨ï¼ˆåœ¨æ–°æ‰“å¼€çš„é¡µé¢ä¸­ï¼Œå¦‚æœå­˜åœ¨ï¼‰
DEADLINE_SELECTORS = [
    ".deadline",
    "[class*='deadline']",
    "[class*='æˆªæ­¢']",
    "*:has-text('æˆªæ­¢æ—¶é—´')",
    "*:has-text('æŠ•é€’æˆªæ­¢')",
    "*:has-text('æˆªæ­¢æ—¥æœŸ')"
]

# ==================== ä¸»ç±» ====================

class AceOfferRecruitScraper:
    def __init__(self):
        """åˆå§‹åŒ–çˆ¬è™«"""
        self.results: List[Dict] = []
        self.playwright = None
        self.browser = None
        self.context = None
        self.page = None
        
    async def random_wait(self, min_seconds: float = None, max_seconds: float = None):
        """éšæœºç­‰å¾…ï¼Œæ¨¡æ‹Ÿäººç±»æ“ä½œ"""
        min_sec = min_seconds or RANDOM_WAIT_MIN
        max_sec = max_seconds or RANDOM_WAIT_MAX
        wait_time = random.uniform(min_sec, max_sec)
        await asyncio.sleep(wait_time)
        
    async def start_browser(self):
        """å¯åŠ¨æµè§ˆå™¨ï¼ŒåŠ è½½ç”¨æˆ·é…ç½®æ–‡ä»¶"""
        print("\n" + "="*60)
        print("AceOffer æ‹›è˜ä¿¡æ¯æŠ“å–è„šæœ¬")
        print("="*60)
        print(f"\nå¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
        
        self.playwright = await async_playwright().start()
        
        # å¯åŠ¨ Chromiumï¼Œä½¿ç”¨ç”¨æˆ·æ•°æ®ç›®å½•ä¿æŒç™»å½•çŠ¶æ€
        print(f"ä½¿ç”¨ç”¨æˆ·æ•°æ®ç›®å½•: {CHROME_USER_DATA_DIR}")
        
        # å°è¯•å¯åŠ¨æµè§ˆå™¨ï¼Œå¦‚æœå¤±è´¥åˆ™æç¤º
        try:
            self.browser = await self.playwright.chromium.launch_persistent_context(
                user_data_dir=CHROME_USER_DATA_DIR,
                headless=False,  # è®¾ç½®ä¸º True å¯å¯ç”¨æ— å¤´æ¨¡å¼
                channel="chrome",  # ä½¿ç”¨ç³»ç»Ÿå®‰è£…çš„ Chromeï¼Œå¦‚æœåªæœ‰ chromium åˆ™æ”¹ä¸º None
                args=[
                    '--disable-blink-features=AutomationControlled',
                    '--disable-dev-shm-usage',
                    # ç§»é™¤ä»£ç†ç¦ç”¨è®¾ç½®ï¼Œä½¿ç”¨ç³»ç»Ÿä»£ç†ï¼ˆTUNæ¨¡å¼ä¼šè‡ªåŠ¨ç”Ÿæ•ˆï¼‰
                ],
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                ignore_https_errors=True  # å¿½ç•¥HTTPSé”™è¯¯
            )
        except Exception as e:
            if "ProcessSingleton" in str(e) or "profile is already in use" in str(e).lower():
                print("\n" + "="*60)
                print("âš  é”™è¯¯ï¼šChrome ç”¨æˆ·æ•°æ®ç›®å½•å·²è¢«å ç”¨")
                print("="*60)
                print("\nè§£å†³æ–¹æ¡ˆï¼š")
                print("1. å…³é—­æ‰€æœ‰ Chrome æµè§ˆå™¨çª—å£ï¼Œç„¶åé‡æ–°è¿è¡Œè„šæœ¬")
                print("2. æˆ–è€…ä¿®æ”¹è„šæœ¬ä¸­çš„ CHROME_USER_DATA_DIR ä¸ºç‹¬ç«‹ç›®å½•")
                print("   ï¼ˆä¾‹å¦‚ï¼š'/Users/changchun/Library/Application Support/Google/Chrome_Scraper'ï¼‰")
                print("   æ³¨æ„ï¼šä½¿ç”¨ç‹¬ç«‹ç›®å½•éœ€è¦é‡æ–°ç™»å½•ç½‘ç«™")
                print("="*60)
                raise
            else:
                raise
        
        # è·å–ç¬¬ä¸€ä¸ªé¡µé¢ï¼ˆpersistent context ä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªé¡µé¢ï¼‰
        pages = self.browser.pages
        if pages:
            self.page = pages[0]
        else:
            self.page = await self.browser.new_page()
            
        print("âœ“ æµè§ˆå™¨å¯åŠ¨æˆåŠŸï¼")
        await self.random_wait(2, 4)
        
    async def navigate_to_target(self):
        """è®¿é—®ç›®æ ‡URL"""
        print(f"\næ­£åœ¨è®¿é—®: {TARGET_URL}")
        try:
            await self.page.goto(TARGET_URL, wait_until="networkidle", timeout=60000)
            await self.random_wait(3, 5)
            print("âœ“ é¡µé¢åŠ è½½å®Œæˆ")
        except Exception as e:
            error_msg = str(e)
            if "PROXY" in error_msg or "proxy" in error_msg.lower():
                print(f"\n{'='*60}")
                print("âš  ä»£ç†è¿æ¥å¤±è´¥")
                print("="*60)
                print("\nè§£å†³æ–¹æ¡ˆï¼š")
                print("1. æ£€æŸ¥Chromeæµè§ˆå™¨çš„ä»£ç†è®¾ç½®ï¼ˆå·²æ‰“å¼€çš„æµè§ˆå™¨çª—å£ä¸­ï¼‰")
                print("2. æˆ–è€…åœ¨æµè§ˆå™¨åœ°å€æ æ‰‹åŠ¨è®¿é—®ç½‘ç«™ç™»å½•åï¼Œè„šæœ¬ä¼šç»§ç»­")
                print("3. ç­‰å¾…10ç§’åè„šæœ¬å°†é‡è¯•...")
                print("="*60)
                await asyncio.sleep(10)
                # é‡è¯•ä¸€æ¬¡
                try:
                    await self.page.goto(TARGET_URL, wait_until="networkidle", timeout=60000)
                    await self.random_wait(3, 5)
                    print("âœ“ é¡µé¢åŠ è½½å®Œæˆï¼ˆé‡è¯•æˆåŠŸï¼‰")
                except Exception as e2:
                    print(f"âš  é‡è¯•ä»ç„¶å¤±è´¥: {str(e2)}")
                    print("è¯·æ‰‹åŠ¨åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ç½‘ç«™å¹¶ç™»å½•ï¼Œç„¶åæŒ‰å›è½¦ç»§ç»­...")
                    # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ç”¨æˆ·æœ‰æœºä¼šæ‰‹åŠ¨æ“ä½œ
                    await asyncio.sleep(5)
            else:
                print(f"âš  è®¿é—®é¡µé¢æ—¶å‡ºé”™: {error_msg}")
                raise
            
    async def click_net_apply_tab(self):
        """ç‚¹å‡»"ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶"æ ‡ç­¾"""
        print("\næ£€æŸ¥å¹¶ç‚¹å‡»'ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶'æ ‡ç­¾...")
        try:
            # å°è¯•å¤šç§æ–¹å¼æ‰¾åˆ°å¹¶ç‚¹å‡»"ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶"æ ‡ç­¾
            tab_selectors = [
                "text=ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶",
                "button:has-text('ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶')",
                "a:has-text('ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶')",
                "[class*='tab']:has-text('ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶')",
                ".tab:has-text('ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶')"
            ]
            
            for selector in tab_selectors:
                try:
                    tab = await self.page.query_selector(selector)
                    if tab:
                        is_visible = await tab.is_visible()
                        if is_visible:
                            # æ£€æŸ¥æ˜¯å¦å·²é€‰ä¸­ï¼ˆå¯èƒ½éœ€è¦æ£€æŸ¥classæˆ–aria-selectedï¼‰
                            classes = await tab.get_attribute("class") or ""
                            if "active" not in classes.lower() and "selected" not in classes.lower():
                                print(f"  æ‰¾åˆ°'ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶'æ ‡ç­¾ï¼Œæ­£åœ¨ç‚¹å‡»...")
                                await tab.click()
                                await self.random_wait(2, 3)
                                print("  âœ“ å·²ç‚¹å‡»'ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶'æ ‡ç­¾")
                            else:
                                print("  âœ“ 'ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶'æ ‡ç­¾å·²é€‰ä¸­")
                            return True
                except Exception:
                    continue
                    
            print("  âš  æœªæ‰¾åˆ°'ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶'æ ‡ç­¾ï¼Œå¯èƒ½å·²åœ¨æ­£ç¡®é¡µé¢")
            return False
        except Exception as e:
            print(f"  âš  ç‚¹å‡»'ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶'æ ‡ç­¾æ—¶å‡ºé”™: {str(e)}")
            return False
            
    async def wait_for_list_loaded(self):
        """ç­‰å¾…æ‹›è˜åˆ—è¡¨åŠ è½½å®Œæˆ"""
        print("\nç­‰å¾…æ‹›è˜åˆ—è¡¨åŠ è½½...")
        try:
            # ç­‰å¾…æ›´é•¿æ—¶é—´ï¼Œç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
            await self.random_wait(3, 5)
            
            # å°è¯•å¤šä¸ªé€‰æ‹©å™¨
            for selector in LIST_CONTAINER_SELECTOR.split(", "):
                try:
                    await self.page.wait_for_selector(
                        selector.strip(),
                        timeout=15000,
                        state="visible"
                    )
                    await self.random_wait(2, 3)
                    print("âœ“ åˆ—è¡¨åŠ è½½å®Œæˆ")
                    break
                except PlaywrightTimeoutError:
                    continue
            
            # æ»šåŠ¨é¡µé¢ï¼Œç¡®ä¿æ‰€æœ‰å¡ç‰‡éƒ½åŠ è½½å‡ºæ¥ï¼ˆå¢åŠ æ»šåŠ¨æ¬¡æ•°ï¼‰
            print("æ­£åœ¨æ»šåŠ¨é¡µé¢ä»¥åŠ è½½æ‰€æœ‰å¡ç‰‡...")
            for i in range(5):  # å¢åŠ æ»šåŠ¨æ¬¡æ•°
                await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await self.random_wait(1.5, 2.5)
            # æ»šåŠ¨å›é¡¶éƒ¨
            await self.page.evaluate("window.scrollTo(0, 0)")
            await self.random_wait(2, 3)
            print("âœ“ é¡µé¢æ»šåŠ¨å®Œæˆ")
        except Exception as e:
            print(f"âš  ç­‰å¾…åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
            
    async def extract_text_with_selectors(self, element, selectors: list, default: str = "") -> str:
        """å°è¯•å¤šä¸ªé€‰æ‹©å™¨æå–æ–‡æœ¬"""
        for selector in selectors:
            try:
                sub_element = await element.query_selector(selector)
                if sub_element:
                    text = await sub_element.inner_text()
                    if text and text.strip():
                        return text.strip()
            except Exception:
                continue
        return default
        
    async def extract_all_text_with_selectors(self, element, selectors: list, separator: str = ", ") -> str:
        """å°è¯•å¤šä¸ªé€‰æ‹©å™¨æå–æ‰€æœ‰åŒ¹é…å…ƒç´ çš„æ–‡æœ¬"""
        for selector in selectors:
            try:
                elements = await element.query_selector_all(selector)
                if elements:
                    texts = []
                    for elem in elements:
                        text = await elem.inner_text()
                        if text and text.strip():
                            texts.append(text.strip())
                    if texts:
                        return separator.join(texts)
            except Exception:
                continue
        return ""
        
    def extract_keywords_from_text(self, text: str, keywords: list) -> str:
        """ä»æ–‡æœ¬ä¸­æå–åŒ…å«å…³é”®è¯çš„éƒ¨åˆ†"""
        found = []
        for keyword in keywords:
            if keyword in text:
                found.append(keyword)
        return ", ".join(found) if found else ""
        
    async def extract_text_from_element(self, element, selector: str, default: str = "") -> str:
        """ä»å…ƒç´ ä¸­æå–æ–‡æœ¬ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
        return await self.extract_text_with_selectors(element, [selector], default)
        
    async def extract_all_text_from_elements(self, element, selector: str, separator: str = ", ") -> str:
        """ä»å¤šä¸ªå…ƒç´ ä¸­æå–æ–‡æœ¬å¹¶åˆå¹¶ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
        return await self.extract_all_text_with_selectors(element, [selector], separator)
        
    async def extract_job_info_from_card(self, card_element) -> Dict:
        """ä»å•ä¸ªæ‹›è˜å¡ç‰‡ä¸­æå–åŸºç¡€ä¿¡æ¯"""
        job_info = {
            'å…¬å¸åç§°': '',
            'å…¬å¸ç±»å‹': '',
            'å·¥ä½œåœ°ç‚¹': '',
            'æ‹›è˜ç±»å‹': '',
            'æ‹›è˜å¯¹è±¡': '',
            'å²—ä½': '',
            'æ›´æ–°æ—¶é—´': '',
            'æŠ•é€’æˆªæ­¢': '',
            'ç›¸å…³é“¾æ¥': ''
        }
        
        try:
            # è·å–æ•´ä¸ªå¡ç‰‡çš„æ–‡æœ¬ï¼Œç”¨äºæ™ºèƒ½æå–
            card_text = await card_element.inner_text()
            
            # æå–å…¬å¸åç§°ï¼ˆä¼˜å…ˆä»æ ‡é¢˜å…ƒç´ æå–ï¼‰
            job_info['å…¬å¸åç§°'] = await self.extract_text_with_selectors(
                card_element, COMPANY_NAME_SELECTORS
            )
            
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»å¡ç‰‡æ–‡æœ¬ä¸­æå–
            if not job_info['å…¬å¸åç§°'] and card_text:
                lines = [line.strip() for line in card_text.split('\n') if line.strip()]
                # å°è¯•å‰å‡ è¡Œï¼Œæ‰¾åˆ°æœ€å¯èƒ½æ˜¯å…¬å¸åç§°çš„è¡Œ
                for line in lines[:10]:  # åªæ£€æŸ¥å‰10è¡Œ
                    # å…¬å¸åç§°é€šå¸¸è¾ƒé•¿ï¼Œä¸”ä¸åŒ…å«ç‰¹å®šå…³é”®è¯
                    if len(line) > 5 and len(line) < 150:
                        # æ’é™¤æ˜æ˜¾çš„æ ‡ç­¾å’ŒæŒ‰é’®æ–‡æœ¬
                        exclude_keywords = ['ç«‹å³æŠ•é€’', 'NEW', 'æ ¡æ‹›', 'å®ä¹ ', 'æ‹›è˜', 'æŠ•é€’', 'ç‚¹å‡»', 'æŸ¥çœ‹', 'æ›´å¤š', 'è¯¦æƒ…', '>>', '<<']
                        if not any(kw in line for kw in exclude_keywords):
                            # æ’é™¤çº¯æ•°å­—ã€çº¯ç¬¦å·ï¼Œå¿…é¡»åŒ…å«ä¸­æ–‡æˆ–è‹±æ–‡
                            if any(c.isalpha() or '\u4e00' <= c <= '\u9fff' for c in line):
                                # ä¼˜å…ˆé€‰æ‹©åŒ…å«"å…¬å¸"ã€"ä¼ä¸š"ã€"é›†å›¢"ç­‰å…³é”®è¯çš„è¡Œ
                                if any(kw in line for kw in ['å…¬å¸', 'ä¼ä¸š', 'é›†å›¢', 'é“¶è¡Œ', 'ç§‘æŠ€', 'ä¿¡æ¯', 'æœ‰é™']):
                                    job_info['å…¬å¸åç§°'] = line
                                    break
                                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ…å«å…³é”®è¯çš„ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªç¬¦åˆæ¡ä»¶çš„
                                if not job_info['å…¬å¸åç§°']:
                                    job_info['å…¬å¸åç§°'] = line
            
            # æå–æ‹›è˜ç±»å‹ï¼ˆä»æ ‡ç­¾ä¸­æå–ï¼Œæˆ–ä»æ–‡æœ¬ä¸­åŒ¹é…å…³é”®è¯ï¼‰
            # å…ˆå°è¯•ä»æ ‡ç­¾å…ƒç´ æå–
            recruit_type_text = ""
            for selector in POSITION_TAG_SELECTORS:
                try:
                    tags = await card_element.query_selector_all(selector)
                    for tag in tags:
                        tag_text = await tag.inner_text()
                        if tag_text:
                            for keyword in RECRUIT_TYPE_KEYWORDS:
                                if keyword in tag_text:
                                    recruit_type_text = tag_text.strip()
                                    break
                        if recruit_type_text:
                            break
                    if recruit_type_text:
                        break
                except Exception:
                    continue
            
            if not recruit_type_text and card_text:
                # ä»æ•´ä¸ªæ–‡æœ¬ä¸­åŒ¹é…å…³é”®è¯
                recruit_type_text = self.extract_keywords_from_text(card_text, RECRUIT_TYPE_KEYWORDS)
            
            job_info['æ‹›è˜ç±»å‹'] = recruit_type_text
            
            # æå–å…¬å¸ç±»å‹ï¼ˆä»æ ‡ç­¾ä¸­æå–å…³é”®è¯ï¼‰
            company_type_text = ""
            if card_text:
                company_type_text = self.extract_keywords_from_text(card_text, COMPANY_TYPE_KEYWORDS)
            job_info['å…¬å¸ç±»å‹'] = company_type_text
            
            # æå–å·¥ä½œåœ°ç‚¹ï¼ˆå°è¯•å¤šä¸ªé€‰æ‹©å™¨ï¼‰
            job_info['å·¥ä½œåœ°ç‚¹'] = await self.extract_all_text_with_selectors(
                card_element, LOCATION_SELECTORS, " "
            )
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–ï¼ˆå¸¸è§åŸå¸‚åï¼‰
            if not job_info['å·¥ä½œåœ°ç‚¹'] and card_text:
                # å¸¸è§åŸå¸‚åˆ—è¡¨
                cities = ["åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³", "æ­å·", "å—äº¬", "è‹å·", "æˆéƒ½", "é‡åº†", 
                         "æ­¦æ±‰", "è¥¿å®‰", "å¤©æ´¥", "é’å²›", "å¤§è¿", "å®æ³¢", "æ— é”¡", "é•¿æ²™", "éƒ‘å·",
                         "æµå—", "åˆè‚¥", "ç¦å·", "å¦é—¨", "æ˜†æ˜", "å—å®", "é¦™æ¸¯", "å°åŒ—", "å˜‰å…´"]
                found_cities = [city for city in cities if city in card_text]
                if found_cities:
                    job_info['å·¥ä½œåœ°ç‚¹'] = " ".join(found_cities)
            
            # æå–å²—ä½/æ ‡ç­¾å…³é”®è¯ï¼ˆæ’é™¤å·²æå–çš„æ‹›è˜ç±»å‹å’Œå…¬å¸ç±»å‹ï¼‰
            all_tags = await self.extract_all_text_with_selectors(
                card_element, POSITION_TAG_SELECTORS, ", "
            )
            if all_tags:
                # è¿‡æ»¤æ‰æ‹›è˜ç±»å‹å’Œå…¬å¸ç±»å‹
                tags_list = [tag.strip() for tag in all_tags.split(",")]
                filtered_tags = []
                for tag in tags_list:
                    is_recruit_type = any(kw in tag for kw in RECRUIT_TYPE_KEYWORDS)
                    is_company_type = any(kw in tag for kw in COMPANY_TYPE_KEYWORDS)
                    if not is_recruit_type and not is_company_type:
                        filtered_tags.append(tag)
                job_info['å²—ä½'] = ", ".join(filtered_tags)
            
            # æå–æ›´æ–°æ—¥æœŸ
            job_info['æ›´æ–°æ—¶é—´'] = await self.extract_text_with_selectors(
                card_element, UPDATE_DATE_SELECTORS
            )
            
        except Exception as e:
            print(f"    æå–åŸºç¡€ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            
        return job_info
        
    async def get_apply_link(self, card_element, job_info: Dict, seen_links: set) -> tuple:
        """ç‚¹å‡»"ç«‹å³æŠ•é€’"æŒ‰é’®ï¼Œè·å–çœŸå®æŠ•é€’é“¾æ¥å¹¶æå–å®Œæ•´ä¿¡æ¯
        
        Returns:
            tuple: (apply_link, extracted_info_dict)
        """
        apply_link = ""
        extracted_info = {
            'æ‹›è˜å¯¹è±¡': '',
            'æŠ•é€’æˆªæ­¢': '',
            'å²—ä½': '',
            'å…¬å¸ç±»å‹': '',
            'å·¥ä½œåœ°ç‚¹': '',
            'æ›´æ–°æ—¶é—´': ''
        }
        initial_page_count = len(self.browser.pages)
        
        try:
            # å°è¯•å¤šä¸ªé€‰æ‹©å™¨æŸ¥æ‰¾"ç«‹å³æŠ•é€’"æŒ‰é’®
            apply_button = None
            for selector in APPLY_BUTTON_SELECTORS:
                try:
                    apply_button = await card_element.query_selector(selector)
                    if apply_button:
                        is_visible = await apply_button.is_visible()
                        if is_visible:
                            break
                        else:
                            apply_button = None
                except Exception:
                    continue
                    
            if not apply_button:
                print(f"    âš  æœªæ‰¾åˆ°'ç«‹å³æŠ•é€’'æŒ‰é’®")
                return apply_link, extracted_info
            
            # ç‚¹å‡»æŒ‰é’®ï¼Œç­‰å¾…æ–°æ ‡ç­¾é¡µæ‰“å¼€
            print(f"    ç‚¹å‡»'ç«‹å³æŠ•é€’'æŒ‰é’®...")
            async with self.browser.expect_page(timeout=8000) as new_page_info:  # å‡å°‘è¶…æ—¶æ—¶é—´
                await apply_button.click()
            
            new_page = await new_page_info.value
            
            # å¿«é€Ÿç­‰å¾…é¡µé¢åŠ è½½ï¼ˆä¸ç­‰å¾…networkidleï¼Œåªç­‰å¾…DOMåŠ è½½ï¼‰
            try:
                await new_page.wait_for_load_state("domcontentloaded", timeout=4000)
            except Exception:
                pass
            
            # è·å–æ–°é¡µé¢çš„URL
            apply_link = new_page.url
            
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡ï¼ˆé¿å…é‡å¤æ‰“å¼€ï¼‰
            if apply_link in seen_links:
                print(f"    âš  é“¾æ¥å·²å¤„ç†è¿‡ï¼Œè·³è¿‡")
                await new_page.close()
                return apply_link, extracted_info
            
            print(f"    âœ“ è·å–åˆ°é“¾æ¥: {apply_link[:80]}...")
            
            # ä»é¡µé¢æå–å®Œæ•´ä¿¡æ¯
            extracted_info = await self.extract_info_from_link_page(new_page)
            
            # æ‰“å°æå–åˆ°çš„ä¿¡æ¯
            if extracted_info['æ‹›è˜å¯¹è±¡']:
                print(f"    âœ“ æ‹›è˜å¯¹è±¡: {extracted_info['æ‹›è˜å¯¹è±¡'][:50]}...")
            if extracted_info['æŠ•é€’æˆªæ­¢']:
                print(f"    âœ“ æŠ•é€’æˆªæ­¢: {extracted_info['æŠ•é€’æˆªæ­¢']}")
            if extracted_info['å²—ä½']:
                print(f"    âœ“ å²—ä½: {extracted_info['å²—ä½'][:50]}...")
            
            # å¿«é€Ÿå…³é—­æ–°æ ‡ç­¾é¡µï¼ˆå‡å°‘ç­‰å¾…æ—¶é—´ï¼‰
            await new_page.close()
            await asyncio.sleep(0.3)  # å‡å°‘ç­‰å¾…æ—¶é—´
            
            # åˆ‡æ¢å›åŸé¡µé¢
            await self.page.bring_to_front()
            
        except PlaywrightTimeoutError:
            print(f"    âš  ç­‰å¾…æ–°æ ‡ç­¾é¡µè¶…æ—¶")
        except Exception as e:
            print(f"    âš  è·å–æŠ•é€’é“¾æ¥æ—¶å‡ºé”™: {str(e)}")
            # ç¡®ä¿å…³é—­å¯èƒ½æ‰“å¼€çš„æ–°é¡µé¢
            try:
                pages = self.browser.pages
                if len(pages) > initial_page_count:
                    for p in pages[initial_page_count:]:
                        await p.close()
            except Exception:
                pass
                
        return apply_link, extracted_info
    
    async def extract_info_from_link_page(self, page) -> Dict:
        """ä»é“¾æ¥é¡µé¢æå–å®Œæ•´ä¿¡æ¯"""
        extracted_info = {
            'æ‹›è˜å¯¹è±¡': '',
            'æŠ•é€’æˆªæ­¢': '',
            'å²—ä½': '',
            'å…¬å¸ç±»å‹': '',
            'å·¥ä½œåœ°ç‚¹': '',
            'æ›´æ–°æ—¶é—´': ''
        }
        
        try:
            # è·å–é¡µé¢æ–‡æœ¬å†…å®¹
            page_text = await page.inner_text("body")
            if not page_text:
                return extracted_info
            
            # 1. æå–æ‹›è˜å¯¹è±¡ï¼ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›´å‡†ç¡®ï¼‰
            recruit_target_patterns = [
                r'æ‹›è˜å¯¹è±¡[ï¼š:]\s*([^ã€‚\n]{10,200})',
                r'é¢å‘[ï¼š:]\s*([^ã€‚\n]{10,200})',
                r'åº”è˜å¯¹è±¡[ï¼š:]\s*([^ã€‚\n]{10,200})',
            ]
            for pattern in recruit_target_patterns:
                matches = re.findall(pattern, page_text[:5000])
                if matches:
                    match = matches[0].strip()
                    # æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œ
                    match = re.sub(r'\s+', ' ', match)
                    if len(match) > 10 and len(match) < 300:
                        extracted_info['æ‹›è˜å¯¹è±¡'] = match[:300]
                        break
            
            # 2. æå–æŠ•é€’æˆªæ­¢æ—¶é—´
            deadline_patterns = [
                r'æˆªæ­¢[è‡³åˆ°]?\s*[:ï¼š]?\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
                r'æŠ•é€’æˆªæ­¢[ï¼š:]?\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
                r'æŠ¥åæˆªæ­¢[ï¼š:]?\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
                r'(\d{4}[-/]\d{1,2}[-/]\d{1,2}).*?æˆªæ­¢',
            ]
            for pattern in deadline_patterns:
                matches = re.findall(pattern, page_text[:5000])
                if matches:
                    extracted_info['æŠ•é€’æˆªæ­¢'] = matches[0].strip()
                    break
            
            # 3. æå–å²—ä½ä¿¡æ¯ï¼ˆæ›´ç²¾ç¡®ï¼‰
            position_patterns = [
                r'å²—ä½[ç±»åˆ«åç§°]?[ï¼š:]\s*([^ã€‚\n]{5,50})',
                r'èŒä½[åç§°]?[ï¼š:]\s*([^ã€‚\n]{5,50})',
                r'æ‹›è˜å²—ä½[ï¼š:]\s*([^ã€‚\n]{5,50})',
            ]
            found_positions = []
            for pattern in position_patterns:
                matches = re.findall(pattern, page_text[:3000])
                for match in matches[:3]:  # æœ€å¤šå–3ä¸ª
                    match = match.strip()
                    if match and len(match) > 3 and len(match) < 50:
                        # æ’é™¤æ˜æ˜¾çš„æ— å…³å†…å®¹
                        exclude_words = ['è¦æ±‚', 'æ¡ä»¶', 'ä¸å¾—', 'æŠ¥è€ƒ', 'å¯¹è±¡']
                        if not any(word in match for word in exclude_words):
                            found_positions.append(match)
            if found_positions:
                extracted_info['å²—ä½'] = ", ".join(found_positions[:5])[:200]
            
            # 4. æå–å·¥ä½œåœ°ç‚¹
            cities = ["åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³", "æ­å·", "å—äº¬", "è‹å·", "æˆéƒ½", "é‡åº†", 
                     "æ­¦æ±‰", "è¥¿å®‰", "å¤©æ´¥", "é’å²›", "å¤§è¿", "å®æ³¢", "æ— é”¡", "é•¿æ²™", "éƒ‘å·",
                     "æµå—", "åˆè‚¥", "ç¦å·", "å¦é—¨", "æ˜†æ˜", "å—å®", "é¦™æ¸¯", "å°åŒ—", "å˜‰å…´"]
            found_cities = [city for city in cities if city in page_text[:3000]]
            if found_cities:
                extracted_info['å·¥ä½œåœ°ç‚¹'] = " ".join(found_cities[:10])
                    
        except Exception as e:
            pass
        
        return extracted_info
        
    async def scrape_current_page(self) -> int:
        """æŠ“å–å½“å‰é¡µçš„æ‰€æœ‰æ‹›è˜ä¿¡æ¯"""
        print("\n" + "-"*60)
        print("å¼€å§‹æŠ“å–å½“å‰é¡µ...")
        
        # ç”¨äºè·Ÿè¸ªå·²å¤„ç†çš„é“¾æ¥ï¼Œé¿å…é‡å¤
        seen_links = set()
        
        try:
            # ä¼˜å…ˆé€šè¿‡"ç«‹å³æŠ•é€’"æŒ‰é’®å®šä½çœŸå®çš„æ‹›è˜å¡ç‰‡
            cards = []
            print("æ­£åœ¨é€šè¿‡'ç«‹å³æŠ•é€’'æŒ‰é’®å®šä½æ‹›è˜å¡ç‰‡...")
            try:
                # å…ˆç»Ÿè®¡æœ‰å¤šå°‘ä¸ª"ç«‹å³æŠ•é€’"æŒ‰é’®
                apply_buttons = await self.page.query_selector_all("text=ç«‹å³æŠ•é€’")
                print(f"  é¡µé¢ä¸Šå…±æœ‰ {len(apply_buttons)} ä¸ª'ç«‹å³æŠ•é€’'æŒ‰é’®")
                
                if apply_buttons:
                    # ç›´æ¥ä½¿ç”¨XPathæ‰¾åˆ°æŒ‰é’®çš„çˆ¶å®¹å™¨
                    xpath = "//button[contains(text(), 'ç«‹å³æŠ•é€’')]/ancestor::*[self::li or (self::div and position()>2)][1] | //a[contains(text(), 'ç«‹å³æŠ•é€’')]/ancestor::*[self::li or (self::div and position()>2)][1]"
                    all_cards = await self.page.query_selector_all(f"xpath={xpath}")
                    print(f"  é€šè¿‡XPathæ‰¾åˆ° {len(all_cards)} ä¸ªå¯èƒ½çš„å¡ç‰‡å®¹å™¨")
                    seen_elements = set()
                    for card in all_cards:
                        try:
                            # éªŒè¯ä¸æ˜¯æŒ‰é’®æœ¬èº«ï¼šæ£€æŸ¥æ–‡æœ¬é•¿åº¦
                            card_text = await card.inner_text()
                            if card_text and len(card_text) > 10:  # ç¡®ä¿æ˜¯å®¹å™¨ï¼Œä¸æ˜¯æŒ‰é’®
                                element_id = await card.evaluate("el => el.outerHTML.substring(0, 200)")
                                if element_id and element_id not in seen_elements:
                                    seen_elements.add(element_id)
                                    cards.append(card)
                        except Exception:
                            continue
                    
                    print(f"âœ“ æ‰¾åˆ° {len(cards)} ä¸ªå”¯ä¸€çš„æ‹›è˜å¡ç‰‡")
            except Exception as e:
                print(f"    å®šä½å¡ç‰‡æ—¶å‡ºé”™: {str(e)}")
                import traceback
                traceback.print_exc()
            
            # å¦‚æœXPathæ–¹æ³•å¤±è´¥ï¼Œå°è¯•å…¶ä»–é€‰æ‹©å™¨
            if not cards:
                print("å°è¯•ä½¿ç”¨å…¶ä»–é€‰æ‹©å™¨...")
                for selector in JOB_CARD_SELECTORS:
                    try:
                        cards = await self.page.query_selector_all(selector)
                        if cards and len(cards) > 0:
                            # è¿‡æ»¤ï¼šåªä¿ç•™åŒ…å«"ç«‹å³æŠ•é€’"æŒ‰é’®çš„å¡ç‰‡
                            filtered_cards = []
                            for card in cards:
                                try:
                                    has_apply = await card.query_selector("*:has-text('ç«‹å³æŠ•é€’')")
                                    if has_apply:
                                        filtered_cards.append(card)
                                except Exception:
                                    pass
                            if filtered_cards:
                                cards = filtered_cards
                                print(f"âœ“ ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(cards)} ä¸ªæœ‰æ•ˆçš„æ‹›è˜å¡ç‰‡")
                                break
                    except Exception:
                        continue
                
                # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œå°è¯•é€šè¿‡"ç«‹å³æŠ•é€’"æŒ‰é’®çš„çˆ¶å…ƒç´ æ¥å®šä½å¡ç‰‡
                if not cards and apply_buttons:
                    print("å°è¯•é€šè¿‡'ç«‹å³æŠ•é€’'æŒ‰é’®çš„çˆ¶å…ƒç´ å®šä½å¡ç‰‡...")
                    try:
                        temp_cards = []
                        for idx, btn in enumerate(apply_buttons[:100], 1):  # é™åˆ¶å¤„ç†å‰100ä¸ªæŒ‰é’®
                            try:
                                # ä½¿ç”¨ evaluate æ‰¾åˆ°æœ€è¿‘çš„çˆ¶å®¹å™¨
                                parent = await btn.evaluate_handle("""
                                    (btn) => {
                                        let el = btn;
                                        // å‘ä¸ŠæŸ¥æ‰¾æœ€å¤š15å±‚ï¼Œæ‰¾åˆ°åŒ…å«è¶³å¤Ÿæ–‡æœ¬çš„å®¹å™¨
                                        for (let i = 0; i < 15; i++) {
                                            el = el.parentElement;
                                            if (!el) break;
                                            let text = el.innerText || '';
                                            let classes = el.className || '';
                                            // æŸ¥æ‰¾åŒ…å«è¶³å¤Ÿæ–‡æœ¬çš„å®¹å™¨ï¼ˆå¯èƒ½æ˜¯å¡ç‰‡ï¼‰
                                            if (text.length > 30) {
                                                // æ£€æŸ¥æ˜¯å¦æ˜¯åˆé€‚çš„å®¹å™¨
                                                if (classes.includes('item') || classes.includes('card') || 
                                                    classes.includes('job') || classes.includes('recruit') ||
                                                    el.tagName === 'LI' || el.tagName === 'DIV' || el.tagName === 'ARTICLE') {
                                                    return el;
                                                }
                                            }
                                        }
                                        // å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›æŒ‰é’®çš„çˆ¶å…ƒç´ çš„çˆ¶å…ƒç´ 
                                        return btn.parentElement?.parentElement || btn.parentElement;
                                    }
                                """)
                                if parent:
                                    parent_elem = await parent.as_element()
                                    card_text = await parent_elem.inner_text()
                                    if card_text and len(card_text) > 20:  # ç¡®ä¿æ˜¯å¡ç‰‡è€Œä¸æ˜¯æŒ‰é’®æœ¬èº«
                                        temp_cards.append(parent_elem)
                            except Exception as e:
                                continue
                        
                        if temp_cards:
                            # å»é‡ï¼šä½¿ç”¨æ›´ç²¾ç¡®çš„å»é‡æ–¹æ³•
                            seen_cards = set()
                            unique_cards = []
                            for card in temp_cards:
                                try:
                                    # ä½¿ç”¨å¡ç‰‡çš„æ–‡æœ¬å†…å®¹å‰100ä¸ªå­—ç¬¦ä½œä¸ºå”¯ä¸€æ ‡è¯†
                                    card_text = await card.inner_text()
                                    card_id = card_text[:100] if card_text else ""
                                    if card_id and card_id not in seen_cards:
                                        seen_cards.add(card_id)
                                        unique_cards.append(card)
                                except:
                                    continue
                            cards = unique_cards
                            print(f"âœ“ é€šè¿‡æŒ‰é’®çˆ¶å…ƒç´ æ‰¾åˆ° {len(cards)} ä¸ªæ‹›è˜å¡ç‰‡")
                    except Exception as e:
                        print(f"  é€šè¿‡æŒ‰é’®çˆ¶å…ƒç´ å®šä½æ—¶å‡ºé”™: {str(e)}")
                        import traceback
                        traceback.print_exc()
                    
            if not cards:
                print("âš  æœªæ‰¾åˆ°æ‹›è˜å¡ç‰‡ï¼Œå°è¯•æœ€åçš„æ–¹æ³•ï¼šç›´æ¥ä½¿ç”¨æ‰€æœ‰åŒ…å«'ç«‹å³æŠ•é€’'çš„å…ƒç´ ...")
                # æœ€åå°è¯•ï¼šç›´æ¥æŸ¥æ‰¾æ‰€æœ‰åŒ…å«æŒ‰é’®çš„å®¹å™¨
                try:
                    # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½åŒ…å«æŒ‰é’®çš„å®¹å™¨
                    all_containers = await self.page.query_selector_all("div, li, article")
                    potential_cards = []
                    for container in all_containers:
                        try:
                            container_text = await container.inner_text()
                            # å¦‚æœå®¹å™¨åŒ…å«"ç«‹å³æŠ•é€’"ä¸”æœ‰è¶³å¤Ÿçš„å†…å®¹ï¼Œå¯èƒ½æ˜¯å¡ç‰‡
                            if container_text and "ç«‹å³æŠ•é€’" in container_text and len(container_text) > 30:
                                # æ£€æŸ¥æ˜¯å¦åŒ…å«å…¬å¸åç§°æˆ–å²—ä½ä¿¡æ¯çš„å…³é”®è¯
                                if any(keyword in container_text for keyword in ["å…¬å¸", "æ‹›è˜", "å²—ä½", "èŒä½", "å®ä¹ ", "æ ¡æ‹›"]):
                                    potential_cards.append(container)
                        except:
                            continue
                    
                    if potential_cards:
                        # å»é‡
                        seen_texts = set()
                        unique_cards = []
                        for card in potential_cards:
                            try:
                                card_text = await card.inner_text()
                                text_id = card_text[:100] if card_text else ""
                                if text_id and text_id not in seen_texts:
                                    seen_texts.add(text_id)
                                    unique_cards.append(card)
                            except:
                                continue
                        
                        if unique_cards:
                            cards = unique_cards[:100]  # é™åˆ¶ä¸º100ä¸ª
                            print(f"âœ“ é€šè¿‡é€šç”¨æ–¹æ³•æ‰¾åˆ° {len(cards)} ä¸ªå¯èƒ½çš„æ‹›è˜å¡ç‰‡")
                except Exception as e:
                    print(f"  é€šç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {str(e)}")
                
                if not cards:
                    print("âš  æœªæ‰¾åˆ°æ‹›è˜å¡ç‰‡ï¼Œè¯·æ£€æŸ¥é¡µé¢æ˜¯å¦æ­£å¸¸åŠ è½½")
                    # å°è¯•æ‰“å°é¡µé¢HTMLçš„ä¸€éƒ¨åˆ†æ¥è°ƒè¯•
                    try:
                        page_content = await self.page.content()
                        if "ç«‹å³æŠ•é€’" in page_content:
                            print("  âœ“ é¡µé¢ä¸­åŒ…å«'ç«‹å³æŠ•é€’'æ–‡æœ¬ï¼Œä½†æœªæ‰¾åˆ°å¡ç‰‡å…ƒç´ ")
                            print("  ğŸ’¡ æç¤ºï¼šå¯èƒ½éœ€è¦è°ƒæ•´é€‰æ‹©å™¨æˆ–ç­‰å¾…æ›´é•¿æ—¶é—´")
                        else:
                            print("  âš  é¡µé¢ä¸­æœªæ‰¾åˆ°'ç«‹å³æŠ•é€’'æ–‡æœ¬")
                    except:
                        pass
                    return 0
                
            # å¦‚æœè®¾ç½®äº†æ¯é¡µæœ€å¤§æ•°é‡ï¼Œåªå¤„ç†å‰Nä¸ª
            if MAX_ITEMS_PER_PAGE and len(cards) > MAX_ITEMS_PER_PAGE:
                print(f"âš  å½“å‰é¡µæœ‰ {len(cards)} ä¸ªå¡ç‰‡ï¼Œä½†é™åˆ¶æ¯é¡µæœ€å¤šæŠ“å– {MAX_ITEMS_PER_PAGE} ä¸ª")
                cards = cards[:MAX_ITEMS_PER_PAGE]
                
            # éå†æ¯ä¸ªå¡ç‰‡
            for idx, card in enumerate(cards, 1):
                print(f"\nå¤„ç†ç¬¬ {idx}/{len(cards)} ä¸ªå¡ç‰‡...")
                
                # éªŒè¯å¡ç‰‡æ˜¯å¦æœ‰"ç«‹å³æŠ•é€’"æŒ‰é’®ï¼ˆç¡®ä¿æ˜¯æœ‰æ•ˆçš„æ‹›è˜å¡ç‰‡ï¼‰
                try:
                    has_apply_btn = await card.query_selector("*:has-text('ç«‹å³æŠ•é€’')")
                    if not has_apply_btn:
                        print(f"  âš  è·³è¿‡ï¼šæœªæ‰¾åˆ°'ç«‹å³æŠ•é€’'æŒ‰é’®ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„æ‹›è˜å¡ç‰‡")
                        continue
                except Exception:
                    print(f"  âš  è·³è¿‡ï¼šæ— æ³•éªŒè¯å¡ç‰‡æœ‰æ•ˆæ€§")
                    continue
                
                # æå–åŸºç¡€ä¿¡æ¯ï¼ˆå…ˆæå–ï¼Œç”¨äºæ—¥æœŸè¿‡æ»¤ï¼‰
                job_info = await self.extract_job_info_from_card(card)
                
                # æ—¥æœŸè¿‡æ»¤ï¼šå¦‚æœå¯ç”¨äº†æ—¥æœŸè¿‡æ»¤ï¼Œå…ˆæ£€æŸ¥æ—¥æœŸå†å†³å®šæ˜¯å¦ç‚¹å‡»æŒ‰é’®
                if ONLY_TODAY_UPDATED:
                    update_time = job_info.get('æ›´æ–°æ—¶é—´', '')
                    if not self.is_recent_days_updated(update_time, days=DATE_FILTER_DAYS):
                        print(f"  âš  è·³è¿‡ï¼šä¸åœ¨æœ€è¿‘{DATE_FILTER_DAYS}å¤©å†…çš„å²—ä½ï¼ˆæ›´æ–°æ—¶é—´: {update_time or 'æ— '}ï¼‰")
                        continue
                
                # è·å–æŠ•é€’é“¾æ¥å¹¶æå–å®Œæ•´ä¿¡æ¯
                apply_link, extracted_info = await self.get_apply_link(card, job_info, seen_links)
                
                # æ£€æŸ¥é“¾æ¥æ˜¯å¦å·²å¤„ç†è¿‡ï¼ˆå»é‡ï¼‰
                if apply_link and apply_link in seen_links:
                    print(f"  âš  è·³è¿‡ï¼šé“¾æ¥å·²å¤„ç†è¿‡ï¼ˆé‡å¤ï¼‰")
                    continue
                
                # æ›´æ–°ä¿¡æ¯ï¼šä¼˜å…ˆä½¿ç”¨ä»é“¾æ¥é¡µé¢æå–çš„ä¿¡æ¯ï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨å¡ç‰‡ä¿¡æ¯
                job_info['ç›¸å…³é“¾æ¥'] = apply_link
                
                # è¡¥å……ç©ºå­—æ®µï¼šå¦‚æœjob_infoä¸­çš„å­—æ®µä¸ºç©ºï¼Œä½¿ç”¨extracted_infoä¸­çš„å€¼
                if not job_info['æ‹›è˜å¯¹è±¡'] and extracted_info.get('æ‹›è˜å¯¹è±¡'):
                    job_info['æ‹›è˜å¯¹è±¡'] = extracted_info['æ‹›è˜å¯¹è±¡']
                if not job_info['æŠ•é€’æˆªæ­¢'] and extracted_info.get('æŠ•é€’æˆªæ­¢'):
                    job_info['æŠ•é€’æˆªæ­¢'] = extracted_info['æŠ•é€’æˆªæ­¢']
                if not job_info['å²—ä½'] and extracted_info.get('å²—ä½'):
                    job_info['å²—ä½'] = extracted_info['å²—ä½']
                if not job_info['å…¬å¸ç±»å‹'] and extracted_info.get('å…¬å¸ç±»å‹'):
                    job_info['å…¬å¸ç±»å‹'] = extracted_info['å…¬å¸ç±»å‹']
                if not job_info['å·¥ä½œåœ°ç‚¹'] and extracted_info.get('å·¥ä½œåœ°ç‚¹'):
                    job_info['å·¥ä½œåœ°ç‚¹'] = extracted_info['å·¥ä½œåœ°ç‚¹']
                if not job_info['æ›´æ–°æ—¶é—´'] and extracted_info.get('æ›´æ–°æ—¶é—´'):
                    job_info['æ›´æ–°æ—¶é—´'] = extracted_info['æ›´æ–°æ—¶é—´']
                
                # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§ï¼šè‡³å°‘è¦æœ‰å…¬å¸åç§°æˆ–ç›¸å…³é“¾æ¥
                if not job_info['å…¬å¸åç§°'] and not job_info['ç›¸å…³é“¾æ¥']:
                    print(f"  âš  è·³è¿‡ï¼šæ•°æ®æ— æ•ˆï¼ˆæ— å…¬å¸åç§°ä¸”æ— é“¾æ¥ï¼‰")
                    continue
                
                # æ—¥æœŸè¿‡æ»¤å·²ç»åœ¨ç‚¹å‡»æŒ‰é’®ä¹‹å‰å®Œæˆï¼Œè¿™é‡Œä¸éœ€è¦å†æ¬¡æ£€æŸ¥
                
                # è®°å½•å·²å¤„ç†çš„é“¾æ¥
                if apply_link:
                    seen_links.add(apply_link)
                
                # ä¿å­˜ç»“æœ
                self.results.append(job_info)
                print(f"  âœ“ å…¬å¸: {job_info['å…¬å¸åç§°'] or '(æœªæå–)'}, ç±»å‹: {job_info['æ‹›è˜ç±»å‹'] or '(æœªæå–)'}, é“¾æ¥: {'å·²è·å–' if job_info['ç›¸å…³é“¾æ¥'] else 'æœªè·å–'}")
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æŠ“å–æ•°é‡
                if MAX_TOTAL_ITEMS and len(self.results) >= MAX_TOTAL_ITEMS:
                    print(f"\nâš  å·²è¾¾åˆ°æœ€å¤§æŠ“å–æ•°é‡é™åˆ¶ ({MAX_TOTAL_ITEMS})ï¼Œåœæ­¢æŠ“å–")
                    return len(self.results)
                
                # çŸ­æš‚ç­‰å¾…ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                await asyncio.sleep(0.3)
                
            print(f"\nâœ“ å½“å‰é¡µæŠ“å–å®Œæˆï¼Œå…± {len(cards)} æ¡è®°å½•")
            return len(cards)
            
        except Exception as e:
            print(f"âš  æŠ“å–å½“å‰é¡µæ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return 0
            
    async def has_next_page(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ"""
        try:
            # å°è¯•å¤šä¸ªé€‰æ‹©å™¨
            for selector in NEXT_PAGE_SELECTORS:
                try:
                    next_button = await self.page.query_selector(selector)
                    if next_button:
                        is_visible = await next_button.is_visible()
                        if is_visible:
                            # æ£€æŸ¥æŒ‰é’®æ˜¯å¦å¯ç‚¹å‡»ï¼ˆæœªè¢«ç¦ç”¨ï¼‰
                            is_disabled = await next_button.get_attribute("disabled")
                            if not is_disabled:
                                return True
                except Exception:
                    continue
            return False
        except Exception:
            return False
            
    async def go_to_next_page(self) -> bool:
        """ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®"""
        try:
            # å°è¯•å¤šä¸ªé€‰æ‹©å™¨
            next_button = None
            for selector in NEXT_PAGE_SELECTORS:
                try:
                    next_button = await self.page.query_selector(selector)
                    if next_button:
                        is_visible = await next_button.is_visible()
                        if is_visible:
                            is_disabled = await next_button.get_attribute("disabled")
                            if not is_disabled:
                                break
                        else:
                            next_button = None
                except Exception:
                    continue
                    
            if not next_button:
                return False
                
            print("\n" + "-"*60)
            print("ç‚¹å‡»'ä¸‹ä¸€é¡µ'æŒ‰é’®...")
            await next_button.click()
            await self.random_wait(3, 5)
            
            # ç­‰å¾…åˆ—è¡¨é‡æ–°åŠ è½½
            await self.wait_for_list_loaded()
            
            return True
            
        except Exception as e:
            print(f"âš  ç¿»é¡µæ—¶å‡ºé”™: {str(e)}")
            return False
            
    def is_recent_days_updated(self, update_date_str: str, days: int = DATE_FILTER_DAYS) -> bool:
        """æ£€æŸ¥æ›´æ–°æ—¥æœŸæ˜¯å¦åœ¨æœ€è¿‘Nå¤©å†…"""
        if not update_date_str or update_date_str == '' or update_date_str == 'æ— ':
            # å¦‚æœæ²¡æœ‰æ›´æ–°æ—¥æœŸï¼Œå‡è®¾å¯èƒ½æ˜¯æœ€æ–°å¼€å¯çš„ï¼ŒåŒ…å«è¿›æ¥
            return True
        
        try:
            from datetime import timedelta
            today = datetime.now()
            cutoff_date = today - timedelta(days=days-1)  # days-1 å› ä¸ºåŒ…å«ä»Šå¤©
            
            # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
            date_formats = ['%Y-%m-%d', '%Y/%m/%d', '%Yå¹´%mæœˆ%dæ—¥', '%m-%d', '%m/%d', '%mæœˆ%dæ—¥']
            for fmt in date_formats:
                try:
                    parsed_date = datetime.strptime(update_date_str.strip(), fmt)
                    # å¦‚æœåªæœ‰æœˆæ—¥ï¼Œéœ€è¦è¡¥å……å¹´ä»½ï¼ˆå‡è®¾æ˜¯ä»Šå¹´ï¼‰
                    if fmt in ['%m-%d', '%m/%d', '%mæœˆ%dæ—¥']:
                        parsed_date = parsed_date.replace(year=today.year)
                        # å¦‚æœæ—¥æœŸå·²ç»è¿‡äº†ä»Šå¹´ï¼Œå¯èƒ½æ˜¯å»å¹´çš„
                        if parsed_date > today:
                            parsed_date = parsed_date.replace(year=today.year - 1)
                    
                    # æ£€æŸ¥æ—¥æœŸæ˜¯å¦åœ¨èŒƒå›´å†…
                    if parsed_date.date() >= cutoff_date.date():
                        return True
                except:
                    continue
            return False
        except:
            return False
    
    def is_today_updated(self, update_date_str: str) -> bool:
        """æ£€æŸ¥æ›´æ–°æ—¥æœŸæ˜¯å¦ä¸ºä»Šå¤©ï¼ˆå…¼å®¹æ—§æ–¹æ³•ï¼‰"""
        return self.is_recent_days_updated(update_date_str, days=1)
    
    async def scrape_all_pages(self):
        """æŠ“å–æ‰€æœ‰é¡µé¢çš„æ‹›è˜ä¿¡æ¯"""
        page_num = 1
        today_updated_count = 0
        skipped_count = 0
        consecutive_empty_pages = 0  # è¿ç»­æ²¡æœ‰å½“å¤©æ›´æ–°å²—ä½çš„é¡µæ•°
        
        if MAX_TOTAL_ITEMS:
            print(f"\n{'='*60}")
            print(f"âš  æŠ“å–é™åˆ¶ï¼šæœ€å¤šæŠ“å– {MAX_TOTAL_ITEMS} ä¸ªå²—ä½")
            print(f"{'='*60}\n")
        
        if ONLY_TODAY_UPDATED:
            print(f"\n{'='*60}")
            print(f"âš  æ—¥æœŸè¿‡æ»¤æ¨¡å¼ï¼šåªæŠ“å–æœ€è¿‘ {DATE_FILTER_DAYS} å¤©æ›´æ–°çš„å²—ä½")
            print(f"âš  æ™ºèƒ½ç¿»é¡µï¼šè¿ç»­ {CONSECUTIVE_EMPTY_PAGES_THRESHOLD} é¡µæ²¡æœ‰ç›®æ ‡æ—¥æœŸèŒƒå›´å†…çš„å²—ä½å°†è‡ªåŠ¨åœæ­¢")
            print(f"{'='*60}\n")
        
        while True:
            print(f"\n{'='*60}")
            print(f"ç¬¬ {page_num} é¡µ")
            print(f"{'='*60}")
            
            # è®°å½•æŠ“å–å‰çš„æ•°é‡
            results_before = len(self.results)
            today_count_before = sum(1 for r in self.results if self.is_recent_days_updated(r.get('æ›´æ–°æ—¶é—´', ''), days=DATE_FILTER_DAYS)) if ONLY_TODAY_UPDATED else 0
            
            # æŠ“å–å½“å‰é¡µ
            count = await self.scrape_current_page()
            
            if count == 0:
                print("âš  å½“å‰é¡µæ²¡æœ‰æ•°æ®ï¼Œåœæ­¢æŠ“å–")
                break
            
            # å¦‚æœå¯ç”¨äº†æ—¥æœŸè¿‡æ»¤ï¼Œç»Ÿè®¡æœ€è¿‘Nå¤©æ›´æ–°çš„æ•°é‡
            if ONLY_TODAY_UPDATED:
                today_count_after = sum(1 for r in self.results if self.is_recent_days_updated(r.get('æ›´æ–°æ—¶é—´', ''), days=DATE_FILTER_DAYS))
                today_added_this_page = today_count_after - today_count_before
                
                if today_added_this_page > 0:
                    print(f"  å½“å‰é¡µæœ€è¿‘{DATE_FILTER_DAYS}å¤©æ›´æ–°çš„å²—ä½: {today_added_this_page} æ¡")
                    today_updated_count = today_count_after
                    skipped_count = len(self.results) - today_updated_count
                    consecutive_empty_pages = 0  # é‡ç½®è¿ç»­ç©ºé¡µè®¡æ•°
                else:
                    consecutive_empty_pages += 1
                    print(f"  å½“å‰é¡µæ²¡æœ‰æœ€è¿‘{DATE_FILTER_DAYS}å¤©æ›´æ–°çš„å²—ä½ï¼ˆè¿ç»­ {consecutive_empty_pages} é¡µï¼‰")
                    
                    # å¦‚æœè¿ç»­Né¡µéƒ½æ²¡æœ‰ç›®æ ‡æ—¥æœŸèŒƒå›´å†…çš„å²—ä½ï¼Œåœæ­¢ç¿»é¡µ
                    if consecutive_empty_pages >= CONSECUTIVE_EMPTY_PAGES_THRESHOLD:
                        print(f"\nâš  è¿ç»­ {consecutive_empty_pages} é¡µæ²¡æœ‰æœ€è¿‘{DATE_FILTER_DAYS}å¤©æ›´æ–°çš„å²—ä½ï¼Œåœæ­¢ç¿»é¡µ")
                        break
            else:
                # æœªå¯ç”¨æ—¥æœŸè¿‡æ»¤æ—¶ï¼Œæ­£å¸¸ç»Ÿè®¡
                today_updated_count = len(self.results)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æŠ“å–æ•°é‡
            if MAX_TOTAL_ITEMS and len(self.results) >= MAX_TOTAL_ITEMS:
                print(f"\nå·²è¾¾åˆ°æœ€å¤§æŠ“å–æ•°é‡é™åˆ¶ ({MAX_TOTAL_ITEMS})ï¼Œåœæ­¢æŠ“å–")
                break
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§é¡µæ•°
            if MAX_PAGES and page_num >= MAX_PAGES:
                print(f"\nå·²è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶ ({MAX_PAGES})ï¼Œåœæ­¢æŠ“å–")
                break
                
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
            if not await self.has_next_page():
                print("\nâœ“ å·²åˆ°è¾¾æœ€åä¸€é¡µ")
                break
                
            # ç¿»é¡µ
            if not await self.go_to_next_page():
                print("\nâš  æ— æ³•ç¿»é¡µï¼Œåœæ­¢æŠ“å–")
                break
                
            page_num += 1
        
        if ONLY_TODAY_UPDATED:
            print(f"\n{'='*60}")
            print(f"æ—¥æœŸè¿‡æ»¤ç»Ÿè®¡:")
            print(f"  æœ€è¿‘{DATE_FILTER_DAYS}å¤©æ›´æ–°çš„å²—ä½: {today_updated_count} æ¡")
            print(f"  å·²è·³è¿‡éæœ€è¿‘{DATE_FILTER_DAYS}å¤©æ›´æ–°çš„å²—ä½: {skipped_count} æ¡")
            print(f"{'='*60}")
            
    async def save_to_excel(self, overwrite: bool = False):
        """ä¿å­˜æ•°æ®åˆ°Excelæ–‡ä»¶
        
        Args:
            overwrite: æ˜¯å¦ä¸ºè¦†ç›–æ›´æ–°æ¨¡å¼ï¼ˆè¦†ç›–ç°æœ‰æ–‡ä»¶ï¼Œåªä¿ç•™ä»Šå¤©çš„æ•°æ®ï¼‰
        """
        import os
        
        if not self.results:
            print("\nâš  æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return
            
        print(f"\n{'='*60}")
        if overwrite:
            print(f"è¦†ç›–æ›´æ–°Excelæ–‡ä»¶ï¼ˆåªä¿ç•™æœ€è¿‘{DATE_FILTER_DAYS}å¤©æ›´æ–°çš„å²—ä½ï¼‰...")
        else:
            print("ä¿å­˜æ•°æ®åˆ°Excel...")
        print(f"{'='*60}")
        
        # åˆ›å»ºDataFrame
        new_df = pd.DataFrame(self.results)
        
        # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºç©ºåˆ—ï¼‰
        columns_order = [
            'å…¬å¸åç§°', 'å…¬å¸ç±»å‹', 'å·¥ä½œåœ°ç‚¹', 'æ‹›è˜ç±»å‹', 
            'æ‹›è˜å¯¹è±¡', 'å²—ä½', 'æ›´æ–°æ—¶é—´', 'æŠ•é€’æˆªæ­¢', 'ç›¸å…³é“¾æ¥'
        ]
        
        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
        for col in columns_order:
            if col not in new_df.columns:
                new_df[col] = ''
        
        # æŒ‰æŒ‡å®šé¡ºåºæ’åˆ—åˆ—
        new_df = new_df[columns_order]
        
        # æ•°æ®æ¸…ç†ï¼šå°†ç©ºå­—ç¬¦ä¸²æ›¿æ¢ä¸ºNaNï¼Œç„¶åè¿‡æ»¤æ‰å®Œå…¨ç©ºçš„è¡Œ
        new_df = new_df.replace('', pd.NA)
        
        # è¿‡æ»¤æ‰æ²¡æœ‰å…¬å¸åç§°ä¸”æ²¡æœ‰ç›¸å…³é“¾æ¥çš„æ— æ•ˆè¡Œ
        new_df = new_df[new_df['å…¬å¸åç§°'].notna() | new_df['ç›¸å…³é“¾æ¥'].notna()]
        
        # å°†NaNæ›¿æ¢å›ç©ºå­—ç¬¦ä¸²ï¼Œä¿æŒExcelæ ¼å¼æ•´æ´
        new_df = new_df.fillna('')
        
        # æ•°æ®éªŒè¯å’Œæ¸…ç†
        print(f"\næ–°æŠ“å–æ•°æ®: {len(new_df)} æ¡è®°å½•")
        
        # ç§»é™¤å…¬å¸åç§°ä¸ºç©ºä¸”ç›¸å…³é“¾æ¥ä¹Ÿä¸ºç©ºçš„è®°å½•
        valid_new_df = new_df[(new_df['å…¬å¸åç§°'] != '') | (new_df['ç›¸å…³é“¾æ¥'] != '')]
        print(f"è¿‡æ»¤æ— æ•ˆè®°å½•å: {len(valid_new_df)} æ¡æœ‰æ•ˆè®°å½•")
        
        # æ¸…ç†ç©ºå€¼ï¼šå°†ç©ºå­—ç¬¦ä¸²å’ŒNaNç»Ÿä¸€å¤„ç†
        for col in valid_new_df.columns:
            valid_new_df[col] = valid_new_df[col].replace('', pd.NA)
            valid_new_df[col] = valid_new_df[col].fillna('')
        
        # åªä¿ç•™æœ‰å…¬å¸åç§°çš„è®°å½•ï¼ˆç¡®ä¿æ•°æ®è´¨é‡ï¼‰
        valid_new_df = valid_new_df[valid_new_df['å…¬å¸åç§°'] != '']
        print(f"æœ€ç»ˆæ–°è®°å½•: {len(valid_new_df)} æ¡ï¼ˆä»…ä¿ç•™æœ‰å…¬å¸åç§°çš„è®°å½•ï¼‰")
        
        # å¦‚æœæ˜¯è¦†ç›–æ›´æ–°æ¨¡å¼ï¼Œç›´æ¥ä¿å­˜ä»Šå¤©çš„æ•°æ®ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰
        if overwrite:
            # è¦†ç›–æ¨¡å¼ï¼šåªä¿å­˜ä»Šå¤©çš„æ•°æ®ï¼Œè¦†ç›–åŸæ–‡ä»¶
            # å»é‡ï¼šä¼˜å…ˆåŸºäºç›¸å…³é“¾æ¥
            before_dedup = len(valid_new_df)
            valid_new_df = valid_new_df.drop_duplicates(subset=['ç›¸å…³é“¾æ¥'], keep='first')
            no_link_df = valid_new_df[valid_new_df['ç›¸å…³é“¾æ¥'] == '']
            has_link_df = valid_new_df[valid_new_df['ç›¸å…³é“¾æ¥'] != '']
            if len(no_link_df) > 0:
                no_link_df = no_link_df.drop_duplicates(subset=['å…¬å¸åç§°'], keep='first')
            valid_new_df = pd.concat([has_link_df, no_link_df], ignore_index=True)
            
            after_dedup = len(valid_new_df)
            if before_dedup > after_dedup:
                print(f"å»é‡å: {after_dedup} æ¡è®°å½•ï¼ˆå»é™¤äº† {before_dedup - after_dedup} æ¡é‡å¤è®°å½•ï¼‰")
            
            print(f"\nè¦†ç›–æ›´æ–°æ¨¡å¼ï¼šå°†ä¿å­˜ {len(valid_new_df)} æ¡æœ€è¿‘{DATE_FILTER_DAYS}å¤©æ›´æ–°çš„å²—ä½åˆ°æ–‡ä»¶")
            df = valid_new_df.reset_index(drop=True)
            filename = EXCEL_FILE_PATH
        else:
            # éå¢é‡æ¨¡å¼ï¼šåªå¤„ç†æ–°æ•°æ®
            # å»é‡ï¼šä¼˜å…ˆåŸºäºç›¸å…³é“¾æ¥
            before_dedup = len(valid_new_df)
            valid_new_df = valid_new_df.drop_duplicates(subset=['ç›¸å…³é“¾æ¥'], keep='first')
            no_link_df = valid_new_df[valid_new_df['ç›¸å…³é“¾æ¥'] == '']
            has_link_df = valid_new_df[valid_new_df['ç›¸å…³é“¾æ¥'] != '']
            if len(no_link_df) > 0:
                no_link_df = no_link_df.drop_duplicates(subset=['å…¬å¸åç§°'], keep='first')
            valid_new_df = pd.concat([has_link_df, no_link_df], ignore_index=True)
            
            after_dedup = len(valid_new_df)
            if before_dedup > after_dedup:
                print(f"å»é‡å: {after_dedup} æ¡è®°å½•ï¼ˆå»é™¤äº† {before_dedup - after_dedup} æ¡é‡å¤è®°å½•ï¼‰")
            
            df = valid_new_df.reset_index(drop=True)
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"recruit_data_{timestamp}.xlsx"
        
        # ä¿å­˜åˆ°Excel
        try:
            df.to_excel(filename, index=False, engine='openpyxl')
            
            # å¦‚æœæ˜¯è¦†ç›–æ›´æ–°æ¨¡å¼ï¼Œç»™æ‰€æœ‰è¡Œæ·»åŠ é¢œè‰²æ ‡æ³¨ï¼ˆå› ä¸ºéƒ½æ˜¯ä»Šå¤©æ›´æ–°çš„ï¼‰
            if overwrite:
                try:
                    from openpyxl import load_workbook
                    from openpyxl.styles import PatternFill, Font, Alignment
                    
                    # æ‰“å¼€å·²ä¿å­˜çš„Excelæ–‡ä»¶
                    wb = load_workbook(filename)
                    ws = wb.active
                    
                    # å®šä¹‰é¢œè‰²ï¼šæµ…ç»¿è‰²èƒŒæ™¯ï¼Œæ·±ç»¿è‰²æ–‡å­—
                    fill_color = PatternFill(start_color='E8F5E9', end_color='E8F5E9', fill_type='solid')  # æµ…ç»¿è‰²
                    header_fill = PatternFill(start_color='C8E6C9', end_color='C8E6C9', fill_type='solid')  # ç¨æ·±çš„ç»¿è‰²ï¼ˆè¡¨å¤´ï¼‰
                    font_color = Font(color='1B5E20', bold=True)  # æ·±ç»¿è‰²æ–‡å­—
                    
                    # è®¾ç½®è¡¨å¤´æ ·å¼
                    for cell in ws[1]:
                        cell.fill = header_fill
                        cell.font = font_color
                        cell.alignment = Alignment(horizontal='center', vertical='center')
                    
                    # è®¾ç½®æ•°æ®è¡Œæ ·å¼ï¼ˆé™¤äº†è¡¨å¤´ï¼‰
                    for row in ws.iter_rows(min_row=2, max_row=ws.max_row):
                        for cell in row:
                            cell.fill = fill_color
                    
                    # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
                    for column in ws.columns:
                        max_length = 0
                        column_letter = column[0].column_letter
                        for cell in column:
                            try:
                                if cell.value:
                                    max_length = max(max_length, len(str(cell.value)))
                            except:
                                pass
                        adjusted_width = min(max_length + 2, 60)  # æœ€å¤§å®½åº¦60
                        ws.column_dimensions[column_letter].width = adjusted_width
                    
                    # ä¿å­˜æ–‡ä»¶
                    wb.save(filename)
                    print(f"\nâœ“ å·²æ·»åŠ é¢œè‰²æ ‡æ³¨ï¼ˆæµ…ç»¿è‰²èƒŒæ™¯ï¼‰")
                except Exception as e:
                    print(f"  âš  æ·»åŠ é¢œè‰²æ ‡æ³¨æ—¶å‡ºé”™: {str(e)}ï¼Œä½†æ–‡ä»¶å·²ä¿å­˜")
            
            print(f"\nâœ“ æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
            print(f"  å…± {len(df)} æ¡è®°å½•")
            print(f"\nåˆ—å: {', '.join(df.columns.tolist())}")
        except Exception as e:
            print(f"\nâš  ä¿å­˜Excelæ—¶å‡ºé”™: {str(e)}")
            # å°è¯•ä¿å­˜ä¸ºCSVä½œä¸ºå¤‡é€‰
            csv_filename = filename.replace('.xlsx', '.csv')
            df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
            print(f"  å·²ä¿å­˜ä¸ºCSVæ ¼å¼: {csv_filename}")
            
    async def run(self, overwrite: bool = False):
        """ä¸»è¿è¡Œå‡½æ•°
        
        Args:
            overwrite: æ˜¯å¦ä¸ºè¦†ç›–æ›´æ–°æ¨¡å¼ï¼ˆè¦†ç›–ç°æœ‰æ–‡ä»¶ï¼‰
        """
        try:
            # å¯åŠ¨æµè§ˆå™¨
            await self.start_browser()
            
            # è®¿é—®ç›®æ ‡URL
            await self.navigate_to_target()
            
            # ç‚¹å‡»"ç½‘ç”³æˆªæ­¢å€’è®¡æ—¶"æ ‡ç­¾
            await self.click_net_apply_tab()
            
            # ç­‰å¾…åˆ—è¡¨åŠ è½½
            await self.wait_for_list_loaded()
            
            # æŠ“å–æ‰€æœ‰é¡µé¢
            await self.scrape_all_pages()
            
            # ä¿å­˜æ•°æ®
            await self.save_to_excel(overwrite=overwrite)
            
            print(f"\n{'='*60}")
            print("æŠ“å–å®Œæˆï¼")
            print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"å…±æŠ“å– {len(self.results)} æ¡è®°å½•")
            print(f"{'='*60}\n")
            
        except Exception as e:
            print(f"\nâš  è¿è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
        finally:
            # å…³é—­æµè§ˆå™¨
            if self.browser:
                await self.browser.close()
            if self.playwright:
                await self.playwright.stop()
                
# ==================== ä¸»ç¨‹åºå…¥å£ ====================

import argparse

async def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='AceOfferæ ¡æ‹›ä¿¡æ¯æŠ“å–è„šæœ¬')
    parser.add_argument('--overwrite', action='store_true', help='è¦†ç›–ç°æœ‰æ–‡ä»¶ï¼Œä½¿ç”¨å›ºå®šæ–‡ä»¶å')
    args = parser.parse_args()
    
    scraper = AceOfferRecruitScraper()
    await scraper.run(overwrite=args.overwrite)

if __name__ == "__main__":
    asyncio.run(main())

