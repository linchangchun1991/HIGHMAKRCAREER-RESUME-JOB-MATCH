#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥å†…æ¨å²—ä½è‡ªåŠ¨æŠ“å–è„šæœ¬ v2.0
åŠŸèƒ½ï¼šè‡ªåŠ¨è®¿é—®ç‰›å®¢ç½‘ç­‰æ‹›è˜å¹³å°ï¼ŒæŠ“å–åŒ…å«"å†…æ¨ç "çš„å¸–å­ä¿¡æ¯ï¼Œå¹¶ä¿å­˜åˆ°Excelæ–‡ä»¶
"""

import time
import re
from datetime import datetime
from pathlib import Path
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException

class JobScraper:
    def __init__(self):
        """åˆå§‹åŒ–çˆ¬è™«é…ç½®"""
        self.chrome_options = Options()
        self.chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        self.chrome_options.add_experimental_option('excludeSwitches', ['enable-automation'])
        self.chrome_options.add_experimental_option('useAutomationExtension', False)
        self.chrome_options.add_argument('--window-size=1920,1080')
        
        self.driver = None
        self.job_data = []
        
    def init_driver(self):
        """åˆå§‹åŒ–æµè§ˆå™¨é©±åŠ¨"""
        try:
            self.driver = webdriver.Chrome(options=self.chrome_options)
            self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                'source': 'Object.defineProperty(navigator, "webdriver", {get: () => undefined})'
            })
            self.driver.implicitly_wait(10)
            print("âœ… Chromeæµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}")
            raise
    
    def scrape_nowcoder(self):
        """æŠ“å–ç‰›å®¢ç½‘å†…æ¨ä¿¡æ¯"""
        print("\nğŸ” å¼€å§‹æŠ“å–ç‰›å®¢ç½‘...")
        try:
            # è®¿é—®ç‰›å®¢ç½‘è®¨è®ºåŒº - ä½¿ç”¨æ›´ç›´æ¥çš„URL
            urls_to_try = [
                "https://www.nowcoder.com/search?query=å†…æ¨ç &type=discuss",
                "https://www.nowcoder.com/discuss/tag/2688",  # å†…æ¨æ ‡ç­¾
                "https://www.nowcoder.com/feed/main/tag/2688",
            ]
            
            for url in urls_to_try:
                print(f"  å°è¯•è®¿é—®: {url}")
                self.driver.get(url)
                time.sleep(3)
                
                # æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹
                for _ in range(3):
                    self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(1)
                
                # å°è¯•å¤šç§é€‰æ‹©å™¨
                selectors = [
                    "a[href*='/discuss/']",
                    ".discuss-item",
                    ".feed-item",
                    "[class*='discuss']",
                    "[class*='post']",
                    ".list-item",
                ]
                
                posts = []
                for selector in selectors:
                    try:
                        posts = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        if posts:
                            print(f"  ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(posts)} ä¸ªå…ƒç´ ")
                            break
                    except:
                        continue
                
                if posts:
                    # æå–æ‰€æœ‰é“¾æ¥
                    links = set()
                    for post in posts[:30]:
                        try:
                            href = post.get_attribute('href')
                            if href and '/discuss/' in href:
                                links.add(href)
                            # ä¹Ÿå°è¯•æ‰¾å­å…ƒç´ ä¸­çš„é“¾æ¥
                            inner_links = post.find_elements(By.TAG_NAME, 'a')
                            for link in inner_links:
                                href = link.get_attribute('href')
                                if href and '/discuss/' in href:
                                    links.add(href)
                        except:
                            continue
                    
                    print(f"  æå–åˆ° {len(links)} ä¸ªè®¨è®ºå¸–é“¾æ¥")
                    
                    # è®¿é—®æ¯ä¸ªå¸–å­
                    for idx, link in enumerate(list(links)[:15], 1):
                        try:
                            self._process_nowcoder_post(link, idx)
                        except Exception as e:
                            print(f"  âš ï¸ å¤„ç†å¸–å­å‡ºé”™: {e}")
                            continue
                    
                    if self.job_data:
                        break
            
            print(f"âœ… ç‰›å®¢ç½‘æŠ“å–å®Œæˆï¼Œå…±è·å– {len(self.job_data)} æ¡æœ‰æ•ˆå†…æ¨ä¿¡æ¯")
            
        except Exception as e:
            print(f"âŒ ç‰›å®¢ç½‘æŠ“å–å¤±è´¥: {e}")
    
    def _process_nowcoder_post(self, link, idx):
        """å¤„ç†å•ä¸ªç‰›å®¢å¸–å­"""
        self.driver.execute_script("window.open(arguments[0]);", link)
        self.driver.switch_to.window(self.driver.window_handles[-1])
        time.sleep(2)
        
        try:
            # è·å–é¡µé¢æ–‡æœ¬
            page_text = self.driver.find_element(By.TAG_NAME, 'body').text
            
            # è·å–æ ‡é¢˜
            title = ""
            title_selectors = ['h1', '.title', '[class*="title"]', '.post-title']
            for sel in title_selectors:
                try:
                    title = self.driver.find_element(By.CSS_SELECTOR, sel).text.strip()
                    if title:
                        break
                except:
                    continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å†…æ¨ç›¸å…³å…³é”®è¯
            keywords = ['å†…æ¨', 'æ¨èç ', 'é‚€è¯·ç ', 'ç›´æ¨', 'å†…éƒ¨æ¨è']
            if any(kw in page_text for kw in keywords):
                job_info = self._parse_job_info(title, page_text, link)
                if job_info:
                    self.job_data.append(job_info)
                    print(f"  âœ… [{idx}] {job_info['å…¬å¸åç§°']} - {job_info['å²—ä½/æ–¹å‘']}")
        finally:
            self.driver.close()
            self.driver.switch_to.window(self.driver.window_handles[0])
    
    def scrape_juejin(self):
        """æŠ“å–ç¨€åœŸæ˜é‡‘å†…æ¨ä¿¡æ¯"""
        print("\nğŸ” å¼€å§‹æŠ“å–ç¨€åœŸæ˜é‡‘...")
        try:
            url = "https://juejin.cn/search?query=å†…æ¨ç &type=0"
            self.driver.get(url)
            time.sleep(3)
            
            # æ»šåŠ¨åŠ è½½
            for _ in range(2):
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1)
            
            # æŸ¥æ‰¾æ–‡ç« é“¾æ¥
            articles = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='/post/']")
            links = set()
            for article in articles:
                href = article.get_attribute('href')
                if href and '/post/' in href:
                    links.add(href)
            
            print(f"  æ‰¾åˆ° {len(links)} ç¯‡ç›¸å…³æ–‡ç« ")
            
            for idx, link in enumerate(list(links)[:10], 1):
                try:
                    self.driver.execute_script("window.open(arguments[0]);", link)
                    self.driver.switch_to.window(self.driver.window_handles[-1])
                    time.sleep(2)
                    
                    title = ""
                    try:
                        title = self.driver.find_element(By.CSS_SELECTOR, 'h1').text.strip()
                    except:
                        pass
                    
                    content = self.driver.find_element(By.TAG_NAME, 'body').text
                    
                    if 'å†…æ¨' in content or 'æ¨èç ' in content:
                        job_info = self._parse_job_info(title, content, link)
                        if job_info:
                            self.job_data.append(job_info)
                            print(f"  âœ… [{idx}] {job_info['å…¬å¸åç§°']} - {job_info['å²—ä½/æ–¹å‘']}")
                    
                    self.driver.close()
                    self.driver.switch_to.window(self.driver.window_handles[0])
                except Exception as e:
                    if len(self.driver.window_handles) > 1:
                        self.driver.close()
                        self.driver.switch_to.window(self.driver.window_handles[0])
                    continue
            
            print(f"âœ… ç¨€åœŸæ˜é‡‘æŠ“å–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ ç¨€åœŸæ˜é‡‘æŠ“å–å¤±è´¥: {e}")
    
    def _parse_job_info(self, title, content, link):
        """è§£æå¸–å­å†…å®¹ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯"""
        full_text = title + " " + content
        
        # æå–å…¬å¸åç§°
        companies = {
            'å­—èŠ‚': 'å­—èŠ‚è·³åŠ¨', 'æŠ–éŸ³': 'å­—èŠ‚è·³åŠ¨', 'ByteDance': 'å­—èŠ‚è·³åŠ¨',
            'è…¾è®¯': 'è…¾è®¯', 'Tencent': 'è…¾è®¯', 'å¾®ä¿¡': 'è…¾è®¯',
            'é˜¿é‡Œ': 'é˜¿é‡Œå·´å·´', 'Alibaba': 'é˜¿é‡Œå·´å·´', 'æ·˜å®': 'é˜¿é‡Œå·´å·´', 'èš‚èš': 'èš‚èšé›†å›¢',
            'ç™¾åº¦': 'ç™¾åº¦', 'Baidu': 'ç™¾åº¦',
            'ç¾å›¢': 'ç¾å›¢', 'äº¬ä¸œ': 'äº¬ä¸œ', 'JD': 'äº¬ä¸œ',
            'ç½‘æ˜“': 'ç½‘æ˜“', 'åä¸º': 'åä¸º', 'Huawei': 'åä¸º',
            'å°ç±³': 'å°ç±³', 'Xiaomi': 'å°ç±³',
            'æ‹¼å¤šå¤š': 'æ‹¼å¤šå¤š', 'å¿«æ‰‹': 'å¿«æ‰‹', 'æ»´æ»´': 'æ»´æ»´',
            'å°çº¢ä¹¦': 'å°çº¢ä¹¦', 'Bç«™': 'bilibili', 'å“”å“©å“”å“©': 'bilibili',
            'æºç¨‹': 'æºç¨‹', 'å»å“ªå„¿': 'å»å“ªå„¿', 'é¥¿äº†ä¹ˆ': 'é¥¿äº†ä¹ˆ',
            'å¾®è½¯': 'å¾®è½¯', 'Microsoft': 'å¾®è½¯', 'Google': 'è°·æ­Œ', 'è°·æ­Œ': 'è°·æ­Œ',
            'Apple': 'è‹¹æœ', 'è‹¹æœ': 'è‹¹æœ', 'Amazon': 'äºšé©¬é€Š', 'äºšé©¬é€Š': 'äºšé©¬é€Š',
            'OPPO': 'OPPO', 'vivo': 'vivo', 'è£è€€': 'è£è€€',
            'æ‹›é“¶': 'æ‹›é“¶ç½‘ç»œ', 'å¹³å®‰': 'å¹³å®‰ç§‘æŠ€', 'ä¸­ä¿¡': 'ä¸­ä¿¡é“¶è¡Œ',
        }
        company = "å…¶ä»–å…¬å¸"
        for key, value in companies.items():
            if key in full_text:
                company = value
                break
        
        # æå–å²—ä½æ–¹å‘
        positions = {
            'å‰ç«¯': 'å‰ç«¯å¼€å‘', 'Frontend': 'å‰ç«¯å¼€å‘', 'Web': 'å‰ç«¯å¼€å‘',
            'åç«¯': 'åç«¯å¼€å‘', 'Backend': 'åç«¯å¼€å‘', 'æœåŠ¡ç«¯': 'åç«¯å¼€å‘',
            'Java': 'Javaå¼€å‘', 'Python': 'Pythonå¼€å‘', 'Go': 'Goå¼€å‘', 'Golang': 'Goå¼€å‘',
            'C++': 'C++å¼€å‘', 'C#': 'C#å¼€å‘',
            'ç®—æ³•': 'ç®—æ³•å·¥ç¨‹å¸ˆ', 'AI': 'AIç®—æ³•', 'æœºå™¨å­¦ä¹ ': 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ': 'æ·±åº¦å­¦ä¹ ',
            'æ•°æ®': 'æ•°æ®å¼€å‘', 'å¤§æ•°æ®': 'å¤§æ•°æ®å¼€å‘', 'æ•°æ®åˆ†æ': 'æ•°æ®åˆ†æ',
            'æµ‹è¯•': 'æµ‹è¯•å¼€å‘', 'QA': 'æµ‹è¯•å¼€å‘', 'æµ‹å¼€': 'æµ‹è¯•å¼€å‘',
            'äº§å“': 'äº§å“ç»ç†', 'PM': 'äº§å“ç»ç†',
            'è¿è¥': 'è¿è¥', 'å¸‚åœº': 'å¸‚åœºè¥é”€',
            'Android': 'Androidå¼€å‘', 'iOS': 'iOSå¼€å‘', 'å®¢æˆ·ç«¯': 'å®¢æˆ·ç«¯å¼€å‘',
            'è¿ç»´': 'è¿ç»´å·¥ç¨‹å¸ˆ', 'DevOps': 'DevOps', 'SRE': 'SRE',
            'å®‰å…¨': 'å®‰å…¨å·¥ç¨‹å¸ˆ',
        }
        position = "ç»¼åˆå²—ä½"
        for key, value in positions.items():
            if key in full_text:
                position = value
                break
        
        # æå–æ‹›è˜ç±»å‹
        if 'å®ä¹ ' in full_text:
            job_type = 'å®ä¹ '
        elif any(kw in full_text for kw in ['æ ¡æ‹›', '2025', '2026', 'åº”å±Š', 'æ¯•ä¸š']):
            job_type = 'æ ¡æ‹›'
        elif 'ç¤¾æ‹›' in full_text:
            job_type = 'ç¤¾æ‹›'
        else:
            job_type = 'æ ¡æ‹›/ç¤¾æ‹›'
        
        # æå–å†…æ¨ç 
        referral_code = ""
        code_patterns = [
            r'å†…æ¨ç [ï¼š:\s]*([A-Za-z0-9]{4,20})',
            r'æ¨èç [ï¼š:\s]*([A-Za-z0-9]{4,20})',
            r'é‚€è¯·ç [ï¼š:\s]*([A-Za-z0-9]{4,20})',
            r'[Cc]ode[ï¼š:\s]*([A-Za-z0-9]{4,20})',
            r'ç [ï¼š:\s]*([A-Za-z0-9]{6,20})',
        ]
        for pattern in code_patterns:
            match = re.search(pattern, full_text)
            if match:
                referral_code = match.group(1)
                break
        
        # æå–é‚®ç®±
        email = ""
        email_match = re.search(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', full_text)
        if email_match:
            email = email_match.group(0)
        
        # æå–æŠ•é€’é“¾æ¥
        apply_link = ""
        link_patterns = [
            r'(https?://[^\s]*(?:job|career|recruit|campus|zhaopin)[^\s]*)',
        ]
        for pattern in link_patterns:
            match = re.search(pattern, full_text)
            if match:
                apply_link = match.group(1)
                break
        
        # æå–æˆªæ­¢æ—¶é—´
        deadline = ""
        deadline_patterns = [
            r'æˆªæ­¢[ï¼š:åˆ°è‡³]?\s*(\d{4}[-/å¹´]\d{1,2}[-/æœˆ]\d{1,2}æ—¥?)',
            r'(\d{1,2}æœˆ\d{1,2}æ—¥?)\s*æˆªæ­¢',
            r'deadline[ï¼š:\s]*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
        ]
        for pattern in deadline_patterns:
            match = re.search(pattern, full_text, re.IGNORECASE)
            if match:
                deadline = match.group(1)
                break
        
        # ç»„åˆå†…æ¨æ–¹å¼
        referral_method = referral_code or email or "è¯¦è§åŸå¸–"
        
        # åªæœ‰åŒ…å«å®è´¨å†…æ¨ä¿¡æ¯æ‰è¿”å›
        if referral_code or email or 'å†…æ¨' in title:
            return {
                'å…¬å¸åç§°': company,
                'å²—ä½/æ–¹å‘': position,
                'æ‹›è˜ç±»å‹': job_type,
                'å†…æ¨ç /ç›´æ¨é‚®ç®±': referral_method,
                'æŠ•é€’é“¾æ¥/æ¥æº': apply_link if apply_link else link,
                'å¤‡æ³¨': deadline if deadline else 'è¯¦è§åŸå¸–'
            }
        return None
    
    def save_to_excel(self, output_path):
        """ä¿å­˜æ•°æ®åˆ°Excelæ–‡ä»¶"""
        if not self.job_data:
            print("\nâš ï¸ æ²¡æœ‰æŠ“å–åˆ°æœ‰æ•ˆæ•°æ®ï¼Œå°†åˆ›å»ºç¤ºä¾‹æ¨¡æ¿...")
            # åˆ›å»ºç¤ºä¾‹æ•°æ®
            self.job_data = [
                {
                    'å…¬å¸åç§°': 'ç¤ºä¾‹-å­—èŠ‚è·³åŠ¨',
                    'å²—ä½/æ–¹å‘': 'åç«¯å¼€å‘',
                    'æ‹›è˜ç±»å‹': 'æ ¡æ‹›',
                    'å†…æ¨ç /ç›´æ¨é‚®ç®±': 'ABCD1234',
                    'æŠ•é€’é“¾æ¥/æ¥æº': 'https://jobs.bytedance.com',
                    'å¤‡æ³¨': 'è¿™æ˜¯ç¤ºä¾‹æ•°æ®ï¼Œè¯·æ‰‹åŠ¨æ›´æ–°'
                }
            ]
        
        try:
            df = pd.DataFrame(self.job_data)
            
            # å»é‡
            df = df.drop_duplicates(subset=['å…¬å¸åç§°', 'å²—ä½/æ–¹å‘', 'å†…æ¨ç /ç›´æ¨é‚®ç®±'])
            
            df.to_excel(output_path, index=False, engine='openpyxl')
            print(f"\nâœ… æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
            print(f"ğŸ“Š å…±ä¿å­˜ {len(df)} æ¡å†…æ¨ä¿¡æ¯")
            
            # è¾“å‡ºTop 3æ¡æ¼æœºä¼š
            print("\n" + "="*50)
            print("ğŸ”¥ ä»Šæ—¥Top 3æ¡æ¼æœºä¼šï¼š")
            print("="*50)
            for i, (_, job) in enumerate(df.head(3).iterrows(), 1):
                print(f"\n{i}. ã€{job['å…¬å¸åç§°']}ã€‘{job['å²—ä½/æ–¹å‘']} ({job['æ‹›è˜ç±»å‹']})")
                print(f"   ğŸ“ å†…æ¨æ–¹å¼: {job['å†…æ¨ç /ç›´æ¨é‚®ç®±']}")
                print(f"   ğŸ”— é“¾æ¥: {job['æŠ•é€’é“¾æ¥/æ¥æº']}")
                if job['å¤‡æ³¨'] != 'è¯¦è§åŸå¸–':
                    print(f"   â° æˆªæ­¢: {job['å¤‡æ³¨']}")
        
        except Exception as e:
            print(f"âŒ ä¿å­˜Excelå¤±è´¥: {e}")
    
    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.driver:
            self.driver.quit()
            print("\nğŸ”’ æµè§ˆå™¨å·²å…³é—­")

def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸ¤– æµ·é©¬èŒåŠ  - æ¯æ—¥å†…æ¨å²—ä½è‡ªåŠ¨æŠ“å–ç³»ç»Ÿ v2.0")
    print(f"ğŸ“… æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    # è®¾ç½®è¾“å‡ºè·¯å¾„ä¸ºæ¡Œé¢
    desktop_path = Path.home() / "Desktop" / "æ¯æ—¥å†…æ¨.xlsx"
    
    scraper = JobScraper()
    
    try:
        scraper.init_driver()
        
        # æŠ“å–å¤šä¸ªå¹³å°
        scraper.scrape_nowcoder()
        scraper.scrape_juejin()
        
        # ä¿å­˜åˆ°Excel
        scraper.save_to_excel(desktop_path)
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
    finally:
        scraper.close()
    
    print("\n" + "="*60)
    print("âœ… ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼")
    print("="*60)

if __name__ == "__main__":
    main()
