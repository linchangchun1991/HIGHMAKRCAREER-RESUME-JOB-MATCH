#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥å†…æ¨ä¿¡æ¯è‡ªåŠ¨æŠ“å–ä¸æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ v2.0
åŠŸèƒ½ï¼š
1. è‡ªåŠ¨æŠ“å–ç‰›å®¢ç½‘ã€çŸ¥ä¹ç­‰å¹³å°çš„æœ€æ–°å†…æ¨ä¿¡æ¯
2. ç”ŸæˆMarkdownæ ¼å¼çš„æ—¥æŠ¥
3. æ›´æ–°Excelæ±‡æ€»è¡¨
4. æå–Top 3æ¡æ¼æœºä¼š
"""

import time
import re
from datetime import datetime, timedelta
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import os
from openpyxl import load_workbook
from openpyxl.styles import Font, PatternFill, Alignment

class EnhancedReferralScraper:
    def __init__(self):
        """åˆå§‹åŒ–çˆ¬è™«"""
        self.chrome_options = Options()
        user_data_dir = os.path.expanduser('~/Library/Application Support/Google/Chrome')
        self.chrome_options.add_argument(f'--user-data-dir={user_data_dir}')
        self.chrome_options.add_argument('--profile-directory=Default')
        self.chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        self.chrome_options.add_experimental_option('excludeSwitches', ['enable-automation'])
        self.chrome_options.add_experimental_option('useAutomationExtension', False)
        
        self.driver = None
        self.results = []
        self.today = datetime.now().strftime('%Y-%m-%d')
        
        # é‡ç‚¹å…¬å¸åˆ—è¡¨
        self.key_companies = [
            'å­—èŠ‚è·³åŠ¨', 'è…¾è®¯', 'é˜¿é‡Œå·´å·´', 'é˜¿é‡Œ', 'ç™¾åº¦', 'ç¾å›¢', 'äº¬ä¸œ',
            'æ‹¼å¤šå¤š', 'å°ç±³', 'åä¸º', 'ç½‘æ˜“', 'æ»´æ»´', 'å¿«æ‰‹', 'Bç«™', 'bilibili',
            'å°çº¢ä¹¦', 'è”šæ¥', 'ç†æƒ³', 'æ¯”äºšè¿ª', 'å¤§ç–†', 'æµ·åº·å¨è§†', 'ç§‘å¤§è®¯é£',
            'ç±³å“ˆæ¸¸', 'åŸºæ©å£«', 'æ–½è€å¾·', 'åšä¸–', 'OPPO', 'vivo', 'è£è€€'
        ]
        
    def start_driver(self):
        """å¯åŠ¨æµè§ˆå™¨"""
        print("\n" + "="*60)
        print("æ¯æ—¥å†…æ¨ä¿¡æ¯è‡ªåŠ¨æŠ“å–ç³»ç»Ÿ v2.0")
        print("="*60)
        print(f"\nå¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("æ­£åœ¨å¯åŠ¨Chromeæµè§ˆå™¨...")
        
        try:
            self.driver = webdriver.Chrome(options=self.chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            print("âœ“ æµè§ˆå™¨å¯åŠ¨æˆåŠŸï¼")
        except Exception as e:
            print(f"âœ— æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {str(e)}")
            print("\nè¯·ç¡®ä¿ï¼š")
            print("1. å·²å®‰è£…Chromeæµè§ˆå™¨")
            print("2. å·²å®‰è£…ChromeDriver (brew install chromedriver)")
            raise
    
    def scrape_nowcoder(self, keywords=['å†…æ¨ç ', '2026æ ¡æ‹›', 'å†…æ¨', 'æ€¥æ‹›']):
        """æŠ“å–ç‰›å®¢ç½‘å†…æ¨ä¿¡æ¯"""
        print("\n" + "-"*60)
        print("[1/3] æ­£åœ¨æŠ“å–ç‰›å®¢ç½‘...")
        print("-"*60)
        
        base_urls = [
            "https://www.nowcoder.com/discuss/experience",
            "https://www.nowcoder.com/discuss/tag/639",  # å†…æ¨æ ‡ç­¾
        ]
        
        try:
            for keyword in keywords:
                try:
                    search_url = f"https://www.nowcoder.com/search?query={keyword}&type=discuss"
                    print(f"\næœç´¢å…³é”®è¯: {keyword}")
                    self.driver.get(search_url)
                    time.sleep(3)
                    
                    # è·å–å¸–å­åˆ—è¡¨
                    posts = self.driver.find_elements(By.CSS_SELECTOR, '.discuss-item, .feed-item, .post-item')
                    print(f"æ‰¾åˆ° {len(posts)} ä¸ªå¸–å­")
                    
                    count = 0
                    for post in posts[:15]:  # å–å‰15æ¡
                        try:
                            # æå–æ ‡é¢˜å’Œé“¾æ¥
                            title_elem = post.find_element(By.CSS_SELECTOR, 'a.discuss-title, a.feed-title, .title a')
                            title = title_elem.text.strip()
                            link = title_elem.get_attribute('href')
                            
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«å†…æ¨ç›¸å…³å…³é”®è¯
                            if not any(kw in title for kw in ['å†…æ¨', 'æ ¡æ‹›', 'æ‹›è˜']):
                                continue
                            
                            # æå–å‘å¸ƒæ—¶é—´
                            try:
                                time_elem = post.find_element(By.CSS_SELECTOR, '.time, .post-time, .feed-time')
                                post_time = time_elem.text
                            except:
                                post_time = "æœªçŸ¥"
                            
                            # æ£€æŸ¥æ˜¯å¦ä¸ºè¿‘æœŸå‘å¸ƒï¼ˆç®€å•åˆ¤æ–­ï¼‰
                            if self.is_recent(post_time):
                                company = self.extract_company_name(title)
                                referral_code = self.extract_referral_code(title)
                                
                                self.results.append({
                                    'å…¬å¸åç§°': company,
                                    'å²—ä½/æ–¹å‘': 'æ ¡æ‹›',
                                    'æ‹›è˜ç±»å‹': 'æ ¡æ‹›',
                                    'å†…æ¨ç /ç›´æ¨é‚®ç®±': referral_code,
                                    'æŠ•é€’é“¾æ¥/æ¥æº': link,
                                    'å¤‡æ³¨': f"å‘å¸ƒæ—¶é—´: {post_time}",
                                    'æ¥æºå¹³å°': 'ç‰›å®¢ç½‘',
                                    'æŠ“å–æ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                                    'æ ‡é¢˜': title
                                })
                                count += 1
                                print(f"  âœ“ [{count}] {company} - {referral_code}")
                        except Exception as e:
                            continue
                    
                    print(f"æœ¬æ¬¡æœç´¢å…±æŠ“å– {count} æ¡æœ‰æ•ˆä¿¡æ¯")
                    time.sleep(2)
                    
                except Exception as e:
                    print(f"  âœ— æœç´¢å…³é”®è¯ '{keyword}' æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            print(f"\nç‰›å®¢ç½‘æŠ“å–å®Œæˆï¼Œå…±è·å– {len(self.results)} æ¡ä¿¡æ¯")
                    
        except Exception as e:
            print(f"\nâœ— æŠ“å–ç‰›å®¢ç½‘æ—¶å‡ºé”™: {str(e)}")
    
    def is_recent(self, time_str):
        """åˆ¤æ–­æ˜¯å¦ä¸ºè¿‘æœŸå‘å¸ƒï¼ˆç®€å•åˆ¤æ–­ï¼‰"""
        recent_keywords = ['ä»Šå¤©', 'å°æ—¶', 'åˆ†é’Ÿ', 'åˆšåˆš', 'æ˜¨å¤©', '1å¤©å‰', '2å¤©å‰']
        return any(kw in time_str for kw in recent_keywords)
    
    def extract_referral_code(self, text):
        """ä»æ–‡æœ¬ä¸­æå–å†…æ¨ç """
        patterns = [
            r'å†…æ¨ç [ï¼š:](\w+)',
            r'æ¨èç [ï¼š:](\w+)',
            r'å†…æ¨[ï¼š:]\s*(\w+)',
            r'ç [ï¼š:](\w+)',
            r'\b[A-Z0-9]{6,10}\b',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                code = match.group(1) if match.lastindex else match.group(0)
                # è¿‡æ»¤æ‰ä¸€äº›å¸¸è§çš„éå†…æ¨ç 
                if code not in ['JAVA', 'PYTHON', 'HTTP', 'HTTPS']:
                    return code
        
        return "è§åŸæ–‡"
    
    def extract_company_name(self, text):
        """ä»æ–‡æœ¬ä¸­æå–å…¬å¸åç§°"""
        for company in self.key_companies:
            if company in text:
                return company
        return "å…¶ä»–å…¬å¸"
    
    def generate_markdown_report(self, filename=None):
        """ç”ŸæˆMarkdownæ ¼å¼çš„æ—¥æŠ¥"""
        if not self.results:
            print("\næ²¡æœ‰æ•°æ®å¯ç”ŸæˆæŠ¥å‘Šï¼")
            return
        
        if filename is None:
            filename = f"ä»Šæ—¥å†…æ¨æ±‡æ€»_{self.today}.md"
        
        desktop_path = os.path.expanduser('~/Desktop')
        file_path = os.path.join(desktop_path, filename)
        
        # æ•°æ®å¤„ç†
        df = pd.DataFrame(self.results)
        df = df.drop_duplicates(subset=['å…¬å¸åç§°', 'å†…æ¨ç /ç›´æ¨é‚®ç®±'])
        
        # æŒ‰å…¬å¸é‡è¦æ€§æ’åº
        def company_priority(company):
            if company in self.key_companies[:10]:  # å‰10å®¶é‡ç‚¹å…¬å¸
                return 0
            elif company in self.key_companies:
                return 1
            else:
                return 2
        
        df['priority'] = df['å…¬å¸åç§°'].apply(company_priority)
        df = df.sort_values('priority')
        
        # ç”ŸæˆMarkdownå†…å®¹
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"# ä»Šæ—¥æœ€æ–°å†…æ¨/ç›´æ¨å²—ä½æ±‡æ€»è¡¨\n\n")
            f.write(f"**æ›´æ–°æ—¥æœŸ**: {self.today}  \n")
            f.write(f"**æ•°æ®æ¥æº**: ç‰›å®¢ç½‘ç­‰å¹³å°  \n")
            f.write(f"**æŠ“å–æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n")
            f.write(f"**æœ‰æ•ˆä¿¡æ¯**: {len(df)} æ¡\n\n")
            f.write("---\n\n")
            
            # è¡¨æ ¼
            f.write("## ğŸ“Š å†…æ¨ä¿¡æ¯æ±‡æ€»\n\n")
            f.write("| å…¬å¸åç§° | å²—ä½/æ–¹å‘ | æ‹›è˜ç±»å‹ | å†…æ¨ç /ç›´æ¨é‚®ç®± | æŠ•é€’é“¾æ¥/æ¥æº | å¤‡æ³¨ |\n")
            f.write("|---------|----------|---------|----------------|--------------|------|\n")
            
            for _, row in df.iterrows():
                f.write(f"| {row['å…¬å¸åç§°']} | {row['å²—ä½/æ–¹å‘']} | {row['æ‹›è˜ç±»å‹']} | ")
                f.write(f"{row['å†…æ¨ç /ç›´æ¨é‚®ç®±']} | {row['æŠ•é€’é“¾æ¥/æ¥æº']} | {row['å¤‡æ³¨']} |\n")
            
            # Top 3æ¡æ¼æœºä¼š
            f.write("\n---\n\n")
            f.write("## ğŸ”¥ ä»Šæ—¥Top 3æ¡æ¼æœºä¼š\n\n")
            
            top_opportunities = self.identify_top_opportunities(df)
            for i, opp in enumerate(top_opportunities, 1):
                f.write(f"### {i}. {opp['emoji']} {opp['company']}\n\n")
                f.write(f"**äº®ç‚¹**: {opp['highlight']}  \n")
                f.write(f"**å†…æ¨ç **: {opp['code']}  \n")
                f.write(f"**æŠ•é€’é“¾æ¥**: {opp['link']}  \n")
                f.write(f"**å¤‡æ³¨**: {opp['note']}\n\n")
                f.write("---\n\n")
            
            # ä½¿ç”¨å»ºè®®
            f.write("## ğŸ“ ä½¿ç”¨å»ºè®®\n\n")
            f.write("1. **å°½æ—©æŠ•é€’**: å¤§éƒ¨åˆ†å…¬å¸é‡‡ç”¨å…ˆåˆ°å…ˆå¾—åŸåˆ™\n")
            f.write("2. **å¤šå¹³å°å°è¯•**: ä¸è¦åªä¾èµ–ä¸€ä¸ªå†…æ¨ç \n")
            f.write("3. **ç®€å†ä¼˜åŒ–**: ä½¿ç”¨å†…æ¨ç å‰å…ˆä¼˜åŒ–ç®€å†\n")
            f.write("4. **å…³æ³¨æ—¶æ•ˆ**: éƒ¨åˆ†å†…æ¨ç æœ‰ä½¿ç”¨æœŸé™\n")
            f.write("5. **è·Ÿè¿›è¿›åº¦**: æŠ•é€’åä¸»åŠ¨æŸ¥è¯¢è¿›åº¦\n\n")
            
            f.write("---\n\n")
            f.write("**å…è´£å£°æ˜**: æœ¬æ±‡æ€»è¡¨ä»…ä¾›å‚è€ƒï¼Œæ‰€æœ‰ä¿¡æ¯æ¥æºäºå…¬å¼€æ¸ é“ã€‚\n\n")
            f.write("**ç¥å„ä½æ±‚èŒé¡ºåˆ©ï¼Œæ—©æ—¥æ‹¿åˆ°å¿ƒä»ªçš„Offerï¼** ğŸ‰\n")
        
        print(f"\nâœ“ MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {file_path}")
        return file_path
    
    def identify_top_opportunities(self, df):
        """è¯†åˆ«Top 3æ¡æ¼æœºä¼š"""
        opportunities = []
        
        # ä¼˜å…ˆé€‰æ‹©é‡ç‚¹å…¬å¸
        for company in self.key_companies[:10]:
            company_data = df[df['å…¬å¸åç§°'] == company]
            if not company_data.empty:
                row = company_data.iloc[0]
                opportunities.append({
                    'emoji': 'ğŸŒŸ',
                    'company': company,
                    'highlight': 'å¤§å‚æœºä¼šï¼Œç®€å†ä¼˜å…ˆç­›é€‰',
                    'code': row['å†…æ¨ç /ç›´æ¨é‚®ç®±'],
                    'link': row['æŠ•é€’é“¾æ¥/æ¥æº'],
                    'note': row['å¤‡æ³¨']
                })
                if len(opportunities) >= 3:
                    break
        
        # å¦‚æœä¸è¶³3ä¸ªï¼Œè¡¥å……å…¶ä»–å…¬å¸
        while len(opportunities) < 3 and len(opportunities) < len(df):
            remaining = df[~df['å…¬å¸åç§°'].isin([o['company'] for o in opportunities])]
            if not remaining.empty:
                row = remaining.iloc[0]
                opportunities.append({
                    'emoji': 'ğŸ’¡',
                    'company': row['å…¬å¸åç§°'],
                    'highlight': 'æ–°æœºä¼šï¼Œç«äº‰è¾ƒå°',
                    'code': row['å†…æ¨ç /ç›´æ¨é‚®ç®±'],
                    'link': row['æŠ•é€’é“¾æ¥/æ¥æº'],
                    'note': row['å¤‡æ³¨']
                })
            else:
                break
        
        return opportunities
    
    def update_excel(self, filename='æ¯æ—¥å†…æ¨.xlsx'):
        """æ›´æ–°Excelæ±‡æ€»è¡¨"""
        if not self.results:
            print("\næ²¡æœ‰æ•°æ®å¯æ›´æ–°Excelï¼")
            return
        
        desktop_path = os.path.expanduser('~/Desktop')
        file_path = os.path.join(desktop_path, filename)
        
        # æ•°æ®å¤„ç†
        df = pd.DataFrame(self.results)
        df = df.drop_duplicates(subset=['å…¬å¸åç§°', 'å†…æ¨ç /ç›´æ¨é‚®ç®±'])
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè¿½åŠ æ•°æ®
        if os.path.exists(file_path):
            try:
                existing_df = pd.read_excel(file_path)
                df = pd.concat([existing_df, df], ignore_index=True)
                df = df.drop_duplicates(subset=['å…¬å¸åç§°', 'å†…æ¨ç /ç›´æ¨é‚®ç®±'], keep='last')
                print(f"\nâœ“ å·²åˆå¹¶ç°æœ‰æ•°æ®")
            except Exception as e:
                print(f"\nâš  è¯»å–ç°æœ‰Excelå¤±è´¥ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶: {str(e)}")
        
        # ä¿å­˜åˆ°Excel
        try:
            with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='å†…æ¨æ±‡æ€»', index=False)
            
            # æ ¼å¼åŒ–Excel
            self.format_excel(file_path)
            
            print(f"âœ“ Excelå·²æ›´æ–°: {file_path}")
            print(f"âœ“ å…± {len(df)} æ¡è®°å½•")
            
        except Exception as e:
            print(f"\nâœ— æ›´æ–°Excelå¤±è´¥: {str(e)}")
    
    def format_excel(self, file_path):
        """æ ¼å¼åŒ–Excelè¡¨æ ¼"""
        try:
            wb = load_workbook(file_path)
            ws = wb.active
            
            # è®¾ç½®è¡¨å¤´æ ·å¼
            header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
            header_font = Font(bold=True, color="FFFFFF")
            
            for cell in ws[1]:
                cell.fill = header_fill
                cell.font = header_font
                cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # è°ƒæ•´åˆ—å®½
            ws.column_dimensions['A'].width = 15
            ws.column_dimensions['B'].width = 20
            ws.column_dimensions['C'].width = 12
            ws.column_dimensions['D'].width = 20
            ws.column_dimensions['E'].width = 40
            ws.column_dimensions['F'].width = 30
            ws.column_dimensions['G'].width = 12
            ws.column_dimensions['H'].width = 20
            
            wb.save(file_path)
            print("âœ“ Excelæ ¼å¼åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âš  Excelæ ¼å¼åŒ–å¤±è´¥: {str(e)}")
    
    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.driver:
            self.driver.quit()
            print("\nâœ“ æµè§ˆå™¨å·²å…³é—­")

def main():
    """ä¸»å‡½æ•°"""
    scraper = EnhancedReferralScraper()
    
    try:
        # å¯åŠ¨æµè§ˆå™¨
        scraper.start_driver()
        
        # æŠ“å–ç‰›å®¢ç½‘
        scraper.scrape_nowcoder()
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        scraper.generate_markdown_report()
        
        # æ›´æ–°Excel
        scraper.update_excel()
        
        print("\n" + "="*60)
        print("ä»»åŠ¡å®Œæˆï¼")
        print("="*60)
        print(f"\nç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"\nç”Ÿæˆæ–‡ä»¶ï¼š")
        print(f"  1. ä»Šæ—¥å†…æ¨æ±‡æ€»_{scraper.today}.md (MarkdownæŠ¥å‘Š)")
        print(f"  2. æ¯æ—¥å†…æ¨.xlsx (Excelæ±‡æ€»è¡¨)")
        print(f"\næ–‡ä»¶ä½ç½®: ~/Desktop/")
        
    except KeyboardInterrupt:
        print("\n\nâš  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\n\nâœ— ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        # å…³é—­æµè§ˆå™¨
        scraper.close()

if __name__ == "__main__":
    main()
