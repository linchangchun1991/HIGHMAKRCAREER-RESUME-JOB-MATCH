#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ·é©¬èŒåŠ Â·å¸‚åœºé›·è¾¾æ—¥æŠ¥
åŸºäº DrissionPage çš„è‡ªåŠ¨åŒ–æƒ…æŠ¥ç³»ç»Ÿ
æ”¯æŒï¼šæŠ–éŸ³ã€å°çº¢ä¹¦ã€å¾®ä¿¡å…¬ä¼—å·
"""

import json
import time
import re
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from DrissionPage import ChromiumPage, ChromiumOptions
from openai import OpenAI
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('market_spy_pro.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==================== ç¡¬ç¼–ç é…ç½® ====================
# é˜¿é‡Œåƒé—®ï¼ˆé€šä¹‰åƒé—®ï¼‰API é…ç½®
QWEN_API_KEY = "sk-668c28bae516493d9ea8a3662118ec98"
# å°è¯•å¤šä¸ªå¯èƒ½çš„ endpoint
QWEN_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"  # å›½å†…ç‰ˆ
# QWEN_BASE_URL = "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"  # å›½é™…ç‰ˆ
QWEN_MODEL = "qwen-plus"  # æˆ–ä½¿ç”¨ "qwen-turbo" æ›´å¿«ä½†è´¨é‡ç¨ä½

# ç«å“å…³é”®è¯åˆ—è¡¨ï¼ˆæ‰©å±•ç‰ˆï¼‰
COMPETITOR_KEYWORDS = [
    'DBCèŒæ¢¦', 
    'é€”é¸½æ±‚èŒ', 
    'Offerå…ˆç”Ÿ', 
    'çˆ±æ€ç›Š', 
    'ç•™å­¦ç”Ÿæ±‚èŒ',
    'ç•™å­¦ç”Ÿå®ä¹ ',
    'è‹±å›½ç•™å­¦ç”Ÿå®ä¹ ',
    'ç¾å›½ç•™å­¦ç”Ÿå®ä¹ ',
    'æ¾³æ´²ç•™å­¦ç”Ÿå®ä¹ ',
    'ç¾å›½ç•™å­¦ç”Ÿæ±‚èŒ',
    'è‹±å›½ç•™å­¦ç”Ÿæ±‚èŒ',
    'æ¾³æ´²ç•™å­¦ç”Ÿæ±‚èŒ'
]

# è´Ÿé¢å…³é”®è¯ï¼ˆç”¨äºç­›é€‰é«˜ä»·å€¼å†…å®¹ï¼‰
NEGATIVE_KEYWORDS = ['é¿é›·', 'å‘', 'é€€è´¹', 'éª—å±€', 'æŠ•è¯‰', 'å·®è¯„', 'åƒåœ¾', 'ä¸è¦', 'åƒä¸‡åˆ«', 'åµæ¶']

# æ—¶é—´èŒƒå›´ï¼ˆæœ€è¿‘3å¤©ï¼‰
DAYS_BACK = 3
CURRENT_DATE = datetime.now().strftime("%Y-%m-%d")


class MarketSpyPro:
    """å¸‚åœºé›·è¾¾ä¸“ä¸šç‰ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµè§ˆå™¨å’Œ AI å®¢æˆ·ç«¯"""
        # é…ç½®é˜¿é‡Œåƒé—®ï¼ˆé€šä¹‰åƒé—®ï¼‰
        self.ai_client = OpenAI(
            api_key=QWEN_API_KEY,
            base_url=QWEN_BASE_URL
        )
        logger.info("é˜¿é‡Œåƒé—®ï¼ˆé€šä¹‰åƒé—®ï¼‰åˆå§‹åŒ–æˆåŠŸ")
        
        # é…ç½®æµè§ˆå™¨
        options = ChromiumOptions()
        options.headless(False)  # æ˜¾ç¤ºæµè§ˆå™¨çª—å£
        options.set_argument('--disable-blink-features=AutomationControlled')
        
        try:
            self.page = ChromiumPage(addr_or_opts=options)
            logger.info("æµè§ˆå™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            logger.warning("æç¤ºï¼šå¦‚æœé‡åˆ°è¿æ¥é”™è¯¯ï¼Œè¯·å…ˆæ‰‹åŠ¨å¯åŠ¨ Chrome è°ƒè¯•æ¨¡å¼")
            self.page = None
        
        # å­˜å‚¨é‡‡é›†çš„æ•°æ®
        self.douyin_data = []
        self.xhs_data = []
        self.wechat_data = []
        
        logger.info(f"å¸‚åœºé›·è¾¾ä¸“ä¸šç‰ˆåˆå§‹åŒ–å®Œæˆï¼Œå½“å‰æ—¥æœŸ: {CURRENT_DATE}")
    
    def is_recent(self, date_str: str) -> bool:
        """
        åˆ¤æ–­æ—¥æœŸå­—ç¬¦ä¸²æ˜¯å¦åœ¨æœ€è¿‘3å¤©å†…
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¯èƒ½æ˜¯"2å°æ—¶å‰"ã€"æ˜¨å¤©"ã€"2025-12-10"ç­‰æ ¼å¼
        
        Returns:
            æ˜¯å¦åœ¨æœ€è¿‘3å¤©å†…
        """
        if not date_str:
            return False
        
        date_str = date_str.strip()
        now = datetime.now()
        three_days_ago = now - timedelta(days=DAYS_BACK)
        
        try:
            # å¤„ç†"Xå°æ—¶å‰"ã€"Xåˆ†é’Ÿå‰"
            if "å°æ—¶å‰" in date_str or "åˆ†é’Ÿå‰" in date_str:
                return True  # å‡è®¾æ˜¯æœ€è¿‘çš„
            
            # å¤„ç†"æ˜¨å¤©"
            if "æ˜¨å¤©" in date_str:
                return True
            
            # å¤„ç†"Xå¤©å‰"
            match = re.search(r'(\d+)å¤©å‰', date_str)
            if match:
                days = int(match.group(1))
                return days <= DAYS_BACK
            
            # å¤„ç†æ ‡å‡†æ—¥æœŸæ ¼å¼ "2025-12-10"
            date_match = re.search(r'(\d{4})-(\d{1,2})-(\d{1,2})', date_str)
            if date_match:
                year, month, day = map(int, date_match.groups())
                post_date = datetime(year, month, day)
                return post_date >= three_days_ago
            
            # å¤„ç†"12-10"æ ¼å¼ï¼ˆå‡è®¾æ˜¯ä»Šå¹´ï¼‰
            date_match = re.search(r'(\d{1,2})-(\d{1,2})', date_str)
            if date_match:
                month, day = map(int, date_match.groups())
                post_date = datetime(now.year, month, day)
                return post_date >= three_days_ago
            
            # å¦‚æœæ— æ³•è§£æï¼Œé»˜è®¤è¿”å› Trueï¼ˆä¿å®ˆç­–ç•¥ï¼‰
            logger.warning(f"æ— æ³•è§£ææ—¥æœŸæ ¼å¼: {date_str}ï¼Œé»˜è®¤ä¿ç•™")
            return True
            
        except Exception as e:
            logger.warning(f"æ—¥æœŸè§£æå¤±è´¥: {date_str}, é”™è¯¯: {str(e)}")
            return True  # ä¿å®ˆç­–ç•¥ï¼šæ— æ³•åˆ¤æ–­æ—¶ä¿ç•™
    
    def manual_login(self):
        """
        ç¬¬ä¸€é˜¶æ®µï¼šäººå·¥ç™»å½• (ä¸‰å¹³å°çƒ­å¯åŠ¨)
        æ‰“å¼€æŠ–éŸ³ã€å°çº¢ä¹¦ã€å¾®ä¿¡å…¬ä¼—å·ä¸‰ä¸ªæ ‡ç­¾é¡µï¼Œç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ç™»å½•
        """
        if not self.page:
            raise RuntimeError("æµè§ˆå™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œç™»å½•")
        
        logger.info("=" * 60)
        logger.info("ç¬¬ä¸€é˜¶æ®µï¼šäººå·¥ç™»å½•")
        logger.info("=" * 60)
        
        # æ‰“å¼€æŠ–éŸ³æ ‡ç­¾é¡µ (Tab 1)
        logger.info("æ­£åœ¨æ‰“å¼€æŠ–éŸ³...")
        self.page.get('https://www.douyin.com')
        time.sleep(3)
        print("âœ… æŠ–éŸ³æ ‡ç­¾é¡µå·²æ‰“å¼€")
        
        # æ‰“å¼€å°çº¢ä¹¦æ ‡ç­¾é¡µ (Tab 2)
        logger.info("æ­£åœ¨æ‰“å¼€å°çº¢ä¹¦...")
        self.page.new_tab()
        time.sleep(1)
        self.page.get('https://www.xiaohongshu.com')
        time.sleep(3)
        print("âœ… å°çº¢ä¹¦æ ‡ç­¾é¡µå·²æ‰“å¼€")
        
        # æ‰“å¼€å¾®ä¿¡å…¬ä¼—å·æœç´¢é¡µ (Tab 3)
        logger.info("æ­£åœ¨æ‰“å¼€å¾®ä¿¡å…¬ä¼—å·æœç´¢é¡µ...")
        self.page.new_tab()
        time.sleep(1)
        self.page.get('https://weixin.sogou.com/')
        time.sleep(3)
        print("âœ… å¾®ä¿¡å…¬ä¼—å·æœç´¢é¡µå·²æ‰“å¼€")
        
        # ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ç™»å½•
        print("\n" + "=" * 80)
        print("ğŸ”´ ã€é‡è¦ã€‘è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨å®Œæˆä»¥ä¸‹æ“ä½œï¼š")
        print("")
        print("1ï¸âƒ£  æŠ–éŸ³ï¼šæ‰«ç æˆ–è¾“å…¥è´¦å·å¯†ç ç™»å½•ï¼Œç¡®ä¿èƒ½çœ‹åˆ°é¦–é¡µæ¨èå†…å®¹")
        print("2ï¸âƒ£  å°çº¢ä¹¦ï¼šæ‰«ç æˆ–è¾“å…¥è´¦å·å¯†ç ç™»å½•ï¼Œç¡®ä¿èƒ½çœ‹åˆ°é¦–é¡µæ¨èå†…å®¹")
        print("3ï¸âƒ£  å¾®ä¿¡å…¬ä¼—å·ï¼šå¦‚æœå‡ºç°éªŒè¯ç ï¼Œè¯·æ‰‹åŠ¨å®ŒæˆéªŒè¯")
        print("")
        print("âš ï¸  è¯·ç¡®ä¿ä¸‰ä¸ªå¹³å°éƒ½å·²æˆåŠŸç™»å½•ï¼")
        print("   ç™»å½•å®Œæˆåï¼Œè¯·å›åˆ°è¿™é‡ŒæŒ‰ã€å›è½¦é”®ã€‘ç»§ç»­é‡‡é›†...")
        print("=" * 80)
        
        # é˜»å¡ç­‰å¾…ç”¨æˆ·æŒ‰å›è½¦
        try:
            input("\nğŸ‘‰ ç¡®è®¤å·²å…¨éƒ¨ç™»å½•åï¼ŒæŒ‰å›è½¦é”®ç»§ç»­...")
        except EOFError:
            # éäº¤äº’å¼ç¯å¢ƒï¼Œç­‰å¾…60ç§’
            logger.warning("æ£€æµ‹åˆ°éäº¤äº’å¼ç¯å¢ƒï¼Œç­‰å¾…60ç§’åè‡ªåŠ¨ç»§ç»­...")
            for i in range(60, 0, -10):
                print(f"â³ ç­‰å¾…ä¸­... {i}ç§’åè‡ªåŠ¨ç»§ç»­ï¼ˆå¦‚æœå·²ç™»å½•ï¼Œç¨‹åºä¼šè‡ªåŠ¨å¼€å§‹é‡‡é›†ï¼‰")
                time.sleep(10)
        
        logger.info("ç”¨æˆ·ç¡®è®¤ç™»å½•å®Œæˆï¼Œå¼€å§‹æ‰§è¡Œé‡‡é›†")
        time.sleep(2)  # é¢å¤–ç­‰å¾…2ç§’ç¡®ä¿é¡µé¢ç¨³å®š
    
    def crawl_douyin(self) -> List[Dict[str, Any]]:
        """
        ç¬¬äºŒé˜¶æ®µï¼šæŠ–éŸ³é‡‡é›†é€»è¾‘
        
        Returns:
            æŠ–éŸ³æ•°æ®åˆ—è¡¨
        """
        if not self.page:
            logger.error("æµè§ˆå™¨æœªåˆå§‹åŒ–")
            return []
        
        logger.info("=" * 60)
        logger.info("ç¬¬äºŒé˜¶æ®µï¼šæŠ–éŸ³é‡‡é›†")
        logger.info("=" * 60)
        
        results = []
        
        try:
            # åˆ‡æ¢åˆ°æŠ–éŸ³æ ‡ç­¾é¡µï¼ˆç¬¬ä¸€ä¸ªæ ‡ç­¾ï¼‰
            self.page.get('https://www.douyin.com')
            time.sleep(3)
            
            for keyword in COMPETITOR_KEYWORDS:
                try:
                    logger.info(f"æœç´¢å…³é”®è¯: {keyword}")
                    
                    # æŸ¥æ‰¾æœç´¢æ¡†
                    search_input = None
                    selectors = [
                        'tag:input@placeholder*=æœç´¢',
                        'tag:input@class*=search',
                        'tag:input@type=text',
                    ]
                    
                    for selector in selectors:
                        try:
                            search_input = self.page.ele(selector, timeout=3)
                            if search_input:
                                break
                        except:
                            continue
                    
                    if not search_input:
                        logger.warning(f"æœªæ‰¾åˆ°æœç´¢æ¡†ï¼Œè·³è¿‡å…³é”®è¯: {keyword}")
                        continue
                    
                    # è¾“å…¥å…³é”®è¯
                    search_input.clear()
                    search_input.input(keyword)
                    time.sleep(1)
                    
                    # ç‚¹å‡»æœç´¢æŒ‰é’®æˆ–æŒ‰å›è½¦
                    search_btn = self.page.ele('tag:button@class*=search', timeout=2)
                    if search_btn:
                        search_btn.click()
                    else:
                        search_input.input('\n')
                    
                    time.sleep(5)  # ç­‰å¾…æœç´¢ç»“æœåŠ è½½
                    
                    # å°è¯•ç‚¹å‡»"æœ€æ–°"æ’åº
                    try:
                        latest_btn = self.page.ele('text:æœ€æ–°', timeout=3)
                        if latest_btn:
                            latest_btn.click()
                            time.sleep(3)
                            logger.info("å·²åˆ‡æ¢åˆ°'æœ€æ–°'æ’åº")
                    except:
                        logger.info("æœªæ‰¾åˆ°'æœ€æ–°'æ’åºæŒ‰é’®ï¼Œä½¿ç”¨é»˜è®¤æ’åº")
                    
                    time.sleep(3)  # å†æ¬¡ç­‰å¾…é¡µé¢åŠ è½½
                    
                    # æå–è§†é¢‘åˆ—è¡¨
                    videos = []
                    selectors = [
                        'tag:a@href*=/video/',
                        'tag:div@class*=video-item',
                        'tag:div@class*=video',
                    ]
                    
                    for selector in selectors:
                        try:
                            videos = self.page.eles(selector, timeout=5)
                            if videos and len(videos) > 0:
                                logger.info(f"ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")
                                break
                        except:
                            continue
                    
                    # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•é€šè¿‡é“¾æ¥ç‰¹å¾æŸ¥æ‰¾
                    if not videos:
                        try:
                            all_links = self.page.eles('tag:a', timeout=5)
                            video_links = [link for link in all_links if '/video/' in (link.attr('href') or '')]
                            if video_links:
                                videos = video_links[:10]
                                logger.info(f"é€šè¿‡é“¾æ¥ç‰¹å¾æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")
                        except Exception as e:
                            logger.warning(f"é€šè¿‡é“¾æ¥æŸ¥æ‰¾å¤±è´¥: {str(e)}")
                    
                    # é™åˆ¶ä¸ºå‰10æ¡
                    videos = videos[:10]
                    
                    if not videos:
                        logger.warning(f"æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘ï¼Œå½“å‰é¡µé¢URL: {self.page.url}")
                        continue
                    
                    for idx, video in enumerate(videos, 1):
                        try:
                            # æå–æ ‡é¢˜å’Œé“¾æ¥
                            title = ""
                            url = ""
                            
                            try:
                                if hasattr(video, 'tag') and video.tag == 'a':
                                    title = video.text or ""
                                    url = video.attr('href') or ""
                                else:
                                    link_elem = video.ele('tag:a', timeout=1)
                                    if link_elem:
                                        url = link_elem.attr('href') or ""
                                        title = link_elem.text or ""
                                    
                                    if not title:
                                        for tag in ['tag:span', 'tag:p', 'tag:div', 'tag:h3']:
                                            try:
                                                title_elem = video.ele(tag, timeout=0.5)
                                                if title_elem and title_elem.text:
                                                    title = title_elem.text
                                                    break
                                            except:
                                                continue
                            except Exception as e:
                                logger.warning(f"æå–è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}")
                                continue
                            
                            if url and not url.startswith('http'):
                                url = 'https://www.douyin.com' + url
                            
                            # æå–å‘å¸ƒæ—¶é—´
                            date_str = ""
                            try:
                                date_selectors = ['tag:span', 'tag:time', 'tag:div']
                                for sel in date_selectors:
                                    try:
                                        elems = video.eles(sel, timeout=0.5)
                                        for elem in elems:
                                            text = elem.text or ""
                                            if any(kw in text for kw in ['å‰', 'å¤©', 'å°æ—¶', 'åˆ†é’Ÿ', 'æ˜¨å¤©', 'ä»Šå¤©']):
                                                date_str = text
                                                break
                                        if date_str:
                                            break
                                    except:
                                        continue
                            except:
                                pass
                            
                            # æ—¶é—´è¿‡æ»¤ï¼šåªä¿ç•™3å¤©å†…
                            if not self.is_recent(date_str):
                                logger.info(f"  è§†é¢‘ {idx} è¶…å‡º3å¤©èŒƒå›´ï¼Œè·³è¿‡: {title[:30] if title else 'æ— æ ‡é¢˜'}...")
                                continue
                            
                            if not title or not url:
                                continue
                            
                            # ç‚¹å‡»è¿›å…¥è§†é¢‘è¯¦æƒ…é¡µè·å–è¯„è®ºï¼ˆå‰5æ¡é«˜èµï¼‰
                            comments = []
                            try:
                                click_link = video if hasattr(video, 'tag') and video.tag == 'a' else video.ele('tag:a', timeout=1)
                                if click_link:
                                    click_link.click()
                                    time.sleep(3)  # ç­‰å¾…è¯¦æƒ…é¡µåŠ è½½
                                    
                                    # æå–è¯„è®ºï¼ˆå‰5æ¡é«˜èµï¼‰
                                    comment_selectors = [
                                        'tag:div@class*=comment-item',
                                        'tag:div@class*=comment',
                                        'tag:li@class*=comment',
                                    ]
                                    
                                    for selector in comment_selectors:
                                        try:
                                            comment_elems = self.page.eles(selector, timeout=2)
                                            if comment_elems:
                                                for comment_elem in comment_elems[:5]:
                                                    comment_text = comment_elem.text
                                                    if comment_text:
                                                        comments.append(comment_text)
                                                break
                                        except:
                                            continue
                                    
                                    # è¿”å›åˆ—è¡¨é¡µ
                                    self.page.back()
                                    time.sleep(2)
                            except Exception as e:
                                logger.warning(f"è·å–è¯„è®ºå¤±è´¥: {str(e)}")
                            
                            result = {
                                "platform": "æŠ–éŸ³",
                                "keyword": keyword,
                                "title": title.strip(),
                                "url": url.strip(),
                                "date": date_str.strip(),
                                "comments": comments,
                                "comment_count": len(comments)
                            }
                            results.append(result)
                            logger.info(f"  âœ“ é‡‡é›†è§†é¢‘ {idx}: {title[:50]}... (è¯„è®º: {len(comments)}æ¡)")
                            
                        except Exception as e:
                            logger.warning(f"å¤„ç†è§†é¢‘ {idx} å¤±è´¥: {str(e)}")
                            continue
                    
                    time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
                    
                except Exception as e:
                    logger.error(f"é‡‡é›†å…³é”®è¯ {keyword} å¤±è´¥: {str(e)}")
                    continue
            
        except Exception as e:
            logger.error(f"æŠ–éŸ³é‡‡é›†å¼‚å¸¸: {str(e)}", exc_info=True)
        
        logger.info(f"æŠ–éŸ³é‡‡é›†å®Œæˆï¼Œå…±æ‰¾åˆ° {len(results)} æ¡æœ‰æ•ˆæ•°æ®")
        self.douyin_data = results
        return results
    
    def crawl_xhs(self) -> List[Dict[str, Any]]:
        """
        ç¬¬ä¸‰é˜¶æ®µï¼šå°çº¢ä¹¦é‡‡é›†é€»è¾‘
        
        Returns:
            å°çº¢ä¹¦æ•°æ®åˆ—è¡¨
        """
        if not self.page:
            logger.error("æµè§ˆå™¨æœªåˆå§‹åŒ–")
            return []
        
        logger.info("=" * 60)
        logger.info("ç¬¬ä¸‰é˜¶æ®µï¼šå°çº¢ä¹¦é‡‡é›†")
        logger.info("=" * 60)
        
        results = []
        
        try:
            # åˆ‡æ¢åˆ°å°çº¢ä¹¦æ ‡ç­¾é¡µ
            self.page.get('https://www.xiaohongshu.com')
            time.sleep(3)
            
            for keyword in COMPETITOR_KEYWORDS:
                try:
                    logger.info(f"æœç´¢å…³é”®è¯: {keyword}")
                    
                    # æŸ¥æ‰¾æœç´¢æ¡†
                    search_input = None
                    selectors = [
                        'tag:input@placeholder*=æœç´¢',
                        'tag:input@class*=search',
                        'tag:input@type=text',
                    ]
                    
                    for selector in selectors:
                        try:
                            search_input = self.page.ele(selector, timeout=3)
                            if search_input:
                                break
                        except:
                            continue
                    
                    if not search_input:
                        logger.warning(f"æœªæ‰¾åˆ°æœç´¢æ¡†ï¼Œè·³è¿‡å…³é”®è¯: {keyword}")
                        continue
                    
                    # è¾“å…¥å…³é”®è¯
                    search_input.clear()
                    search_input.input(keyword)
                    time.sleep(1)
                    
                    # ç‚¹å‡»æœç´¢
                    search_btn = self.page.ele('tag:button@class*=search', timeout=2)
                    if search_btn:
                        search_btn.click()
                    else:
                        search_input.input('\n')
                    
                    time.sleep(5)  # ç­‰å¾…æœç´¢ç»“æœåŠ è½½
                    
                    # å°è¯•ç‚¹å‡»"æœ€æ–°"æ’åº
                    try:
                        latest_btn = self.page.ele('text:æœ€æ–°', timeout=3)
                        if latest_btn:
                            latest_btn.click()
                            time.sleep(3)
                            logger.info("å·²åˆ‡æ¢åˆ°'æœ€æ–°'æ’åº")
                    except:
                        logger.info("æœªæ‰¾åˆ°'æœ€æ–°'æ’åºæŒ‰é’®ï¼Œä½¿ç”¨é»˜è®¤æ’åº")
                    
                    time.sleep(3)  # å†æ¬¡ç­‰å¾…é¡µé¢åŠ è½½
                    
                    # æå–ç¬”è®°åˆ—è¡¨ï¼ˆå‰10-15æ¡ï¼‰
                    notes = []
                    selectors = [
                        'tag:a@href*=/explore/',
                        'tag:div@class*=note-item',
                        'tag:div@class*=note',
                    ]
                    
                    for selector in selectors:
                        try:
                            notes = self.page.eles(selector, timeout=5)
                            if notes and len(notes) > 0:
                                logger.info(f"ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(notes)} æ¡ç¬”è®°")
                                break
                        except:
                            continue
                    
                    # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•é€šè¿‡é“¾æ¥ç‰¹å¾æŸ¥æ‰¾
                    if not notes:
                        try:
                            all_links = self.page.eles('tag:a', timeout=5)
                            explore_links = [link for link in all_links if '/explore/' in (link.attr('href') or '')]
                            if explore_links:
                                notes = explore_links[:15]
                                logger.info(f"é€šè¿‡é“¾æ¥ç‰¹å¾æ‰¾åˆ° {len(notes)} æ¡ç¬”è®°")
                        except Exception as e:
                            logger.warning(f"é€šè¿‡é“¾æ¥æŸ¥æ‰¾å¤±è´¥: {str(e)}")
                    
                    # é™åˆ¶ä¸ºå‰15æ¡
                    notes = notes[:15]
                    
                    if not notes:
                        logger.warning(f"æœªæ‰¾åˆ°ä»»ä½•ç¬”è®°ï¼Œå½“å‰é¡µé¢URL: {self.page.url}")
                        continue
                    
                    for idx, note in enumerate(notes, 1):
                        try:
                            # æå–æ ‡é¢˜å’Œé“¾æ¥
                            title = ""
                            url = ""
                            
                            try:
                                if hasattr(note, 'tag') and note.tag == 'a':
                                    title = note.text or ""
                                    url = note.attr('href') or ""
                                else:
                                    link_elem = note.ele('tag:a', timeout=1)
                                    if link_elem:
                                        url = link_elem.attr('href') or ""
                                        title = link_elem.text or ""
                                    
                                    if not title:
                                        for tag in ['tag:span', 'tag:p', 'tag:div', 'tag:h3']:
                                            try:
                                                title_elem = note.ele(tag, timeout=0.5)
                                                if title_elem and title_elem.text:
                                                    title = title_elem.text
                                                    break
                                            except:
                                                continue
                            except Exception as e:
                                logger.warning(f"æå–ç¬”è®°ä¿¡æ¯å¤±è´¥: {str(e)}")
                                continue
                            
                            if url and not url.startswith('http'):
                                url = 'https://www.xiaohongshu.com' + url
                            
                            # æå–å‘å¸ƒæ—¶é—´
                            date_str = ""
                            try:
                                date_selectors = ['tag:span', 'tag:time', 'tag:div']
                                for sel in date_selectors:
                                    try:
                                        elems = note.eles(sel, timeout=0.5)
                                        for elem in elems:
                                            text = elem.text or ""
                                            if any(kw in text for kw in ['å‰', 'å¤©', 'å°æ—¶', 'åˆ†é’Ÿ', 'æ˜¨å¤©', 'ä»Šå¤©']):
                                                date_str = text
                                                break
                                        if date_str:
                                            break
                                    except:
                                        continue
                            except:
                                pass
                            
                            # æ—¶é—´è¿‡æ»¤ï¼šåªä¿ç•™3å¤©å†…
                            if date_str and not self.is_recent(date_str):
                                logger.info(f"  ç¬”è®° {idx} è¶…å‡º3å¤©èŒƒå›´ï¼Œè·³è¿‡: {title[:30] if title else 'æ— æ ‡é¢˜'}...")
                                continue
                            
                            if not title or not url:
                                continue
                            
                            # æå–æ‘˜è¦
                            snippet = ""
                            try:
                                all_text = note.text or ""
                                if all_text and len(all_text) > len(title):
                                    snippet = all_text[:200]
                            except:
                                pass
                            
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«è´Ÿé¢å…³é”®è¯
                            has_negative = any(kw in (title + snippet) for kw in NEGATIVE_KEYWORDS)
                            
                            # å¦‚æœåŒ…å«è´Ÿé¢å…³é”®è¯ï¼Œå¿…é¡»ç‚¹è¿›å»è·å–è¯„è®º
                            comments = []
                            if has_negative or any(kw in snippet for kw in NEGATIVE_KEYWORDS):
                                try:
                                    click_link = note if hasattr(note, 'tag') and note.tag == 'a' else note.ele('tag:a', timeout=1)
                                    if click_link:
                                        click_link.click()
                                        time.sleep(3)  # ç­‰å¾…è¯¦æƒ…é¡µåŠ è½½
                                        
                                        # æå–è¯„è®ºï¼ˆç½®é¡¶æˆ–é«˜èµï¼‰
                                        comment_selectors = [
                                            'tag:div@class*=comment-item',
                                            'tag:div@class*=comment',
                                            'tag:li@class*=comment',
                                        ]
                                        
                                        for selector in comment_selectors:
                                            try:
                                                comment_elems = self.page.eles(selector, timeout=2)
                                                if comment_elems:
                                                    for comment_elem in comment_elems[:5]:
                                                        comment_text = comment_elem.text
                                                        if comment_text:
                                                            comments.append(comment_text)
                                                    break
                                            except:
                                                continue
                                        
                                        # è¿”å›åˆ—è¡¨é¡µ
                                        self.page.back()
                                        time.sleep(2)
                                except Exception as e:
                                    logger.warning(f"è·å–è¯„è®ºå¤±è´¥: {str(e)}")
                            
                            result = {
                                "platform": "å°çº¢ä¹¦",
                                "keyword": keyword,
                                "title": title.strip(),
                                "url": url.strip(),
                                "date": date_str.strip(),
                                "snippet": snippet.strip(),
                                "has_negative": has_negative,
                                "comments": comments,
                                "comment_count": len(comments)
                            }
                            results.append(result)
                            logger.info(f"  âœ“ é‡‡é›†ç¬”è®° {idx}: {title[:50]}... (è´Ÿé¢: {has_negative}, è¯„è®º: {len(comments)}æ¡)")
                            
                        except Exception as e:
                            logger.warning(f"å¤„ç†ç¬”è®° {idx} å¤±è´¥: {str(e)}")
                            continue
                    
                    time.sleep(2)
                    
                except Exception as e:
                    logger.error(f"é‡‡é›†å…³é”®è¯ {keyword} å¤±è´¥: {str(e)}")
                    continue
            
        except Exception as e:
            logger.error(f"å°çº¢ä¹¦é‡‡é›†å¼‚å¸¸: {str(e)}", exc_info=True)
        
        logger.info(f"å°çº¢ä¹¦é‡‡é›†å®Œæˆï¼Œå…±æ‰¾åˆ° {len(results)} æ¡æœ‰æ•ˆæ•°æ®")
        self.xhs_data = results
        return results
    
    def crawl_wechat(self) -> List[Dict[str, Any]]:
        """
        ç¬¬ä¸‰é˜¶æ®µï¼ˆè¡¥å……ï¼‰ï¼šå¾®ä¿¡å…¬ä¼—å·é‡‡é›†é€»è¾‘
        
        Returns:
            å¾®ä¿¡å…¬ä¼—å·æ•°æ®åˆ—è¡¨
        """
        if not self.page:
            logger.error("æµè§ˆå™¨æœªåˆå§‹åŒ–")
            return []
        
        logger.info("=" * 60)
        logger.info("ç¬¬ä¸‰é˜¶æ®µï¼ˆè¡¥å……ï¼‰ï¼šå¾®ä¿¡å…¬ä¼—å·é‡‡é›†")
        logger.info("=" * 60)
        
        results = []
        
        try:
            # åˆ‡æ¢åˆ°å¾®ä¿¡å…¬ä¼—å·æœç´¢é¡µï¼ˆæœç‹—å¾®ä¿¡ï¼‰
            self.page.get('https://weixin.sogou.com/')
            time.sleep(3)
            
            # å¤„ç†å¯èƒ½çš„éªŒè¯ç 
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰éªŒè¯ç 
                verify_img = self.page.ele('tag:img@id=seccodeImage', timeout=2)
                if verify_img:
                    logger.warning("âš ï¸ æ£€æµ‹åˆ°éªŒè¯ç ï¼Œè¯·æ‰‹åŠ¨å®ŒæˆéªŒè¯åæŒ‰å›è½¦ç»§ç»­...")
                    try:
                        input("éªŒè¯å®ŒæˆåæŒ‰å›è½¦ç»§ç»­...")
                    except EOFError:
                        time.sleep(10)
            except:
                pass  # æ²¡æœ‰éªŒè¯ç ï¼Œç»§ç»­
            
            for keyword in COMPETITOR_KEYWORDS:
                try:
                    logger.info(f"æœç´¢å…³é”®è¯: {keyword}")
                    
                    # æŸ¥æ‰¾æœç´¢æ¡†
                    search_input = None
                    selectors = [
                        'tag:input@id=query',
                        'tag:input@name=query',
                        'tag:input@class*=search',
                        'tag:input@type=text',
                    ]
                    
                    for selector in selectors:
                        try:
                            search_input = self.page.ele(selector, timeout=3)
                            if search_input:
                                break
                        except:
                            continue
                    
                    if not search_input:
                        logger.warning(f"æœªæ‰¾åˆ°æœç´¢æ¡†ï¼Œè·³è¿‡å…³é”®è¯: {keyword}")
                        continue
                    
                    # è¾“å…¥å…³é”®è¯
                    search_input.clear()
                    search_input.input(keyword)
                    time.sleep(1)
                    
                    # ç‚¹å‡»æœç´¢æŒ‰é’®
                    search_btn = self.page.ele('tag:input@type=submit', timeout=2)
                    if search_btn:
                        search_btn.click()
                    else:
                        search_input.input('\n')
                    
                    time.sleep(5)  # ç­‰å¾…æœç´¢ç»“æœåŠ è½½
                    
                    # å¤„ç†å¯èƒ½çš„éªŒè¯ç ï¼ˆå†æ¬¡æ£€æŸ¥ï¼‰
                    try:
                        verify_img = self.page.ele('tag:img@id=seccodeImage', timeout=2)
                        if verify_img:
                            logger.warning("âš ï¸ æ£€æµ‹åˆ°éªŒè¯ç ï¼Œè¯·æ‰‹åŠ¨å®ŒæˆéªŒè¯åæŒ‰å›è½¦ç»§ç»­...")
                            try:
                                input("éªŒè¯å®ŒæˆåæŒ‰å›è½¦ç»§ç»­...")
                            except EOFError:
                                time.sleep(10)
                    except:
                        pass
                    
                    # æå–æ–‡ç« åˆ—è¡¨
                    articles = []
                    selectors = [
                        'tag:div@class*=news-box',
                        'tag:div@class*=news-item',
                        'tag:div@class*=news',
                        'tag:h3@class*=news-title',
                    ]
                    
                    for selector in selectors:
                        try:
                            articles = self.page.eles(selector, timeout=5)
                            if articles and len(articles) > 0:
                                logger.info(f"ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« ")
                                break
                        except:
                            continue
                    
                    # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•é€šè¿‡é“¾æ¥ç‰¹å¾æŸ¥æ‰¾
                    if not articles:
                        try:
                            all_links = self.page.eles('tag:a', timeout=5)
                            wechat_links = [link for link in all_links if 'mp.weixin.qq.com' in (link.attr('href') or '')]
                            if wechat_links:
                                articles = wechat_links[:15]
                                logger.info(f"é€šè¿‡é“¾æ¥ç‰¹å¾æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« ")
                        except Exception as e:
                            logger.warning(f"é€šè¿‡é“¾æ¥æŸ¥æ‰¾å¤±è´¥: {str(e)}")
                    
                    # é™åˆ¶ä¸ºå‰15æ¡
                    articles = articles[:15]
                    
                    if not articles:
                        logger.warning(f"æœªæ‰¾åˆ°ä»»ä½•æ–‡ç« ï¼Œå½“å‰é¡µé¢URL: {self.page.url}")
                        continue
                    
                    for idx, article in enumerate(articles, 1):
                        try:
                            # æå–æ ‡é¢˜å’Œé“¾æ¥
                            title = ""
                            url = ""
                            
                            try:
                                if hasattr(article, 'tag') and article.tag == 'a':
                                    title = article.text or ""
                                    url = article.attr('href') or ""
                                else:
                                    link_elem = article.ele('tag:a', timeout=1)
                                    if link_elem:
                                        url = link_elem.attr('href') or ""
                                        title = link_elem.text or ""
                                    
                                    if not title:
                                        for tag in ['tag:h3', 'tag:h2', 'tag:span', 'tag:p']:
                                            try:
                                                title_elem = article.ele(tag, timeout=0.5)
                                                if title_elem and title_elem.text:
                                                    title = title_elem.text
                                                    break
                                            except:
                                                continue
                            except Exception as e:
                                logger.warning(f"æå–æ–‡ç« ä¿¡æ¯å¤±è´¥: {str(e)}")
                                continue
                            
                            if not url.startswith('http'):
                                # å¤„ç†ç›¸å¯¹é“¾æ¥
                                if url.startswith('//'):
                                    url = 'https:' + url
                                elif url.startswith('/'):
                                    url = 'https://weixin.sogou.com' + url
                            
                            # æå–å‘å¸ƒæ—¶é—´
                            date_str = ""
                            try:
                                date_selectors = ['tag:span@class*=news-time', 'tag:span', 'tag:time']
                                for sel in date_selectors:
                                    try:
                                        elems = article.eles(sel, timeout=0.5)
                                        for elem in elems:
                                            text = elem.text or ""
                                            if any(kw in text for kw in ['å‰', 'å¤©', 'å°æ—¶', 'åˆ†é’Ÿ', 'æ˜¨å¤©', 'ä»Šå¤©', '-']):
                                                date_str = text
                                                break
                                        if date_str:
                                            break
                                    except:
                                        continue
                            except:
                                pass
                            
                            # æ—¶é—´è¿‡æ»¤ï¼šåªä¿ç•™3å¤©å†…
                            if date_str and not self.is_recent(date_str):
                                logger.info(f"  æ–‡ç«  {idx} è¶…å‡º3å¤©èŒƒå›´ï¼Œè·³è¿‡: {title[:30] if title else 'æ— æ ‡é¢˜'}...")
                                continue
                            
                            if not title or not url:
                                continue
                            
                            # æå–æ‘˜è¦
                            snippet = ""
                            try:
                                snippet_elem = article.ele('tag:p@class*=news-text', timeout=1)
                                if snippet_elem:
                                    snippet = snippet_elem.text or ""
                                else:
                                    all_text = article.text or ""
                                    if all_text and len(all_text) > len(title):
                                        snippet = all_text[:200]
                            except:
                                pass
                            
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«è´Ÿé¢å…³é”®è¯
                            has_negative = any(kw in (title + snippet) for kw in NEGATIVE_KEYWORDS)
                            
                            # å¦‚æœåŒ…å«è´Ÿé¢å…³é”®è¯ï¼Œç‚¹è¿›å»è·å–è¯„è®º
                            comments = []
                            if has_negative or any(kw in snippet for kw in NEGATIVE_KEYWORDS):
                                try:
                                    click_link = article if hasattr(article, 'tag') and article.tag == 'a' else article.ele('tag:a', timeout=1)
                                    if click_link:
                                        click_link.click()
                                        time.sleep(3)  # ç­‰å¾…è¯¦æƒ…é¡µåŠ è½½
                                        
                                        # æå–è¯„è®ºï¼ˆå¾®ä¿¡å…¬ä¼—å·çš„è¯„è®ºåœ¨æ–‡ç« åº•éƒ¨ï¼‰
                                        comment_selectors = [
                                            'tag:div@class*=comment',
                                            'tag:div@id*=comment',
                                            'tag:div@class*=msg',
                                        ]
                                        
                                        for selector in comment_selectors:
                                            try:
                                                comment_elems = self.page.eles(selector, timeout=2)
                                                if comment_elems:
                                                    for comment_elem in comment_elems[:5]:
                                                        comment_text = comment_elem.text
                                                        if comment_text:
                                                            comments.append(comment_text)
                                                    break
                                            except:
                                                continue
                                        
                                        # è¿”å›åˆ—è¡¨é¡µ
                                        self.page.back()
                                        time.sleep(2)
                                except Exception as e:
                                    logger.warning(f"è·å–è¯„è®ºå¤±è´¥: {str(e)}")
                            
                            result = {
                                "platform": "å¾®ä¿¡å…¬ä¼—å·",
                                "keyword": keyword,
                                "title": title.strip(),
                                "url": url.strip(),
                                "date": date_str.strip(),
                                "snippet": snippet.strip(),
                                "has_negative": has_negative,
                                "comments": comments,
                                "comment_count": len(comments)
                            }
                            results.append(result)
                            logger.info(f"  âœ“ é‡‡é›†æ–‡ç«  {idx}: {title[:50]}... (è´Ÿé¢: {has_negative}, è¯„è®º: {len(comments)}æ¡)")
                            
                        except Exception as e:
                            logger.warning(f"å¤„ç†æ–‡ç«  {idx} å¤±è´¥: {str(e)}")
                            continue
                    
                    time.sleep(2)
                    
                except Exception as e:
                    logger.error(f"é‡‡é›†å…³é”®è¯ {keyword} å¤±è´¥: {str(e)}")
                    continue
            
        except Exception as e:
            logger.error(f"å¾®ä¿¡å…¬ä¼—å·é‡‡é›†å¼‚å¸¸: {str(e)}", exc_info=True)
        
        logger.info(f"å¾®ä¿¡å…¬ä¼—å·é‡‡é›†å®Œæˆï¼Œå…±æ‰¾åˆ° {len(results)} æ¡æœ‰æ•ˆæ•°æ®")
        self.wechat_data = results
        return results
    
    def save_raw_data(self):
        """ä¿å­˜åŸå§‹æ•°æ®åˆ° CSV"""
        all_data = self.douyin_data + self.xhs_data + self.wechat_data
        
        if not all_data:
            logger.warning("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return
        
        # è½¬æ¢ä¸º DataFrame
        df_data = []
        for item in all_data:
            row = {
                "å¹³å°": item.get("platform", ""),
                "å…³é”®è¯": item.get("keyword", ""),
                "æ ‡é¢˜": item.get("title", ""),
                "é“¾æ¥": item.get("url", ""),
                "å‘å¸ƒæ—¶é—´": item.get("date", ""),
                "æ‘˜è¦": item.get("snippet", ""),
                "åŒ…å«è´Ÿé¢": item.get("has_negative", False),
                "è¯„è®ºæ•°": item.get("comment_count", 0),
                "è¯„è®ºå†…å®¹": "\n".join(item.get("comments", []))
            }
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        df.to_csv('raw_data.csv', index=False, encoding='utf-8-sig')
        logger.info(f"åŸå§‹æ•°æ®å·²ä¿å­˜åˆ°: raw_data.csv (å…± {len(df_data)} æ¡)")
    
    def generate_report(self) -> str:
        """
        ç¬¬å››é˜¶æ®µï¼šä½¿ç”¨ Gemini Pro ç”Ÿæˆå¸‚åœºé›·è¾¾æ—¥æŠ¥
        
        Returns:
            Markdown æ ¼å¼çš„æŠ¥å‘Š
        """
        logger.info("=" * 60)
        logger.info("ç¬¬å››é˜¶æ®µï¼šé˜¿é‡Œåƒé—® é”€å† åˆ†æ")
        logger.info("=" * 60)
        
        all_data = {
            "douyin_data": self.douyin_data,
            "xhs_data": self.xhs_data,
            "wechat_data": self.wechat_data,
            "current_date": CURRENT_DATE
        }
        data_json = json.dumps(all_data, ensure_ascii=False, indent=2)
        
        system_prompt = """ä½ ä¸æ˜¯AIï¼Œä½ æ˜¯æµ·é©¬èŒåŠ çš„**é¦–å¸­å¸‚åœºå®˜**ã€‚ä½ çš„å—ä¼—æ˜¯ä¸€çº¿é”€å”®å›¢é˜Ÿã€‚
è¯·é˜…è¯»ä»¥ä¸‹ä»æŠ–éŸ³ã€å°çº¢ä¹¦å’Œå¾®ä¿¡å…¬ä¼—å·æŠ“å–çš„æœ€è¿‘3å¤©ç«å“æƒ…æŠ¥ã€‚
è¯·ç”Ÿæˆä¸€ä»½ã€Šå¸‚åœºé›·è¾¾æ—¥æŠ¥ã€‹ï¼ŒåŒ…å«ä¸‰ä¸ªæ¿å—ï¼š

1. **ğŸš¨ ç«å“æš´é›·åŒº (é‡ç‚¹)**ï¼š
   - è°å®¶æœ€è¿‘è¢«éª‚äº†ï¼Ÿç”¨æˆ·ç—›ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ
   - **é”€å”®è¯æœ¯**ï¼šé”€å”®é‡åˆ°å®¢æˆ·æè¿™å®¶ç«å“æ—¶ï¼Œå¦‚ä½•ç”¨è¿™ä¸ªé»‘æ–™ä¸€æ‹›åˆ¶æ•Œï¼Ÿ

2. **ğŸ“‰ ä»·æ ¼/æ´»åŠ¨ç›‘æµ‹**ï¼š
   - ç«å“æœ‰æ²¡æœ‰å‘"é™ä»·"ã€"ä¿Offer"ç­‰æ–°æµ·æŠ¥ï¼Ÿæˆ‘ä»¬è¯¥æ€ä¹ˆåº”å¯¹ï¼Ÿ

3. **ğŸ—£ï¸ çœŸå®å­¦å‘˜å£°éŸ³ (è¯„è®ºåŒºç²¾å)**ï¼š
   - æ‘˜å½• 3-5 æ¡æœ€æœ‰ä»£è¡¨æ€§çš„ç”¨æˆ·åæ§½è¯„è®ºï¼ˆåŸè¯ï¼‰ã€‚"""

        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹é‡‡é›†åˆ°çš„ç«å“æƒ…æŠ¥ï¼ˆæœ€è¿‘3å¤©ï¼‰ï¼š

{data_json}

è¯·æŒ‰ç…§ä¸Šè¿°è¦æ±‚ç”Ÿæˆã€Šå¸‚åœºé›·è¾¾æ—¥æŠ¥ã€‹ï¼Œæ ¼å¼ä¸º Markdownã€‚
æ¯æ¡æƒ…æŠ¥å¿…é¡»åŒ…å«åŸå§‹é“¾æ¥ï¼Œä¸¥ç¦ç¼–é€ ä¿¡æ¯ã€‚"""

        try:
            logger.info("è°ƒç”¨é˜¿é‡Œåƒé—® API ç”ŸæˆæŠ¥å‘Š...")
            
            # ä½¿ç”¨é˜¿é‡Œåƒé—®ç”Ÿæˆå†…å®¹ï¼ˆæ·»åŠ é‡è¯•æœºåˆ¶ï¼‰
            max_retries = 3
            retry_delay = 5
            
            for attempt in range(max_retries):
                try:
                    response = self.ai_client.chat.completions.create(
                        model=QWEN_MODEL,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.3,
                        max_tokens=2048,
                        timeout=60  # 60ç§’è¶…æ—¶
                    )
                    
                    report = response.choices[0].message.content
                    break  # æˆåŠŸï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                    
                except Exception as e:
                    if attempt < max_retries - 1:
                        logger.warning(f"é˜¿é‡Œåƒé—® API è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
                        logger.info(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        time.sleep(retry_delay)
                    else:
                        raise  # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
            
            # æ·»åŠ æ ‡é¢˜å’Œæ—¥æœŸ
            full_report = f"# æµ·é©¬èŒåŠ Â·å¸‚åœºé›·è¾¾æ—¥æŠ¥\n\n**ç”Ÿæˆæ—¶é—´**: {CURRENT_DATE}\n\n---\n\n{report}"
            
            logger.info("é˜¿é‡Œåƒé—® æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            return full_report
            
        except Exception as e:
            logger.error(f"é˜¿é‡Œåƒé—® ç”Ÿæˆå¤±è´¥: {str(e)}")
            # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œè¿”å›åŸºç¡€æŠ¥å‘Š
            return f"""# æµ·é©¬èŒåŠ Â·å¸‚åœºé›·è¾¾æ—¥æŠ¥

**ç”Ÿæˆæ—¶é—´**: {CURRENT_DATE}

## æ•°æ®ç»Ÿè®¡

- æŠ–éŸ³æ•°æ®: {len(self.douyin_data)} æ¡
- å°çº¢ä¹¦æ•°æ®: {len(self.xhs_data)} æ¡
- å¾®ä¿¡å…¬ä¼—å·æ•°æ®: {len(self.wechat_data)} æ¡

*æ³¨ï¼šAI åˆ†æå¤±è´¥ï¼Œè¯·æŸ¥çœ‹ raw_data.csv è·å–åŸå§‹æ•°æ®ã€‚*
"""
    
    def run(self, test_mode: bool = False, skip_login: bool = False):
        """
        æ‰§è¡Œå®Œæ•´çš„é‡‡é›†æµç¨‹
        
        Args:
            test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼ŒTrue æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            skip_login: æ˜¯å¦è·³è¿‡ç™»å½•æ­¥éª¤ï¼ˆå‡è®¾å·²ç™»å½•ï¼‰
        """
        logger.info("=" * 80)
        logger.info("æµ·é©¬èŒåŠ Â·å¸‚åœºé›·è¾¾æ—¥æŠ¥ - å¼€å§‹è¿è¡Œ" + (" [æµ‹è¯•æ¨¡å¼]" if test_mode else ""))
        logger.info("=" * 80)
        
        try:
            if test_mode:
                # æµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                logger.info("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•...")
                self.douyin_data = [
                    {
                        "platform": "æŠ–éŸ³",
                        "keyword": "DBCèŒæ¢¦",
                        "title": "DBCèŒæ¢¦å­¦å‘˜åˆ†äº«ï¼šæ‹¿åˆ°Amazon offerçš„çœŸå®ç»å†",
                        "url": "https://www.douyin.com/video/example1",
                        "date": "2å°æ—¶å‰",
                        "comments": [
                            "æˆ‘ä¹ŸæŠ¥äº†DBCï¼Œä½†æ˜¯æœåŠ¡çœŸçš„å¾ˆä¸€èˆ¬ï¼Œå¯¼å¸ˆå›å¤å¾ˆæ…¢",
                            "ä»–ä»¬ä»·æ ¼å¤ªè´µäº†ï¼Œæ€§ä»·æ¯”ä¸é«˜",
                            "DBCçš„ä¿offeræ‰¿è¯ºæ ¹æœ¬å…‘ç°ä¸äº†ï¼Œæˆ‘æœ‹å‹é€€è´¹æ‹–äº†3ä¸ªæœˆ"
                        ],
                        "comment_count": 3
                    }
                ]
                self.xhs_data = [
                    {
                        "platform": "å°çº¢ä¹¦",
                        "keyword": "çˆ±æ€ç›Š",
                        "title": "é¿é›·ï¼çˆ±æ€ç›Šé€€è´¹æ‹–å»¶ï¼Œå®¢æœä¸å›å¤",
                        "url": "https://www.xiaohongshu.com/explore/example1",
                        "date": "1å¤©å‰",
                        "snippet": "æŠ¥äº†çˆ±æ€ç›Šçš„è¯¾ç¨‹ï¼Œç”³è¯·é€€è´¹å·²ç»2ä¸ªæœˆäº†ï¼Œå®¢æœä¸€ç›´è¯´åœ¨å¤„ç†ï¼Œä½†å°±æ˜¯ä¸é€€é’±",
                        "has_negative": True,
                        "comments": [
                            "æˆ‘ä¹Ÿæ˜¯ï¼Œé€€è´¹æ‹–äº†3ä¸ªæœˆæ‰åˆ°è´¦",
                            "çˆ±æ€ç›Šçš„å®¢æœæ€åº¦å¾ˆå·®ï¼Œæ ¹æœ¬ä¸è§£å†³é—®é¢˜",
                        ],
                        "comment_count": 2
                    }
                ]
                self.wechat_data = [
                    {
                        "platform": "å¾®ä¿¡å…¬ä¼—å·",
                        "keyword": "é€”é¸½æ±‚èŒ",
                        "title": "é€”é¸½æ±‚èŒ2025æ˜¥å­£è¯¾ç¨‹ä¸Šçº¿",
                        "url": "https://mp.weixin.qq.com/s/example",
                        "date": "æ˜¨å¤©",
                        "snippet": "é€”é¸½æ¨å‡º2025æ˜¥å­£è¯¾ç¨‹ï¼ŒåŒ…å«ä¿offeræœåŠ¡",
                        "has_negative": False,
                        "comments": [],
                        "comment_count": 0
                    }
                ]
                logger.info(f"æ¨¡æ‹Ÿæ•°æ®ï¼šæŠ–éŸ³ {len(self.douyin_data)} æ¡ï¼Œå°çº¢ä¹¦ {len(self.xhs_data)} æ¡ï¼Œå¾®ä¿¡å…¬ä¼—å· {len(self.wechat_data)} æ¡")
            else:
                # æ­£å¸¸æ¨¡å¼ï¼šçœŸå®é‡‡é›†
                if not skip_login:
                    # ç¬¬ä¸€é˜¶æ®µï¼šäººå·¥ç™»å½•
                    self.manual_login()
                else:
                    logger.info("è·³è¿‡ç™»å½•æ­¥éª¤ï¼Œå‡è®¾æµè§ˆå™¨å·²ç™»å½•")
                    # æ‰“å¼€ä¸‰ä¸ªæ ‡ç­¾é¡µï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
                    try:
                        tabs = self.page.tab_ids
                        if len(tabs) == 0:
                            self.page.get('https://www.douyin.com')
                            time.sleep(2)
                            self.page.new_tab()
                            self.page.get('https://www.xiaohongshu.com')
                            time.sleep(2)
                            self.page.new_tab()
                            self.page.get('https://weixin.sogou.com/')
                            time.sleep(2)
                    except:
                        pass
                
                # ç¬¬äºŒé˜¶æ®µï¼šæŠ–éŸ³é‡‡é›†
                self.crawl_douyin()
                
                # ç¬¬ä¸‰é˜¶æ®µï¼šå°çº¢ä¹¦é‡‡é›†
                self.crawl_xhs()
                
                # ç¬¬ä¸‰é˜¶æ®µï¼ˆè¡¥å……ï¼‰ï¼šå¾®ä¿¡å…¬ä¼—å·é‡‡é›†
                self.crawl_wechat()
            
            # ä¿å­˜åŸå§‹æ•°æ®
            self.save_raw_data()
            
            # ç¬¬å››é˜¶æ®µï¼šç”ŸæˆæŠ¥å‘Š
            report = self.generate_report()
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = f"Market_Daily_Report_{CURRENT_DATE}.md"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
            if test_mode:
                # æµ‹è¯•æ¨¡å¼ï¼šæ‰“å°æŠ¥å‘Šåˆ°æ§åˆ¶å°
                print("\n" + "=" * 80)
                print("ã€æµ‹è¯•æ¨¡å¼ - æ¶ˆæ¯é¢„è§ˆã€‘")
                print("=" * 80)
                print(report)
                print("=" * 80)
                print(f"\nâœ… æµ‹è¯•å®Œæˆï¼Œæ¶ˆæ¯æœªå‘é€")
                print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼šæŠ–éŸ³ {len(self.douyin_data)} æ¡ï¼Œå°çº¢ä¹¦ {len(self.xhs_data)} æ¡ï¼Œå¾®ä¿¡å…¬ä¼—å· {len(self.wechat_data)} æ¡")
                logger.info("æµ‹è¯•æ¨¡å¼ï¼šæ¶ˆæ¯å·²æ‰“å°åˆ°æ§åˆ¶å°")
            else:
                print(f"\nâœ… é‡‡é›†å®Œæˆï¼")
                print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼šæŠ–éŸ³ {len(self.douyin_data)} æ¡ï¼Œå°çº¢ä¹¦ {len(self.xhs_data)} æ¡ï¼Œå¾®ä¿¡å…¬ä¼—å· {len(self.wechat_data)} æ¡")
                print(f"ğŸ“„ åŸå§‹æ•°æ®ï¼šraw_data.csv")
                print(f"ğŸ“‹ åˆ†ææŠ¥å‘Šï¼š{report_file}")
            
            logger.info("=" * 80)
            logger.info("å¸‚åœºé›·è¾¾æ—¥æŠ¥ç”Ÿæˆå®Œæˆ")
            logger.info("=" * 80)
            
        except Exception as e:
            logger.error(f"è¿è¡Œå¼‚å¸¸: {str(e)}", exc_info=True)
            raise
        finally:
            # ä¸è‡ªåŠ¨å…³é—­æµè§ˆå™¨ï¼Œè®©ç”¨æˆ·æŸ¥çœ‹ç»“æœ
            logger.info("æµè§ˆå™¨ä¿æŒæ‰“å¼€çŠ¶æ€ï¼Œè¯·æ‰‹åŠ¨å…³é—­")


def main():
    """ä¸»å‡½æ•°"""
    import sys
    # å¦‚æœå‘½ä»¤è¡Œå‚æ•°åŒ…å« --test æˆ– -tï¼Œåˆ™è¿›å…¥æµ‹è¯•æ¨¡å¼
    test_mode = '--test' in sys.argv or '-t' in sys.argv
    # å¦‚æœå‘½ä»¤è¡Œå‚æ•°åŒ…å« --skip-loginï¼Œåˆ™è·³è¿‡ç™»å½•æ­¥éª¤
    skip_login = '--skip-login' in sys.argv or '--skip' in sys.argv
    
    spy = MarketSpyPro()
    spy.run(test_mode=test_mode, skip_login=skip_login)


if __name__ == "__main__":
    main()
